ID,Start time,Completion time,Email,Name,What is your main occupation?,"Select main country or region of your workplace in past 5 years. [among the countries in Top500 list as of Nov. 2018. If you cannot find your country or region, please specify.]",Rate your overall programming skill (non-MPI programs):,Rate your MPI programming skill:,What programming language(s) do you use most often?,How long have you been writing computer programs (incl. non-MPI programs)?,How long have you been writing MPI programs?,Which fields are you mostly working in?,What is your major role at your place of work?,Have you ever read the MPI standard specification document?,How did you learn MPI?,Which MPI book(s) have you read?,Which MPI implementations do you use?,Why did you choose the MPI implementation(s)? [Select most suitable one],How do you check MPI specifications when you are writing MPI programs?,What is the most difficult part of writing an MPI program?,Which MPI features have you never heard of?,What aspects of the MPI standard do you use in your program in its current form?,Which MPI thread support are you using?,What are your obstacles to mastering MPI?,"When you call an MPI routine, how often do you check the error code of the MPI routine (excepting MPI-IO)?","In most of your programs, do you pack MPI function calls into their own file or files to have your own abstraction layer for communication?","Have you ever written MPI+”X” programs? If so, select all that apply.",Is there any room for performance tuning in your MPI programs? Select most suitable one.,"What, if any, alternatives are you investigating to indirectly call MPI or another communication layer by using another parallel language/library?","If there were one communication aspect which is not enough in the current MPI could improve the performance of your application, what would you prioritize? Or is MPI providing all the communicatio...","Is MPI providing all the communication semantics required by your application? If not, what is missing?",What MPI feature(s) are NOT useful for you application?,Do you think the MPI standard should maintain backward compatibility?,"In the tradeoff between code portability and performance, which is more or less important for you to write MPI programs? [""1"" means portability is the most important and ""3"" means both are equally..."
1,5/11/19 17:11:15,5/11/19 17:23:12,anonymous,,,China,6,4,C/C++;Python;,more than 10 years,between 2 and 5 years,"System software development (OS, runtime library, communication library, etc.);",Research and development of application(s);Research and development on system software (OS and/or runtime library);,I read only the chapters of interest for my work.,"I read the MPI standard document.;Other lectures or tutorials (workplace, conference).;",I have never read any MPI books;,MPICH;,I am familiar with it.,I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).;,Debugging,PMPI interface;,"Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread);",I do not know or I do not care.;,I have no obstacles.;Too many routines.;,Sometimes,"No, MPI calls are scattered in my programs.",OpenMP;,"Yes, I know there is room for tuning but I do not have enough resources to do that.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).;A Domain Specific Language (DSL).;",Multi-threading support,"Latency hiding (including asynchronous completion);Endpoints (multi-thread, sessions);Resilience (fault tolerance);",There are no unnecessary features;,"Yes, compatibility is very important for me.",3
2,5/12/19 12:08:30,5/12/19 12:20:48,anonymous,,College/University,China,4,4,C/C++;Fortran 90 or newer;,more than 10 years,more than 10 years,Numerical application and/or library;,Research and development of application(s);Performance tuning of MPI program(s);,I read only the chapters of interest for my work.,"I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;",Parallel Programming with MPI;Using MPI;,MPICH;Open MPI;Intel MPI;Tianhe MPI;,I am familiar with it.,I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).;,Domain decomposition,Persistent communication;PMPI interface;,"Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;",I have never called MPI_INIT_THREAD;,No appropriate lecture / book / info.;,Sometimes,"No, MPI calls are scattered in my programs.",OpenMP;CUDA;,"Yes, I know there is room for tuning but I should re-write large part of my program to do that.",A framework or library using MPI.;,Bandwidth,Resilience (fault tolerance);,There are no unnecessary features;,I prefer to have new API which is simpler and/or easier-to-use.,4
3,5/20/19 15:29:35,5/20/19 15:35:27,anonymous,,College/University,China,4,4,C/C++;,more than 10 years,between 5 and 10 years,"System software development (OS, runtime library, communication library, etc.);",Research and development on system software (OS and/or runtime library);,I read most of it. ,I read the MPI standard document.;I read book(s).;I had lecture(s) at school.;,Beginning MPI (An Introduction in C);Parallel Programming with MPI;Parallel Programming in C with MPI and OpenMP;,MPICH;,I like to use it.,I read the MPI Standard document (web/book).;,Algorithm design,Persistent communication;,Point-to-point communications;Collective communications;MPI datatypes;MPI with OpenMP (or multithread);,MPI_THREAD_MULTIPLE;,I have no obstacles.;,Always,"No, MPI calls are scattered in my programs.",OpenMP;,"Yes, I know there is room for tuning but I do not have enough resources to do that.",A framework or library using MPI.;,Message injection rate,Resilience (fault tolerance);,Dynamic process creation;,"Yes, compatibility is very important for me.",3
4,12/2/19 13:07:44,12/2/19 13:17:29,anonymous,,Software vendor,China,6,5,C/C++;Fortran 90 or newer;Python;,more than 10 years,between 5 and 10 years,Parallel language (incl. domain specific language);Numerical application and/or library;,Research and development of application(s);Performance tuning of MPI program(s);Debugging MPI programs;,I read only the chapters of interest for my work.,I read articles found on Internet.;,I have never read any MPI books;,Open MPI;,I am familiar with it.,I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).;,Performance tuning,Point-to-point communications;Dynamic process creation;Persistent communication;PMPI interface;,Collective communications;MPI datatypes;MPI with OpenMP (or multithread);,I have never called MPI_INIT_THREAD;I do not know or I do not care.;,Too complicated and hard to understand.;,Always,"Yes, to minimize the changes of communication API.",OpenMP;CUDA;,"Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A framework or library using MPI.;A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).;A Domain Specific Language (DSL).;",Latency,"Latency hiding (including asynchronous completion);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.);",There are no unnecessary features;,I prefer to have new API for better performance.,2
5,1/23/20 18:52:31,1/23/20 19:12:01,anonymous,,Private research institute,China,,,C/C++;,between 5 and 10 years,less than 2 years,other;,Research and development on system software (OS and/or runtime library);Debugging MPI programs;,I read only the chapters of interest for my work.,"I read the MPI standard document.;I read book(s).;Other lectures or tutorials (workplace, conference).;",Beginning MPI (An Introduction in C);Parallel Programming with MPI;Using MPI;,Open MPI;,I like to use it.,I read online documents (such as man pages).;,Debugging,Persistent communication;PMPI interface;,"Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;",I have never called MPI_INIT_THREAD;I do not know or I do not care.;,I have no obstacles.;,I rely on the default 'Errors abort' error handling,"No, MPI calls are scattered in my programs.",Sunway Athread;OpenACC;,"Yes, I know there is room for tuning but I do not have enough resources to do that.",A framework or library using MPI.;,MPI provides all semantics I need,Another API which is easier and/or simpler to use;MPI is providing all the communication semantics required by my application;,Process topologies;Error handlers;There are no unnecessary features;,"Yes, compatibility is very important for me.",4
6,1/23/20 19:17:41,1/23/20 19:24:39,anonymous,,Software vendor,China,4,2,Python;,between 2 and 5 years,less than 2 years,Numerical application and/or library;,Research and development of application(s);,"I have not read it, but I plan to. ",I read articles found on Internet.;,I have never read any MPI books;,MPICH;Open MPI;Intel MPI;,I could not have any choice (the one provided by a vendor).,I search the Internet (Google / Stack Overflow).;,Finding appropriate MPI routines,One-sided communications;PMPI interface;,MPI with OpenMP (or multithread);,I do not know or I do not care.;,I have nobody to ask.;,Always,"No, my program is too small to do that.",OpenMP;,I do not know how to find bottlenecks.,I am not investigating any alternatives.;,Bandwidth,MPI is providing all the communication semantics required by my application;,There are no unnecessary features;,"Yes, compatibility is very important for me.",1
7,1/23/20 20:44:19,1/23/20 20:48:30,anonymous,,College/University,China,4,3,C/C++;,between 2 and 5 years,less than 2 years,AI (Deep Learning);Image processing;,Research and development of application(s);,"I have not read it, but I plan to. ",I had lecture(s) at school.;I read articles found on Internet.;,Beginning MPI (An Introduction in C);,Open MPI;Sunway MPI;,I was said to use it.,I read book(s) (except the MPI standard).;,Algorithm design,One-sided communications;,"Collective communications;Communicator operations (split, duplicate, and so on);",MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED;MPI_THREAD_SERIALIZED;,I have no obstacles.;,Sometimes,"Yes, to minimize the changes of communication API.",Pthread;OpenACC;,"Yes, I know there is room for tuning but I should re-write large part of my program to do that.",A framework or library using MPI.;,"Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Endpoints (multi-thread, sessions);",Collective operations;,I do not know or I do not care.,3
8,1/23/20 21:09:06,1/23/20 21:29:59,anonymous,,Software vendor,China,4,3,C/C++;Fortran 90 or newer;,between 5 and 10 years,between 2 and 5 years,Numerical application and/or library;,Research and development of application(s);,"I have not read it, but I plan to. ",I read book(s).;I read articles found on Internet.;,Parallel Programming with MPI;,MPICH;Intel MPI;Sunway MPI;,I was said to use it.,I read book(s) (except the MPI standard).;,Algorithm design,One-sided communications;Dynamic process creation;PMPI interface;,Point-to-point communications;Collective communications;,I have never called MPI_INIT_THREAD;,I have no obstacles.;,Sometimes,"Yes, but I have no special reason for doing that.",OpenMP;,"Yes, I know there is room for tuning but I do not have enough resources to do that.",I am not investigating any alternatives.;,MPI provides all semantics I need,MPI is providing all the communication semantics required by my application;,There are no unnecessary features;,"Yes, compatibility is very important for me.",3
9,1/24/20 0:59:08,1/24/20 1:07:54,anonymous,,College/University,China,6,4,C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer;Python;,more than 10 years,between 5 and 10 years,"System software development (OS, runtime library, communication library, etc.);Numerical application and/or library;Tool development (performance tuning, debugging, etc.);",Research and development of application(s);Research and development on system software (OS and/or runtime library);Research and development software tool(s);Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs;,I read only the chapters of interest for my work.,Reading existing code;I read the MPI standard document.;I read articles found on Internet.;,MPI: The Complete Reference;,MVAPICH;Sunway MPI;,I could not have any choice (the one provided by a vendor).,I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).;,Performance tuning,Persistent communication;,"Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);PMPI interface;",I have never called MPI_INIT_THREAD;,Too many routines.;I do not like the API.;,I rely on the default 'Errors abort' error handling,"Yes, to minimize the changes of communication API.",Sunway athread;,"Yes, I know there is room for tuning but I should re-write large part of my program to do that.",I am not investigating any alternatives.;,"Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Latency hiding (including asynchronous completion);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.);",Datatypes;Process topologies;,I prefer to have new API which is simpler and/or easier-to-use.,5
10,1/24/20 10:21:40,1/24/20 10:34:03,anonymous,,Software vendor,China,6,6,C/C++;Python;,between 2 and 5 years,less than 2 years,Parallel language (incl. domain specific language);,Parallelization of sequential program(s);Performance tuning of MPI program(s);,I read only the chapters of interest for my work.,"Other lectures or tutorials (workplace, conference).;",Parallel Programming with MPI;,Sunway MPI;,I could not have any choice (the one provided by a vendor).,I read the MPI Standard document (web/book).;I read online documents (such as man pages).;,Performance tuning,Persistent communication;PMPI interface;,"Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;",MPI_THREAD_MULTIPLE;,No appropriate lecture / book / info.;,Mostly,"No, my program is too small to do that.",athread;,"Yes, I know there is room for tuning but I should re-write large part of my program to do that.",I am not investigating any alternatives.;,Bandwidth,Latency hiding (including asynchronous completion);,There are no unnecessary features;,I do not know or I do not care.,5
11,1/24/20 12:49:29,1/24/20 13:00:29,anonymous,,College/University,China,3,2,C/C++;,between 2 and 5 years,less than 2 years,Parallel language (incl. domain specific language);,Parallelization of sequential program(s);,I read only the chapters of interest for my work.,I read book(s).;,Parallel Programming with MPI;,Open MPI;,I am familiar with it.,I read book(s) (except the MPI standard).;,Algorithm design,Dynamic process creation;Persistent communication;PMPI interface;,Point-to-point communications;Collective communications;MPI datatypes;,MPI_THREAD_MULTIPLE;,Too complicated and hard to understand.;,I rely on the default 'Errors abort' error handling,"Yes, to minimize the changes of communication API.",Pthread;,"Yes, I know there is room for tuning but I should re-write large part of my program to do that.",A Domain Specific Language (DSL).;,"Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)",Latency hiding (including asynchronous completion);,There are no unnecessary features;,"Yes, compatibility is very important for me.",2