"Timestamp","What is your main occupation?","Select main country or region of your workplace in past 5 years. [among the countries in Top500 list as of Nov. 2018. If you cannot find your country or region, please specify.]","Rate your overall programming skill (non-MPI programs):","Rate your MPI programming skill:","What programming language(s) do you use most often?","How long have you been writing computer programs (incl. non-MPI programs)?","How long have you been writing MPI programs?","Which fields are you mostly working in?","What is your major role at your place of work?","Have you ever read the MPI standard specification document?","How did you learn MPI?","Which MPI book(s) have you read?","Which MPI implementations do you use?","Why did you choose the MPI implementation(s)? [Select most suitable one]","How do you check MPI specifications when you are writing MPI programs?","What is the most difficult part of writing an MPI program?","Which MPI features have you never heard of?","What aspects of the MPI standard do you use in your program in its current form?","Which MPI thread support are you using?","What are your obstacles to mastering MPI?","When you call an MPI routine, how often do you check the error code of the MPI routine  (excepting MPI-IO)?","In most of your programs, do you pack MPI function calls into their own file or files to have your own abstraction layer for communication?","Have you ever written MPI+”X” programs? If so, select all that apply.","Is there any room for performance tuning in your MPI programs? Select most suitable one.","What, if any, alternatives are you investigating to indirectly call MPI or another communication layer by using another parallel language/library?","If there were one communication aspect which is not enough in the current MPI could improve the performance of your application, what would you prioritize? Or is MPI providing all the communication semantics required by your application? If not, what is missing?","Is MPI providing all the communication semantics required by your application? If not, what is missing?","What MPI feature(s) are NOT useful for you application?","Do you think the MPI standard should maintain backward compatibility?","In the tradeoff between code portability and performance, which is more or less important for you to write MPI programs? [""1"" means portability is the most important and ""3"" means both are equally important.]"
"2019/02/17 1:10:36 AM AST","Governmental institute","Japan","5","3","Fortran 90 or newer;Ruby","more than 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s)","No, and I will not read it.","I read articles found on Internet.","","MPICH;Open MPI;Intel MPI","I have no special reason.","I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation;MPI with OpenMP (or multithread);PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;Persistent communications","I do not know or I do not care.","","Sometimes","Yes, to minimize the changes of communication API.","OpenMP","I think there is room but I do not know how to tune it.","A Domain Specific Language (DSL).","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","","API should be clearly versioned.","4"
"2019/02/17 1:14:06 AM AST","Hardware vendor","United States","5","6","C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer","more than 10 years","more than 10 years","System software development (OS, runtime library, communication library, etc.);Numerical application and/or library","Research and development of application(s);Research and development on system software (OS and/or runtime library);Debugging MPI programs","I read all.","I read the MPI standard document.;I read code.","Parallel Programming with MPI;Using MPI;MPI: The Complete Reference","MPICH;Open MPI;Intel MPI;Cray MPI","I am familiar with it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).;I know almost all MPI routines.","Domain decomposition","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread);PMPI interface","MPI_THREAD_FUNNELED;MPI_THREAD_MULTIPLE","Open-MPI is routinely buggy and prevents me from using MPI 3.0 as specified","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","OpenMP;Pthread","No, my MPI programs are well-tuned.","A framework or library using MPI.;A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).;Low-level communication layer provided by vendor (Verbs, DCMF, ...).","Asynchronous progress","Good integration with modern C++, including coroutines/fibers/async/future as well as object (de)serialization","Dynamic process creation","Yes, compatibility is very important for me.","3"
"2019/02/17 1:17:08 AM AST","College/University","Japan","5","6","C/C++;Fortran 90 or newer","more than 10 years","more than 10 years","System software development (OS, runtime library, communication library, etc.);AI (Deep Learning)","Performance tuning of MPI program(s)","","I read the MPI standard document.","Parallel Programming with MPI","Open MPI;MVAPICH;Intel MPI","I am familiar with it.","I read online documents (such as man pages).","Debugging","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread);PMPI interface","MPI_THREAD_FUNNELED;MPI_THREAD_MULTIPLE","I have no obstacles.;Too many routines.","Sometimes","No, MPI calls are scattered in my programs.","OpenMP;OpenACC;CUDA","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A framework or library using MPI.;A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Multi-threading support","Endpoints (multi-thread, sessions);Resilience (fault tolerance);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","Dynamic process creation","I prefer to have new API for better performance.","3"
"2019/02/17 5:07:14 AM AST","Software vendor","France","5","4","C/C++;Perl","between 5 and 10 years","between 2 and 5 years","System software development (OS, runtime library, communication library, etc.);Parallel language (incl. domain specific language);Tool development (performance tuning, debugging, etc.)","Research and development on system software (OS and/or runtime library);Research and development software tool(s)","I read only the chapters of interest for my work.","I read the MPI standard document.","I have never read any MPI books","MPICH;Open MPI;MPC MPI","I am familiar with it.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Domain decomposition","Dynamic process creation","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;Persistent communications;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED;MPI_THREAD_SERIALIZED;MPI_THREAD_MULTIPLE","Too many routines.","Sometimes","No, MPI calls are scattered in my programs.","OpenMP;Pthread","Yes, I know there is room for tuning but I do not have enough resources to do that.","A Domain Specific Language (DSL).;Low-level communication layer provided by vendor (Verbs, DCMF, ...).","Multi-threading support","Latency hiding (including asynchronous completion);Endpoints (multi-thread, sessions);Resilience (fault tolerance)","Datatypes","API should be clearly versioned.","4"
"2019/02/17 12:58:58 PM AST","College/University","Brazil","6","6","C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer;Java;Python","between 5 and 10 years","between 5 and 10 years","System software development (OS, runtime library, communication library, etc.);Parallel language (incl. domain specific language);Numerical application and/or library;Image processing;Visualization","Research and development of application(s);Research and development on system software (OS and/or runtime library);Research and development software tool(s);Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","I read all.","I read the MPI standard document.;I read book(s).;I had lecture(s) at school.","Parallel Programming with MPI;Using MPI","Open MPI;HPE MPI","I have no special reason.","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).","Finding appropriate MPI routines","Point-to-point communications;Collective communications","Point-to-point communications;Collective communications;MPI datatypes","MPI_THREAD_MULTIPLE","Too many routines.","Always","Yes, to minimize the changes of communication API.","OpenMP;Pthread","","A framework or library using MPI.","Latency","Latency hiding (including asynchronous completion);Endpoints (multi-thread, sessions);Resilience (fault tolerance)","","","5"
"2019/02/17 1:03:44 PM AST","Hardware vendor","United States","4","4","C/C++;Fortran (older one than Fortran 90)","between 5 and 10 years","between 2 and 5 years","System software development (OS, runtime library, communication library, etc.);Numerical application and/or library","Research and development on system software (OS and/or runtime library)","I read only the chapters of interest for my work.","I read the MPI standard document.","I have never read any MPI books","MPICH;MVAPICH;Cray MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED;MPI_THREAD_SERIALIZED;MPI_THREAD_MULTIPLE","I have no obstacles.","Sometimes","Yes, to minimize the changes of communication API.","OpenMP;Pthread","I have no chance to investigate.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Message injection rate","Latency hiding (including asynchronous completion);Endpoints (multi-thread, sessions);Resilience (fault tolerance)","Dynamic process creation","Yes, compatibility is very important for me.","4"
"2019/02/17 1:58:34 PM AST","College/University","Italy","6","6","C/C++;Python","more than 10 years","more than 10 years","Numerical application and/or library;AI (Deep Learning);Big data;Workflow and/or In-situ","Teaching at MSc and PhD level, research on parallel and distributed computing","I read most of it.","I read the MPI standard document.;I read book(s).;Other lectures or tutorials (workplace, conference).","Parallel Programming with MPI;Using MPI;Parallel Programming in C with MPI and OpenMP;MPI: The Complete Reference;Other volumes of MPI: the complete reference","MPICH;Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).;I search the Internet (Google / Stack Overflow).;I know almost all MPI routines.","Other","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;Dynamic process creation;Persistent communications;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE","I have no obstacles.","Always","No, MPI calls are scattered in my programs.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","MPI is providing all the communication semantics required by my application","There are no unnecessary features","Yes, compatibility is very important for me.","3"
"2019/02/17 3:12:24 PM AST","Governmental institute","United States","6","4","Fortran (older one than Fortran 90);Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library;Tool development (performance tuning, debugging, etc.)","Research and development of application(s);Performance tuning of MPI program(s);Debugging MPI programs","I read only the chapters of interest for my work.","On the job training","Using MPI","Intel MPI;HPE MPI","I am familiar with it.","I read online documents (such as man pages).","Domain decomposition","Persistent communication","Point-to-point communications;Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_MULTIPLE","Too many routines.","Never","No, MPI calls are scattered in my programs.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Message injection rate","Resilience (fault tolerance);Another API which is easier and/or simpler to use","Process topologies;Dynamic process creation","Yes, compatibility is very important for me.","3"
"2019/02/17 3:26:38 PM AST","Governmental institute","United States","5","5","C/C++;Python","more than 10 years","between 5 and 10 years","System software development (OS, runtime library, communication library, etc.);AI (Deep Learning)","Research and development on system software (OS and/or runtime library);Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","I read book(s).;I read articles found on Internet.","I have never read any MPI books","Open MPI","I was said to use it.","I read online documents (such as man pages).","Domain decomposition","PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);Dynamic process creation;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE","Too many routines.;No appropriate lecture / book / info.","Sometimes","No, MPI calls are scattered in my programs.","OpenMP","I do not have (know) tools to find performance bottlenecks.","A framework or library using MPI.","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Endpoints (multi-thread, sessions);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","Error handlers","API should be clearly versioned.","4"
"2019/02/17 3:41:03 PM AST","College/University","Brazil","5","4","C/C++;Python","between 5 and 10 years","between 2 and 5 years","System software development (OS, runtime library, communication library, etc.);Workflow and/or In-situ;Tool development (performance tuning, debugging, etc.);I/O","Research and development on system software (OS and/or runtime library);Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","I read book(s).;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","MPICH;Open MPI;Intel MPI","I like to use it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Performance tuning","One-sided communications;Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","I have no obstacles.","Sometimes","No, my program is too small to do that.","OpenMP;Pthread","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A framework or library using MPI.","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Latency hiding (including asynchronous completion);Endpoints (multi-thread, sessions);Resilience (fault tolerance)","There are no unnecessary features","I prefer to have new API for better performance.","4"
"2019/02/17 4:55:01 PM AST","College/University","Japan","4","5","C/C++;Fortran 90 or newer;Python","more than 10 years","more than 10 years","System software development (OS, runtime library, communication library, etc.)","Research and development on system software (OS and/or runtime library);Performance tuning of MPI program(s)","","I read book(s).;I read articles found on Internet.","Parallel Programming with MPI;Using MPI;Parallel Programming in C with MPI and OpenMP","Open MPI;MVAPICH;Intel MPI;Fujistu MPI","I have no special reason.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","","Point-to-point communications;Collective communications;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_FUNNELED;MPI_THREAD_MULTIPLE","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","No, MPI calls are scattered in my programs.","OpenMP;Pthread","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A framework or library using MPI.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","Datatypes;Dynamic process creation","Yes, compatibility is very important for me.","4"
"2019/02/17 8:03:12 PM AST","Private research institute","Japan","5","4","C/C++;Fortran 90 or newer","more than 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).","MPI: The Complete Reference","Open MPI;Intel MPI;Fujistu MPI","I was said to use it.","I read the MPI Standard document (web/book).;I search the Internet (Google / Stack Overflow).","Algorithm design","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);Dynamic process creation;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED","Too many routines.","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","One-sided communication","Yes, compatibility is very important for me.","2"
"2019/02/17 8:28:28 PM AST","Private research institute","United States","5","5","C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s);Research and development software tool(s);Parallelization of sequential program(s);Debugging MPI programs","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).","MPI: The Complete Reference","MPICH;Open MPI;MVAPICH;IBM MPI (BG/Q, PE, Spectrum)","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).","Implementation issue workaround","Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes","MPI_THREAD_MULTIPLE","I have no obstacles.","Mostly","No, MPI calls are scattered in my programs.","Pthread","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","There are no unnecessary features","Yes, compatibility is very important for me.","5"
"2019/02/17 8:52:58 PM AST","College/University","Brazil","6","5","C/C++;Python","more than 10 years","more than 10 years","Parallel language (incl. domain specific language);AI (Deep Learning);Workflow and/or In-situ","Research and development of application(s);Research and development on system software (OS and/or runtime library)","","I read book(s).","I have never read any MPI books","MPICH;Open MPI","I am familiar with it.","I search the Internet (Google / Stack Overflow).","Algorithm design","","Point-to-point communications;Communicator operations (split, duplicate, and so on);MPI datatypes;Dynamic process creation;Persistent communications","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","the message passing paradigm ","","Yes, to minimize the changes of communication API.","No","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.","dynamic scheduling ","Resilience (fault tolerance)","Error handlers","Yes, compatibility is very important for me.","4"
"2019/02/17 9:18:22 PM AST","College/University","Korea, South","5","4","C/C++;Python","more than 10 years","between 2 and 5 years","System software development (OS, runtime library, communication library, etc.);AI (Deep Learning)","Research and development on system software (OS and/or runtime library)","I read only the chapters of interest for my work.","I read book(s).;I had lecture(s) at school.","Parallel Programming in C with MPI and OpenMP","MPICH;Open MPI","I am familiar with it.","I read book(s) (except the MPI standard).;I read online documents (such as man pages).","Finding appropriate MPI routines","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes","I have never called MPI_INIT_THREAD","I have nobody to ask.","Sometimes","Yes, but I have no special reason for doing that.","No","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","Dynamic process creation","I do not know or I do not care.","2"
"2019/02/17 9:46:43 PM AST","Other","United States","6","6","C/C++;Fortran 90 or newer;Python","more than 10 years","more than 10 years","System software development (OS, runtime library, communication library, etc.);Parallel language (incl. domain specific language);Numerical application and/or library;Tool development (performance tuning, debugging, etc.)","Research and development of application(s);Research and development on system software (OS and/or runtime library);Research and development software tool(s);Performance tuning of MPI program(s);Debugging MPI programs","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).;I had lecture(s) at school.;I read articles found on Internet.","Using MPI;MPI: The Complete Reference","MPICH;Open MPI;MVAPICH;Intel MPI;Cray MPI;IBM MPI (BG/Q, PE, Spectrum);MS MPI;Adaptive MPI","I have no special reason.","I read online documents (such as man pages).","Algorithm design","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;PMPI interface","MPI_THREAD_FUNNELED;MPI_THREAD_MULTIPLE","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","OpenMP;Pthread;CUDA","Yes, I am actively doing tuning work","A framework or library using MPI.;Dynamic runtime system that MPI usage to provide asynchronous execution","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Endpoints (multi-thread, sessions);Resilience (fault tolerance);MPI is providing all the communication semantics required by my application","Dynamic process creation;Error handlers","Yes, compatibility is very important for me.","4"
"2019/02/18 2:58:27 AM AST","College/University","Germany","5","5","C/C++;Python","more than 10 years","more than 10 years","Parallel language (incl. domain specific language);Tool development (performance tuning, debugging, etc.)","Management","I read only the chapters of interest for my work.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).","I have never read any MPI books","MPICH;Open MPI;Intel MPI;IBM MPI (BG/Q, PE, Spectrum)","I like to use it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation;Persistent communication","Point-to-point communications;Collective communications;MPI datatypes;One-sided communications;MPI with OpenMP (or multithread);PMPI interface","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED","Too many routines.;Too complicated and hard to understand.;I do not like the API.","Sometimes","No, MPI calls are scattered in my programs.","OpenMP;Pthread;CUDA","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A framework or library using MPI.","Multi-threading support","Endpoints (multi-thread, sessions);Another API which is easier and/or simpler to use","Dynamic process creation","I prefer to have new API which is simpler and/or easier-to-use.","4"
"2019/02/18 5:48:47 AM AST","College/University","Germany","4","4","C/C++","between 2 and 5 years","less than 2 years","Numerical application and/or library;Workflow and/or In-situ;Visualization;Tool development (performance tuning, debugging, etc.)","Research and development of application(s);Performance tuning of MPI program(s);Debugging MPI programs","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","I have never read any MPI books","Open MPI","I like to use it.","I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation;Persistent communication;PMPI interface","Collective communications;MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","Too complicated and hard to understand.;no unified, simplified (i.e. for beginners) function documentation (with usage examples)","Always","No, MPI calls are scattered in my programs.","OpenMP","I think there is room but I do not know how to tune it.","I am not investigating any alternatives.","ensure information from one-sided call (e.g. MPI_Get) has arrived, without the need to close the communication fence (i.e. synchronize all ranks at once)","Latency hiding (including asynchronous completion);Another API which is easier and/or simpler to use","Communicator and group management","I prefer to have new API which is simpler and/or easier-to-use.","3"
"2019/02/18 6:15:32 AM AST","College/University","Spain","6","6","C/C++","more than 10 years","more than 10 years","Parallel language (incl. domain specific language)","Research and development of application(s)","I read only the chapters of interest for my work.","I had lecture(s) at school.","I have never read any MPI books","Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).","Debugging","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;One-sided communications;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","I have no obstacles.","Sometimes","No, MPI calls are scattered in my programs.","OpenMP;Pthread;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Bandwidth","MPI is providing all the communication semantics required by my application","Process topologies","Yes, compatibility is very important for me.","1"
"2019/02/18 7:24:41 AM AST","College/University","Argentina","5","5","C/C++;Java;Python","more than 10 years","more than 10 years","Big data","Research and development of application(s)","I read only the chapters of interest for my work.","I read articles found on Internet.","I have never read any MPI books","MPICH;Open MPI","I have no special reason.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Performance tuning","Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","Too many routines.","I rely on the default ‘Errors abort’ error handling","No, MPI calls are scattered in my programs.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Multi-threading support","MPI is providing all the communication semantics required by my application","One-sided communication","Yes, compatibility is very important for me.","4"
"2019/02/18 7:56:20 AM AST","Governmental institute","France","5","4","C/C++","more than 10 years","between 5 and 10 years","System software development (OS, runtime library, communication library, etc.);Tool development (performance tuning, debugging, etc.)","Research and development on system software (OS and/or runtime library);Research and development software tool(s)","I read most of it.","I had lecture(s) at school.","Parallel Programming with MPI;Using MPI;MPI: The Complete Reference","MPICH;Open MPI;MVAPICH","I am familiar with it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).","Debugging","","Point-to-point communications;Collective communications;MPI with OpenMP (or multithread)","MPI_THREAD_FUNNELED;MPI_THREAD_MULTIPLE","Too many routines.","I rely on the default ‘Errors abort’ error handling","No, MPI calls are scattered in my programs.","OpenMP;Pthread;CUDA","I think there is room but I do not know how to tune it.","I am not investigating any alternatives.","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","MPI is providing all the communication semantics required by my application","Dynamic process creation","I prefer to have new API which is simpler and/or easier-to-use.","3"
"2019/02/18 9:01:55 AM AST","College/University","Germany","5","5","C/C++;Python","more than 10 years","more than 10 years","Parallel language (incl. domain specific language);Tool development (performance tuning, debugging, etc.)","Research and development of application(s);Research and development on system software (OS and/or runtime library);Research and development software tool(s);Performance tuning of MPI program(s)","I read most of it.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.;From experts and interaction with MPI-Forum members","","Open MPI;MVAPICH;Intel MPI;Cray MPI;NEC MPI","I am familiar with it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I ask colleagues.;I know almost all MPI routines.","Performance tuning","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread);MPI I/O","MPI_THREAD_MULTIPLE","While send/recv and collectives are easy to start, the amount of specialized functions is sometimes hard to oversea","","No, MPI calls are scattered in my programs.","OpenMP;Pthread;OmpSs","No, my MPI programs are well-tuned.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).;A Domain Specific Language (DSL).;Low-level communication layer provided by vendor (Verbs, DCMF, ...).","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Latency hiding (including asynchronous completion);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","Dynamic process creation;Error handlers","API should be clearly versioned.","4"
"2019/02/18 9:18:29 AM AST","College/University","United States","5","4","C/C++;Python","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I read book(s).;I read articles found on Internet.","Using MPI;MPI: The Complete Reference","MPICH;Open MPI","I have no special reason.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes","I have never called MPI_INIT_THREAD","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","It depends on the program; my longer programs have abstraction layers but shorter ones do not","","I do not know how to find bottlenecks.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","One-sided communication;Dynamic process creation","Yes, compatibility is very important for me.","3"
"2019/02/18 9:24:11 AM AST","Software vendor","United Kingdom","5","4","C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer","more than 10 years","more than 10 years","Parallel language (incl. domain specific language);Numerical application and/or library","Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","No, and I will not read it.","I read book(s).;I had lecture(s) at school.","Using MPI","MPICH;Open MPI;Intel MPI;Cray MPI","I could not have any choice (the one provided by a vendor).","I read book(s) (except the MPI standard).;I search the Internet (Google / Stack Overflow).","Algorithm design","Persistent communication","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_MULTIPLE","I have no obstacles.","Always","No, MPI calls are scattered in my programs.","OpenMP","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","I am not investigating any alternatives.","Multi-threading support","MPI is providing all the communication semantics required by my application","Dynamic process creation","Yes, compatibility is very important for me.","3"
"2019/02/18 9:35:38 AM AST","Governmental institute","Italy","5","5","C/C++;Fortran (older one than Fortran 90)","more than 10 years","more than 10 years","Parallel language (incl. domain specific language);Numerical application and/or library","Research and development of application(s);Parallelization of sequential program(s)","","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).","Using MPI;MPI: The Complete Reference","MPICH;Intel MPI","I like to use it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Performance tuning","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;One-sided communications","I have never called MPI_INIT_THREAD","I have no obstacles.","Mostly","Yes, but I have no special reason for doing that.","No","I think there is room but I do not know how to tune it.","A framework or library using MPI.","Message injection rate","Resilience (fault tolerance);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","There are no unnecessary features","Yes, compatibility is very important for me.","3"
"2019/02/18 9:52:07 AM AST","Governmental institute","Switzerland","4","3","C/C++;Python","more than 10 years","more than 10 years","Tool development (performance tuning, debugging, etc.)","Research and development software tool(s);Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","","MPICH;MVAPICH;Intel MPI;Cray MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).","Performance tuning","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread);PMPI interface","Point-to-point communications;Collective communications;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED;MPI_THREAD_SERIALIZED","Too many routines.;No appropriate lecture / book / info.;Too complicated and hard to understand.;I do not like the API.","Sometimes","No, MPI calls are scattered in my programs.","OpenMP;OpenACC;OpenCL;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.;A Domain Specific Language (DSL).;Low-level communication layer provided by vendor (Verbs, DCMF, ...).","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Latency hiding (including asynchronous completion);Resilience (fault tolerance);Another API which is easier and/or simpler to use","Process topologies","API should be clearly versioned.","3"
"2019/02/18 10:37:36 AM AST","Hardware vendor","United States","6","6","C/C++","more than 10 years","more than 10 years","System software development (OS, runtime library, communication library, etc.)","Research and development on system software (OS and/or runtime library);Research and development software tool(s)","I read all.","I read the MPI standard document.;I read book(s).;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Using MPI;MPI: The Complete Reference","MPICH;Open MPI","I am familiar with it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).;I know almost all MPI routines.","Algorithm design","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","No, MPI calls are scattered in my programs.","Pthread","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Endpoints (multi-thread, sessions)","One-sided communication","API should be clearly versioned.","2"
"2019/02/18 2:37:20 PM AST","College/University","Brazil","6","5","C/C++;Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library;AI (Deep Learning);Image processing;Tool development (performance tuning, debugging, etc.)","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s)","I read most of it.","I read the MPI standard document.;I read book(s).;I had lecture(s) at school.;I read articles found on Internet.","Parallel Programming with MPI;Using MPI;Parallel Programming in C with MPI and OpenMP;MPI: The Complete Reference","MPICH;Open MPI;MVAPICH;Intel MPI;Cray MPI;NEC MPI","I am familiar with it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Implementation issue workaround","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_FUNNELED","I have no obstacles.","Sometimes","No, MPI calls are scattered in my programs.","OpenMP;OpenACC;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Latency hiding (including asynchronous completion);Resilience (fault tolerance);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","There are no unnecessary features","Yes, compatibility is very important for me.","4"
"2019/02/18 6:19:41 PM AST","College/University","United Kingdom","6","5","C/C++;Python","more than 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).;I had lecture(s) at school.","I have never read any MPI books","MPICH;Open MPI;MVAPICH;Intel MPI;Cray MPI;HPE MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).","Algorithm design","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED;MPI_THREAD_MULTIPLE","Too many routines.","Always","Yes, to minimize the changes of communication API.","OpenMP;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Multi-threading support","Another API which is easier and/or simpler to use","One-sided communication;Process topologies;Dynamic process creation","I prefer to have new API for better performance.","1"
"2019/02/19 6:00:01 AM AST","Software vendor","Japan","5","5","C/C++;Python","more than 10 years","more than 10 years","System software development (OS, runtime library, communication library, etc.);AI (Deep Learning);Tool development (performance tuning, debugging, etc.)","Research and development on system software (OS and/or runtime library);Research and development software tool(s);Performance tuning of MPI program(s);Debugging MPI programs","","I read the MPI standard document.;I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Using Advanced MPI","Open MPI","I like to use it.","I read online documents (such as man pages).","Debugging","Persistent communication","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_MULTIPLE","I have no obstacles.","Always","Yes, but I have no special reason for doing that.","CUDA;StarPU, Intel TBB, MassiveThreads","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A framework or library using MPI.;Low-level communication layer provided by vendor (Verbs, DCMF, ...).","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","","Dynamic process creation;Error handlers","API should be clearly versioned.","4"
"2019/02/19 6:44:50 AM AST","College/University","United Kingdom","4","3","C/C++;Fortran 90 or newer;Java;Python","between 5 and 10 years","between 2 and 5 years","Numerical application and/or library","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","I have never read any MPI books","Open MPI;Intel MPI;Cray MPI;IBM MPI (BG/Q, PE, Spectrum);HPE MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I search the Internet (Google / Stack Overflow).","Domain decomposition","Communicator operations (split, duplicate, and so on);Dynamic process creation;PMPI interface","Point-to-point communications;Collective communications;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","Too complicated and hard to understand.","Never","No, MPI calls are scattered in my programs.","OpenMP","Yes, but I can not be bothered","A framework or library using MPI.;A Domain Specific Language (DSL).","","","Process topologies;Dynamic process creation","I prefer to have new API which is simpler and/or easier-to-use.","3"
"2019/02/19 7:07:07 AM AST","Governmental institute","United States","6","6","C/C++;Fortran 90 or newer;Python","more than 10 years","","System software development (OS, runtime library, communication library, etc.)","Research and development on system software (OS and/or runtime library);Debugging MPI programs","I read all.","I read the MPI standard document.;I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Parallel Programming with MPI;Using MPI;MPI: The Complete Reference","MPICH;Open MPI;Intel MPI;Cray MPI;IBM MPI (BG/Q, PE, Spectrum)","I am familiar with it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).;I know almost all MPI routines.","Performance tuning","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_MULTIPLE","Too many routines.","Mostly","Yes, to minimize the changes of communication API.","OpenMP;OpenACC;OpenCL;CUDA","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).;Low-level communication layer provided by vendor (Verbs, DCMF, ...).","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Endpoints (multi-thread, sessions);Resilience (fault tolerance)","Dynamic process creation","API should be clearly versioned.","3"
"2019/02/19 7:50:27 AM AST","College/University","United Kingdom","5","3","C/C++;Fortran 90 or newer;Shell scripts, Perl","more than 10 years","more than 10 years","Numerical application and/or library;Application optimisation and benchmarking","Research and development of application(s);Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).","I have never read any MPI books;Just the standard version 3.0","MPICH;Intel MPI;Cray MPI;SGI MPT ","","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","Too complicated and hard to understand.","Always","No, MPI calls are scattered in my programs.","OpenMP","I have no chance to investigate.","I am not investigating any alternatives.","Bandwidth","MPI is providing all the communication semantics required by my application","Dynamic process creation","Yes, compatibility is very important for me.","4"
"2019/02/19 10:18:28 AM AST","College/University","Brazil","5","5","C/C++;Python","more than 10 years","more than 10 years","Parallel language (incl. domain specific language)","Parallelization of sequential program(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).","Parallel Programming with MPI;Using MPI;Parallel Programming in C with MPI and OpenMP","MPICH;Open MPI","I like to use it.","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).;I search the Internet (Google / Stack Overflow).","Debugging","PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;Dynamic process creation;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_SERIALIZED","I have no obstacles.","Always","Yes, to minimize the changes of communication API.","OpenMP","I do not have (know) tools to find performance bottlenecks.","A framework or library using MPI.","I do not know if there is more to improve","Latency hiding (including asynchronous completion)","There are no unnecessary features","I prefer to have new API for better performance.","4"
"2019/02/19 10:57:31 AM AST","College/University","United States","6","6","C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer","more than 10 years","more than 10 years","System software development (OS, runtime library, communication library, etc.);Numerical application and/or library","Administration but with some R&D","I read all.","I read the MPI standard document.;MPI Forum","Using MPI;MPI: The Complete Reference","MPICH;MVAPICH;Cray MPI;IBM MPI (BG/Q, PE, Spectrum)","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).","Domain decomposition","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;Persistent communications;MPI with OpenMP (or multithread);PMPI interface","MPI_THREAD_FUNNELED;MPI_THREAD_MULTIPLE","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","OpenMP;Pthread","No, my MPI programs are well-tuned.","A framework or library using MPI.","Latency","Endpoints (multi-thread, sessions)","Dynamic process creation;Error handlers","API should be clearly versioned.","3"
"2019/02/19 5:13:04 PM AST","College/University","United States","5","5","C/C++;Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library;Big data","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","I read book(s).;I had lecture(s) at school.;I read articles found on Internet.","Parallel Programming with MPI;Using MPI","MPICH;Open MPI;MVAPICH;Intel MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).","Debugging","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_FUNNELED;MPI_THREAD_MULTIPLE","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","Yes, but I have no special reason for doing that.","OpenMP;CUDA","I think there is room but I do not know how to tune it.","I am not investigating any alternatives.","Message injection rate","Endpoints (multi-thread, sessions);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","There are no unnecessary features","I prefer to have new API for better performance.","3"
"2019/02/19 8:12:24 PM AST","College/University","United States","4","5","C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library","Research and development software tool(s);Parallelization of sequential program(s);Performance tuning of MPI program(s)","I read most of it.","I read the MPI standard document.;I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","MPI: The Complete Reference","MVAPICH;Intel MPI;Cray MPI;IBM MPI (BG/Q, PE, Spectrum)","I could not have any choice (the one provided by a vendor).","I search the Internet (Google / Stack Overflow).","Performance tuning","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED;MPI_THREAD_SERIALIZED;MPI_THREAD_MULTIPLE","Too many routines.;I do not like the API.","Never","Yes, to minimize the changes of communication API.","OpenMP","I think there is room but I do not know how to tune it.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).;Low-level communication layer provided by vendor (Verbs, DCMF, ...).","Bandwidth","Latency hiding (including asynchronous completion);Another API which is easier and/or simpler to use","Process topologies;Dynamic process creation;Error handlers","Yes, compatibility is very important for me.","4"
"2019/02/20 7:52:28 AM AST","Governmental institute","Poland","5","3","Fortran 90 or newer","more than 10 years","more than 10 years","Parallel language (incl. domain specific language);Numerical application and/or library;Tool development (performance tuning, debugging, etc.)","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","I read only the chapters of interest for my work.","I read code !","I have never read any MPI books","MPICH;Open MPI;Intel MPI;Cray MPI;IBM MPI (BG/Q, PE, Spectrum)","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I search the Internet (Google / Stack Overflow).","Algorithm design","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes","I have never called MPI_INIT_THREAD","difficulty with debugging","Sometimes","Yes, to minimize the changes of communication API.","No","Yes, I know there is room for tuning but I do not have enough resources to do that.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).;A Domain Specific Language (DSL).","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Latency hiding (including asynchronous completion);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.);MPI is providing all the communication semantics required by my application","There are no unnecessary features","I prefer to have new API for better performance.","3"
"2019/02/20 7:54:13 AM AST","College/University","Poland","5","4","Java","more than 10 years","more than 10 years","Parallel language (incl. domain specific language);Numerical application and/or library","Research and development of application(s)","No, and I will not read it.","Other lectures or tutorials (workplace, conference).","I have never read any MPI books","MPICH;Open MPI;Cray MPI","I have no special reason.","I search the Internet (Google / Stack Overflow).","Implementation issue workaround","","Point-to-point communications;Collective communications;MPI datatypes;Persistent communications","I do not know or I do not care.","Too many routines.;Too complicated and hard to understand.;I do not like the API.;no good Java support","Sometimes","No, MPI calls are scattered in my programs.","No","Yes, I know there is room for tuning but I do not have enough resources to do that.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","MPI provides all semantics I need","Latency hiding (including asynchronous completion);Another API which is easier and/or simpler to use","Process topologies","I do not know or I do not care.","3"
"2019/02/20 7:55:15 AM AST","College/University","Poland","4","4","C/C++;Fortran 90 or newer","between 5 and 10 years","between 5 and 10 years","Parallel language (incl. domain specific language);Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).","I have never read any MPI books","Open MPI;MVAPICH;Intel MPI;IBM MPI (BG/Q, PE, Spectrum)","I have no special reason.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Communicator operations (split, duplicate, and so on);One-sided communications;Dynamic process creation","Point-to-point communications;Collective communications;MPI with OpenMP (or multithread)","MPI_THREAD_MULTIPLE","I have no obstacles.","Sometimes","No, my program is too small to do that.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Multi-threading support","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","There are no unnecessary features","Yes, compatibility is very important for me.","5"
"2019/02/20 8:21:18 AM AST","College/University","Poland","6","6","C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer;Python","more than 10 years","between 5 and 10 years","Numerical application and/or library;AI (Deep Learning)","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","I have never read any MPI books","Open MPI;Intel MPI;Cray MPI;IBM MPI (BG/Q, PE, Spectrum)","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Algorithm design","PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;Persistent communications;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE","I have no obstacles.","Sometimes","No, MPI calls are scattered in my programs.","OpenMP;CUDA","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Multi-threading support","","Dynamic process creation","Yes, compatibility is very important for me.","5"
"2019/02/20 8:25:57 AM AST","College/University","United Kingdom","4","5","C/C++;Fortran 90 or newer","more than 10 years","more than 10 years","Parallel language (incl. domain specific language);Numerical application and/or library","Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).","Using MPI","Open MPI;Intel MPI;Cray MPI","I have no special reason.","I read online documents (such as man pages).","Algorithm design","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;Persistent communications;MPI with OpenMP (or multithread);PMPI interface","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","OpenMP;OpenACC","","A framework or library using MPI.;A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).;A Domain Specific Language (DSL).","Latency","Latency hiding (including asynchronous completion);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","One-sided communication;Dynamic process creation","I prefer to have new API which is simpler and/or easier-to-use.","3"
"2019/02/20 3:50:32 PM AST","College/University","United Kingdom","6","6","C/C++;Fortran 90 or newer;Python","more than 10 years","more than 10 years","Parallel language (incl. domain specific language);Numerical application and/or library;Visualization","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","I read only the chapters of interest for my work.","I read book(s).","MPI: The Complete Reference","MPICH;Open MPI;MVAPICH;Intel MPI;Cray MPI;IBM MPI (BG/Q, PE, Spectrum)","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).","Algorithm design","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;Persistent communications;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED;MPI_THREAD_SERIALIZED","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","OpenMP;Pthread","No, my MPI programs are well-tuned.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Resilience (fault tolerance);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","Dynamic process creation","API should be clearly versioned.","3"
"2019/02/20 3:58:24 PM AST","College/University","United States","6","4","C/C++","more than 10 years","between 2 and 5 years","Neuroscience modelling","Lab head","No, and I will not read it.","I read book(s).","MPI: The Complete Reference","Open MPI","I was said to use it.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","MPI with OpenMP (or multithread);PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;Dynamic process creation","I have never called MPI_INIT_THREAD","I have no obstacles.","Mostly","No, MPI calls are scattered in my programs.","No","I have no chance to investigate.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","There are no unnecessary features","Yes, compatibility is very important for me.","4"
"2019/02/20 4:00:48 PM AST","Governmental institute","United States","6","5","C/C++;Fortran 90 or newer","more than 10 years","between 5 and 10 years","System software development (OS, runtime library, communication library, etc.);Numerical application and/or library","Research and development of application(s);Research and development software tool(s);Parallelization of sequential program(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).","Using MPI","MPICH;Open MPI;Intel MPI","I am familiar with it.","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Domain decomposition","Dynamic process creation;Persistent communication","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED;MPI_THREAD_SERIALIZED;MPI_THREAD_MULTIPLE","","Sometimes","Yes, to minimize the changes of communication API.","OpenMP","I have no chance to investigate.","A framework or library using MPI.;A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Non-blocking collectives that could be used to loosen consistency semantics in PGAS languages","Non-blocking collectives","There are no unnecessary features","","3"
"2019/02/20 4:07:55 PM AST","College/University","United States","4","4","C/C++","between 5 and 10 years","between 2 and 5 years","System software development (OS, runtime library, communication library, etc.);Numerical application and/or library","Research and development of application(s);Research and development on system software (OS and/or runtime library);Performance tuning of MPI program(s);Debugging MPI programs","I read most of it.","I read the MPI standard document.;I read book(s).","Using MPI;The green and blue books (of Using MPI series)","MPICH;MVAPICH;Intel MPI;Cray MPI","I am familiar with it.","I read the MPI Standard document (web/book).","Domain decomposition","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE;I do not know or I do not care.","I have nobody to ask.","Sometimes","Yes, to minimize the changes of communication API.","OpenMP;CUDA","I believe there should be another option: ""MPI does not provide the option that I need for performance tuning.""","A framework or library using MPI.;A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).;A Domain Specific Language (DSL).;Low-level communication layer provided by vendor (Verbs, DCMF, ...).","RPC/Active messages support in MPI RMA (like UPC++ RPC). A public RPC API in RMA could be very useful for graph/combinatorial workloads. ","RPC, reasons mentioned above.","There are no unnecessary features","Yes, compatibility is very important for me.","3"
"2019/02/20 4:08:31 PM AST","Governmental institute","Canada","4","4","C/C++;Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","I read only the chapters of interest for my work.","I read book(s).;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Using MPI","MPICH;Open MPI;Cray MPI;IBM MPI (BG/Q, PE, Spectrum)","I am familiar with it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Performance tuning","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;Persistent communications;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE","Subtleties related to performance, lack of vendor information on environment variables, proprietary communication subsystem  ","Sometimes","No, MPI calls are scattered in my programs.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.;A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).;Low-level communication layer provided by vendor (Verbs, DCMF, ...).","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","client-server connection for coupled application, more versatility in launching multiple applications in parallel than MPMD  ","There are no unnecessary features","I prefer to have new API for better performance.","3"
"2019/02/20 4:12:53 PM AST","College/University","United States","3","4","Fortran (older one than Fortran 90)","more than 10 years","between 5 and 10 years","implementing parallel codes, performance optimization","Research and development of application(s);Performance tuning of MPI program(s)","I have not read it, but I plan to.","I read book(s).;Other lectures or tutorials (workplace, conference).","Using MPI","MVAPICH;Intel MPI","I am familiar with it.","I read book(s) (except the MPI standard).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Implementation issue workaround","Point-to-point communications;Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","Point-to-point communications;Collective communications;MPI with OpenMP (or multithread)","I do not know or I do not care.","In general carefully understanding all the calls and parameters","Sometimes","No, MPI calls are scattered in my programs.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Latency hiding (including asynchronous completion);Resilience (fault tolerance)","all of the above are useful","API should be clearly versioned.","3"
"2019/02/20 4:19:12 PM AST","College/University","Japan","5","4","C/C++","more than 10 years","between 2 and 5 years","System software development (OS, runtime library, communication library, etc.);Tool development (performance tuning, debugging, etc.)","Research and development on system software (OS and/or runtime library)","I read only the chapters of interest for my work.","I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","MPICH;Intel MPI","I am familiar with it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Debugging","Persistent communication;PMPI interface","Point-to-point communications;Collective communications;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED;MPI_THREAD_MULTIPLE","Too complicated and hard to understand.;Difficult to reason performance numbers.","Never","No, my program is too small to do that.","OpenMP;Pthread;CUDA","Yes, but it's an MPI implementation issue.","Low-level communication layer provided by vendor (Verbs, DCMF, ...).","Multi-threading support","Latency hiding (including asynchronous completion);Endpoints (multi-thread, sessions)","Communicator and group management;Process topologies;Dynamic process creation;Error handlers","Yes, compatibility is very important for me.","5"
"2019/02/20 4:38:47 PM AST","College/University","Argentina","5","4","Fortran 90 or newer;Python","more than 10 years","more than 10 years","Parallel language (incl. domain specific language);Numerical application and/or library","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s)","I read most of it.","I read the MPI standard document.;I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Using MPI;MPI: The Complete Reference","MPICH;Open MPI","I am familiar with it.","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Domain decomposition","MPI with OpenMP (or multithread);PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;One-sided communications;Persistent communications","I have never called MPI_INIT_THREAD","No appropriate lecture / book / info.","Always","Yes, to minimize the changes of communication API.","OpenMP","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Bandwidth","MPI is providing all the communication semantics required by my application","There are no unnecessary features","API should be clearly versioned.","3"
"2019/02/20 5:13:47 PM AST","Private research institute","Denmark","5","4","C/C++;Python","more than 10 years","more than 10 years","Numerical application and/or library;Big data;Visualization","Research and development of application(s);Parallelization of sequential program(s)","No, and I will not read it.","I read book(s).;I read articles found on Internet.","MPI: The Complete Reference","MPICH;Open MPI;Intel MPI","I like to use it.","I search the Internet (Google / Stack Overflow).","Algorithm design","Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;Dynamic process creation;MPI with OpenMP (or multithread)","MPI_THREAD_MULTIPLE","Too complicated and hard to understand.","Mostly","Yes, but I have no special reason for doing that.","","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.;A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Resilience (fault tolerance);Another API which is easier and/or simpler to use","There are no unnecessary features","I do not know or I do not care.","4"
"2019/02/20 6:00:51 PM AST","College/University","United States","5","5","C/C++;Python","more than 10 years","more than 10 years","Image processing","Research and development of application(s);Performance tuning of MPI program(s);Debugging MPI programs","I read only the chapters of interest for my work.","I read book(s).","Parallel Programming with MPI;Using MPI","MPICH;MVAPICH","I like to use it.","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Persistent communication","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE","I have nobody to ask.","I rely on the default ‘Errors abort’ error handling","No, MPI calls are scattered in my programs.","OpenMP;Pthread;OpenCL;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","MPI is providing all the communication semantics required by my application","Dynamic process creation","Yes, compatibility is very important for me.","4"
"2019/02/20 8:21:41 PM AST","Governmental institute","United States","6","5","Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s);Performance tuning of MPI program(s);Debugging MPI programs","I read only the chapters of interest for my work.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).","Using MPI;MPI: The Complete Reference","Open MPI;Intel MPI;Cray MPI","I like to use it.","I read the MPI Standard document (web/book).","Debugging","Dynamic process creation;Persistent communication","Point-to-point communications;Collective communications;MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","I have no obstacles.","Mostly","No, MPI calls are scattered in my programs.","OpenMP","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","Dynamic process creation","Yes, compatibility is very important for me.","4"
"2019/02/20 9:03:19 PM AST","College/University","Russia","5","5","C/C++","more than 10 years","more than 10 years","System software development (OS, runtime library, communication library, etc.);Parallel language (incl. domain specific language);Tool development (performance tuning, debugging, etc.)","Research and development on system software (OS and/or runtime library);Research and development software tool(s);Performance tuning of MPI program(s)","","I read the MPI standard document.;I had lecture(s) at school.;I read articles found on Internet.","I have never read any MPI books","MPICH;Open MPI;MVAPICH","I am familiar with it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I know almost all MPI routines.","Debugging","Dynamic process creation","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes","MPI_THREAD_MULTIPLE","I have no obstacles.","Never","No, MPI calls are scattered in my programs.","OpenMP","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Multi-threading support","Latency hiding (including asynchronous completion);Endpoints (multi-thread, sessions);Resilience (fault tolerance);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","Dynamic process creation","I prefer to have new API for better performance.","5"
"2019/02/20 9:10:43 PM AST","Governmental institute","Japan","5","5","C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer","more than 10 years","more than 10 years","Parallel language (incl. domain specific language);Numerical application and/or library","Research and development software tool(s)","I read only the chapters of interest for my work.","I read book(s).","Parallel Programming with MPI","MPICH;Open MPI;MVAPICH;Intel MPI;Fujistu MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation;Persistent communication","Point-to-point communications;Collective communications;MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","Too many routines.","Never","Yes, but I have no special reason for doing that.","OpenMP;OpenACC;CUDA","I have no chance to investigate.","A framework or library using MPI.;A Domain Specific Language (DSL).","Slow initialization","Resilience (fault tolerance)","Datatypes","I prefer to have new API which is simpler and/or easier-to-use.","3"
"2019/02/20 9:16:07 PM AST","Governmental institute","Japan","5","5","Fortran 90 or newer;Python","more than 10 years","more than 10 years","Numerical application and/or library;AI (Deep Learning)","Research and development of application(s)","I have not read it, but I plan to.","I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","MPICH;Open MPI;MVAPICH;Intel MPI","I have no special reason.","I read book(s) (except the MPI standard).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","Persistent communication","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_FUNNELED","When it comes to a development of algorithms, the strategy of parallelism and  data/domain decomposition has a close relationship. This might make it harder to master MPI than other parallel paradigm. ","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","OpenMP","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","I am not investigating any alternatives.","Bandwidth","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","There are no unnecessary features","Yes, compatibility is very important for me.","4"
"2019/02/20 9:34:07 PM AST","College/University","Japan","5","5","C/C++","more than 10 years","more than 10 years","Parallel language (incl. domain specific language);Numerical application and/or library","Research and development of application(s);Research and development software tool(s)","I read most of it.","I read the MPI standard document.","","Intel MPI;Cray MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).","Algorithm design","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_FUNNELED;MPI_THREAD_MULTIPLE","Too many routines.","I rely on the default ‘Errors abort’ error handling","No, MPI calls are scattered in my programs.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","A Domain Specific Language (DSL).","Multi-threading support","Endpoints (multi-thread, sessions);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","Dynamic process creation","I prefer to have new API which is simpler and/or easier-to-use.","4"
"2019/02/20 9:55:23 PM AST","College/University","Japan","4","5","C/C++;Fortran (older one than Fortran 90)","more than 10 years","more than 10 years","System software development (OS, runtime library, communication library, etc.);Parallel language (incl. domain specific language)","Research and development on system software (OS and/or runtime library);Research and development software tool(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I read articles found on Internet.","I have never read any MPI books","MPICH;Open MPI;MVAPICH;Intel MPI","I am familiar with it.","I read the MPI Standard document (web/book).","Performance tuning","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE","Too many routines.","Mostly","No, MPI calls are scattered in my programs.","OpenMP;Pthread;OpenACC;CUDA","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Resilience (fault tolerance)","Dynamic process creation","API should be clearly versioned.","4"
"2019/02/20 10:13:01 PM AST","College/University","Japan","3","3","C/C++","more than 10 years","more than 10 years","System software development (OS, runtime library, communication library, etc.);Big data;Tool development (performance tuning, debugging, etc.)","Research and development on system software (OS and/or runtime library);Manage software at supercomputer center","I read only the chapters of interest for my work.","I read the MPI standard document.;I had lecture(s) at school.","MPI Specification","Open MPI;MVAPICH;Intel MPI;HPE MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).","Debugging","","Collective communications;MPI with OpenMP (or multithread)","MPI_THREAD_FUNNELED;MPI_THREAD_MULTIPLE","Too many routines.;Too complicated and hard to understand.","Sometimes","No, my program is too small to do that.","OpenMP;Pthread;OpenACC;CUDA","I think there is room but I do not know how to tune it.","A Domain Specific Language (DSL).;NCCL","MPI provides all semantics I need","Another API which is easier and/or simpler to use","Process topologies;Error handlers","I prefer to have new API which is simpler and/or easier-to-use.","2"
"2019/02/20 10:29:02 PM AST","College/University","Germany","4","3","C/C++;Bash, sed, Makefile, TeX","more than 10 years","between 2 and 5 years","System software development (OS, runtime library, communication library, etc.);Tool development (performance tuning, debugging, etc.)","Research and development on system software (OS and/or runtime library);Research and development software tool(s);Debugging MPI programs","I read only the chapters of interest for my work.","I read the MPI standard document.;I read articles found on Internet.;Trial & Error :-)","I have never read any MPI books","MPICH;Open MPI;MVAPICH","I was said to use it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;Dynamic process creation;Persistent communication;MPI with OpenMP (or multithread);PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);Persistent communications;PMPI interface","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","I do not like the API.;too many similar functions; sometimes obscure behaviour (e.g. MPI_Startall unable to deal with MPI_REQUEST_NULL among actual request objects)","Mostly","No, MPI calls are scattered in my programs.","No","I have no chance to investigate.","Low-level communication layer provided by vendor (Verbs, DCMF, ...).","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Endpoints (multi-thread, sessions);Resilience (fault tolerance);Another API which is easier and/or simpler to use","One-sided communication;Dynamic process creation;Error handlers","API should be clearly versioned.","3"
"2019/02/21 12:29:45 AM AST","College/University","Russia","3","3","C/C++","between 2 and 5 years","between 2 and 5 years","System software development (OS, runtime library, communication library, etc.)","Research and development of application(s);Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).","Parallel Programming in C with MPI and OpenMP","MPICH;Open MPI;MVAPICH","I like to use it.","I read the MPI Standard document (web/book).","Domain decomposition","Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_MULTIPLE","I have no obstacles.","Always","Yes, to minimize the changes of communication API.","OpenMP","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","There are no unnecessary features","Yes, compatibility is very important for me.","4"
"2019/02/21 1:08:10 AM AST","College/University","Japan","5","4","C/C++;Java;Python","more than 10 years","more than 10 years","Parallel language (incl. domain specific language);AI (Deep Learning)","Research and development software tool(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).","Using MPI","MPICH;Open MPI","I have no special reason.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Performance tuning","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;One-sided communications","I have never called MPI_INIT_THREAD","I have no obstacles.","Sometimes","No, my program is too small to do that.","No","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.;A Domain Specific Language (DSL).","Latency","Latency hiding (including asynchronous completion)","Communicator and group management;Process topologies;Dynamic process creation","Yes, compatibility is very important for me.","2"
"2019/02/21 3:00:30 AM AST","College/University","Russia","3","3","C/C++;Python","less than 2 years","less than 2 years","Tool development (performance tuning, debugging, etc.)","Research and development software tool(s)","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).","I have never read any MPI books","MPICH;Open MPI;MVAPICH","I have no special reason.","I ask colleagues.","Domain decomposition","Point-to-point communications;Collective communications;MPI datatypes;One-sided communications","Point-to-point communications;Collective communications;One-sided communications","I have never called MPI_INIT_THREAD","Too complicated and hard to understand.","","Yes, to minimize the changes of communication API.","OpenMP","I think there is room but I do not know how to tune it.","A Domain Specific Language (DSL).","Bandwidth","Endpoints (multi-thread, sessions)","One-sided communication;Datatypes;Communicator and group management;Collective operations","Yes, compatibility is very important for me.","3"
"2019/02/21 3:50:53 AM AST","College/University","Sweden","5","5","C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer;Python","more than 10 years","more than 10 years","Parallel language (incl. domain specific language);Numerical application and/or library","Research and development of application(s);Parallelization of sequential program(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Parallel Programming with MPI;Using MPI;MPI: The Complete Reference","MPICH;Open MPI;Intel MPI;Cray MPI;IBM MPI (BG/Q, PE, Spectrum)","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).","Performance tuning","Dynamic process creation;Persistent communication","Point-to-point communications;Collective communications;MPI datatypes","I have never called MPI_INIT_THREAD","Too many routines.","Sometimes","Yes, to minimize the changes of communication API.","OpenACC;CUDA","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Latency","Latency hiding (including asynchronous completion)","There are no unnecessary features","Yes, compatibility is very important for me.","4"
"2019/02/21 3:56:10 AM AST","College/University","United Kingdom","6","4","C/C++","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s);Performance tuning of MPI program(s);Debugging MPI programs","I read only the chapters of interest for my work.","I read book(s).;I read articles found on Internet.","I have never read any MPI books","Open MPI;Intel MPI","I have no special reason.","I read the MPI Standard document (web/book).;I search the Internet (Google / Stack Overflow).","Performance tuning","Dynamic process creation;Persistent communication","Point-to-point communications;Collective communications;MPI datatypes","I have never called MPI_INIT_THREAD","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","Communicator and group management;Process topologies;Dynamic process creation","Yes, compatibility is very important for me.","4"
"2019/02/21 4:20:55 AM AST","Governmental institute","Germany","4","4","Python","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of parallel numerical software","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).;I read articles found on Internet.;Learning by doing","I have never read any MPI books","MPICH;Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Algorithm design","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD;I do not know or I do not care.","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","OpenMP;Pthread","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Latency hiding (including asynchronous completion);Resilience (fault tolerance)","There are no unnecessary features","API should be clearly versioned.","2"
"2019/02/21 5:46:57 AM AST","College/University","Japan","4","3","C/C++","more than 10 years","between 5 and 10 years","System software development (OS, runtime library, communication library, etc.);Microarchitecture","Research and development on system software (OS and/or runtime library);Research and development on Microarchitecture","I read only the chapters of interest for my work.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","I have never read any MPI books","MPICH;Open MPI;Fujistu MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Finding appropriate MPI routines","PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED;MPI_THREAD_SERIALIZED;MPI_THREAD_MULTIPLE","Too many routines.","Mostly","Yes, but I have no special reason for doing that.","OpenMP","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A framework or library using MPI.","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","Error handlers","I prefer to have new API which is simpler and/or easier-to-use.","2"
"2019/02/21 5:58:56 AM AST","College/University","Pakistan","5","5","C/C++;Python","more than 10 years","between 5 and 10 years","System software development (OS, runtime library, communication library, etc.);Parallel language (incl. domain specific language);Big data;Tool development (performance tuning, debugging, etc.)","Research and development of application(s);Research and development on system software (OS and/or runtime library);Research and development software tool(s);Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","I read all.","I read the MPI standard document.;I read book(s).;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Beginning MPI (An Introduction in C);Parallel Programming with MPI;Using MPI;Parallel Programming in C with MPI and OpenMP","MPICH;Open MPI;Intel MPI","I like to use it.","I know almost all MPI routines.","Debugging","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;Dynamic process creation;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED;MPI_THREAD_SERIALIZED;MPI_THREAD_MULTIPLE","I have no obstacles.","Mostly","No, MPI calls are scattered in my programs.","OpenMP;CUDA","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A framework or library using MPI.","Bandwidth","Resilience (fault tolerance)","There are no unnecessary features","Yes, compatibility is very important for me.","3"
"2019/02/21 6:01:25 AM AST","Governmental institute","France","5","5","Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","I have not read it, but I plan to.","I read book(s).;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Using MPI","Open MPI;Intel MPI","I like to use it.","I read book(s) (except the MPI standard).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications","I have never called MPI_INIT_THREAD","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","No, MPI calls are scattered in my programs.","No","Yes, I know there is room for tuning but I do not have enough resources to do that.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","Dynamic process creation","I prefer to have new API for better performance.","4"
"2019/02/21 8:39:31 AM AST","College/University","Japan","5","5","C/C++","more than 10 years","more than 10 years","System software development (OS, runtime library, communication library, etc.);Numerical application and/or library;Visualization","Research and development of application(s);Research and development on system software (OS and/or runtime library)","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","I have never read any MPI books","MPICH;Open MPI;Intel MPI;Cray MPI","I am familiar with it.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Implementation issue workaround","Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Dynamic process creation;MPI with OpenMP (or multithread)","MPI_THREAD_MULTIPLE","Many implementations.","Sometimes","No, MPI calls are scattered in my programs.","OpenMP;Pthread;OpenACC;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.","Fault Tolerancy","Resilience (fault tolerance)","Dynamic process creation","Yes, compatibility is very important for me.","4"
"2019/02/21 9:27:35 AM AST","College/University","Russia","5","5","C/C++","more than 10 years","between 2 and 5 years","System software development (OS, runtime library, communication library, etc.);Tool development (performance tuning, debugging, etc.)","Research and development on system software (OS and/or runtime library);Research and development software tool(s);Performance tuning of MPI program(s)","I read all.","I read the MPI standard document.;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","I have never read any MPI books","MPICH;Open MPI;MVAPICH","I have no special reason.","I read online documents (such as man pages).","Debugging","Persistent communication","Point-to-point communications;Collective communications;One-sided communications;PMPI interface","I have never called MPI_INIT_THREAD","Too many routines.;Too complicated and hard to understand.;I do not like the API.","Sometimes","No, MPI calls are scattered in my programs.","OpenMP","No, my MPI programs are well-tuned.","I am not investigating any alternatives.","Latency","Another API which is easier and/or simpler to use","Dynamic process creation","I prefer to have new API which is simpler and/or easier-to-use.","5"
"2019/02/21 10:59:43 AM AST","College/University","Austria","5","6","C/C++","more than 10 years","more than 10 years","Parallel language (incl. domain specific language);Algorithms","Research and development on system software (OS and/or runtime library);Parallelization of sequential program(s)","I read all.","I read the MPI standard document.;I read book(s).","Parallel Programming with MPI;Using MPI;Parallel Programming in C with MPI and OpenMP;MPI: The Complete Reference","MPICH;Open MPI;Intel MPI;Cray MPI;NEC MPI","I like to use it.","I read the MPI Standard document (web/book).;I know almost all MPI routines.","Performance tuning","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;Persistent communications;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED;MPI_THREAD_SERIALIZED;MPI_THREAD_MULTIPLE","Too many routines.","Sometimes","No, my program is too small to do that.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Multi-threading support","Latency hiding (including asynchronous completion);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","There are no unnecessary features","I prefer to have new API which is simpler and/or easier-to-use.","5"
"2019/02/21 11:19:17 AM AST","College/University","United States","4","4","C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library;Big data;Workflow and/or In-situ","Debugging MPI programs","I have not read it, but I plan to.","Other lectures or tutorials (workplace, conference).","I have never read any MPI books","Open MPI;MVAPICH;Intel MPI","I am familiar with it.","I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Debugging","","Point-to-point communications;Collective communications;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_MULTIPLE","Too many routines.","Sometimes","Yes, to minimize the changes of communication API.","OpenMP","No, my MPI programs are well-tuned.","Low-level communication layer provided by vendor (Verbs, DCMF, ...).","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Resilience (fault tolerance);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","","Yes, compatibility is very important for me.","3"
"2019/02/21 11:23:15 AM AST","Software vendor","United States","6","6","C/C++;Python;BASH, Perl","more than 10 years","more than 10 years","System software development (OS, runtime library, communication library, etc.)","Research and development on system software (OS and/or runtime library);Research and development software tool(s);Performance tuning of MPI program(s)","I read most of it.","I read book(s).;I had lecture(s) at school.","Using MPI;MPI: The Complete Reference","MPICH;Open MPI;IBM MPI (BG/Q, PE, Spectrum)","I like to use it.","I read online documents (such as man pages).","Debugging","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;PMPI interface","MPI_THREAD_SINGLE","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","No, MPI calls are scattered in my programs.","OpenMP;Pthread;CUDA","I have no chance to investigate.","I am not investigating any alternatives.","MPI provides all semantics I need","Resilience (fault tolerance)","There are no unnecessary features","Yes, compatibility is very important for me.","3"
"2019/02/21 3:02:23 PM AST","Governmental institute","Poland","5","5","C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library","Research and development software tool(s);Parallelization of sequential program(s)","I read most of it.","I read the MPI standard document.;I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","Parallel Programming with MPI;Using MPI","MPICH;Open MPI;Intel MPI","I have no special reason.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Domain decomposition","PMPI interface","Point-to-point communications;Collective communications;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_SERIALIZED","I have no obstacles.","Mostly","Yes, but I have no special reason for doing that.","OpenMP;Pthread","No, my MPI programs are well-tuned.","A framework or library using MPI.;A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Multi-threading support","MPI is providing all the communication semantics required by my application","There are no unnecessary features","Yes, compatibility is very important for me.","4"
"2019/02/21 4:21:05 PM AST","College/University","Netherlands","5","4","Fortran 90 or newer;Julia","between 5 and 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s)","No, and I will not read it.","I read articles found on Internet.;colleagues","","Open MPI;MVAPICH;Cray MPI","I like to use it.","I read online documents (such as man pages).","Debugging","Dynamic process creation","Collective communications;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_MULTIPLE","I have no obstacles.","Mostly","No, MPI calls are scattered in my programs.","OpenMP","No, my MPI programs are well-tuned.","I am not investigating any alternatives.","Multi-threading support","","Collective operations","Yes, compatibility is very important for me.","3"
"2019/02/22 12:23:59 AM AST","College/University","Japan","4","5","C/C++;Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library","Parallelization of sequential program(s);Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","I read book(s).;Other lectures or tutorials (workplace, conference).","Parallel Programming with MPI;Using MPI","Intel MPI;Fujistu MPI","I like to use it.","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).","Debugging","PMPI interface","Collective communications","I have never called MPI_INIT_THREAD","Too many routines.","Never","No, my program is too small to do that.","OpenMP","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A framework or library using MPI.","Latency","Latency hiding (including asynchronous completion)","Communicator and group management","API should be clearly versioned.","5"
"2019/02/22 12:45:09 AM AST","College/University","Japan","6","4","Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s);Parallelization of sequential program(s)","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","I have never read any MPI books","MPICH;Open MPI;Intel MPI;Fujistu MPI","I could not have any choice (the one provided by a vendor).","I search the Internet (Google / Stack Overflow).","Finding appropriate MPI routines","Point-to-point communications;Dynamic process creation;Persistent communication;PMPI interface","Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD;I do not know or I do not care.","Too many routines.;No appropriate lecture / book / info.","Never","Yes, but I have no special reason for doing that.","OpenMP","I think there is room but I do not know how to tune it.","I am not investigating any alternatives.","Multi-threading support","Endpoints (multi-thread, sessions)","One-sided communication;Dynamic process creation","I prefer to have new API which is simpler and/or easier-to-use.","3"
"2019/02/22 4:30:52 AM AST","Governmental institute","Japan","5","5","C/C++;Java;Python","more than 10 years","between 5 and 10 years","System software development (OS, runtime library, communication library, etc.);Parallel language (incl. domain specific language);Numerical application and/or library;Tool development (performance tuning, debugging, etc.)","Research and development on system software (OS and/or runtime library);Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","I read book(s).;Other lectures or tutorials (workplace, conference).","Parallel Programming with MPI;Using MPI","MPICH;Open MPI;Intel MPI;NEC MPI","I have no special reason.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Communicator operations (split, duplicate, and so on);Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","I have no obstacles.","Mostly","Yes, but I have no special reason for doing that.","OpenMP;Pthread;OpenACC;OpenCL;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.;A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Resilience (fault tolerance);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","There are no unnecessary features","I prefer to have new API which is simpler and/or easier-to-use.","2"
"2019/02/22 10:09:31 PM AST","Hardware vendor","United States","6","5","C/C++;Python;Shell","more than 10 years","between 5 and 10 years","System software development (OS, runtime library, communication library, etc.)","Research and development on system software (OS and/or runtime library);Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;web","I have never read any MPI books","MPICH;Open MPI;Intel MPI","I was said to use it.","I read the MPI Standard document (web/book).;I search the Internet (Google / Stack Overflow).","Algorithm design","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;Persistent communications;MPI with OpenMP (or multithread);PMPI interface","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED;MPI_THREAD_MULTIPLE","Poor integration with threading libraries, slow adoption to new technologies","Never","Yes, to minimize the changes of communication API.","OpenMP;Pthread;CUDA","","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Multi-threading support + Batching sends for better message injection rate","Endpoints (multi-thread, sessions);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","Dynamic process creation","I prefer to have new API for better performance.","5"
"2019/02/23 1:35:36 PM AST","Hardware vendor","Russia","6","5","C/C++;Python","more than 10 years","between 5 and 10 years","System software development (OS, runtime library, communication library, etc.);Numerical application and/or library","Research and development on system software (OS and/or runtime library);Performance tuning of MPI program(s)","I read most of it.","I read the MPI standard document.;I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Using MPI","Open MPI;Intel MPI;MS MPI","I have no special reason.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I ask colleagues.","Debugging","PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;Persistent communications","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","I have nobody to ask.","Mostly","No, MPI calls are scattered in my programs.","OpenMP;Pthread;CUDA","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","I am not investigating any alternatives.","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","MPI is providing all the communication semantics required by my application","Datatypes;Process topologies","I prefer to have new API for better performance.","4"
"2019/02/24 8:07:09 PM AST","College/University","Germany","5","5","C/C++;Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library","Research and development software tool(s);Parallelization of sequential program(s)","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","I have never read any MPI books","MPICH;Open MPI;MVAPICH;Cray MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","Persistent communication;PMPI interface","Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","No appropriate lecture / book / info.","Mostly","Yes, to minimize the changes of communication API.","OpenMP;Pthread;CUDA","it depends, I have many projects","I am not investigating any alternatives.","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Latency hiding (including asynchronous completion);Resilience (fault tolerance)","There are no unnecessary features","compatibility for a typical ""PhD completion"" window is a must","4"
"2019/02/24 9:47:56 PM AST","College/University","Japan","5","4","C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer","more than 10 years","more than 10 years","Parallel language (incl. domain specific language);Numerical application and/or library;Tool development (performance tuning, debugging, etc.)","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","I have never read any MPI books","Open MPI;MVAPICH;Intel MPI","I like to use it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Performance tuning","","Point-to-point communications;Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_FUNNELED","Too many routines.","Sometimes","No, my program is too small to do that.","OpenMP;OpenACC;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.","Latency","MPI is providing all the communication semantics required by my application","Communicator and group management;Dynamic process creation","API should be clearly versioned.","4"
"2019/02/24 11:32:08 PM AST","Other","Russia","4","4","C/C++;Fortran 90 or newer;Python","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s)","I read most of it.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).","Using MPI","Open MPI","I am familiar with it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","","Point-to-point communications;Collective communications;MPI datatypes","I have never called MPI_INIT_THREAD","I have no obstacles.","Sometimes","No, MPI calls are scattered in my programs.","OpenMP;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","MPI provides all semantics I need","Debugging capabilities, i.e. message sequence traces, type matching, etc.","","I do not know or I do not care.","3"
"2019/02/25 2:41:21 AM AST","College/University","Germany","5","4","C/C++","between 5 and 10 years","between 2 and 5 years","Parallel language (incl. domain specific language);Numerical application and/or library","Research and development of application(s);Research and development software tool(s);Parallelization of sequential program(s)","I read only the chapters of interest for my work.","I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","MPICH;Open MPI;MVAPICH","I am familiar with it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes","MPI_THREAD_SINGLE","I have no obstacles.","Sometimes","Yes, to minimize the changes of communication API.","OpenMP;CUDA","No, my MPI programs are well-tuned.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","There are no unnecessary features","Yes, compatibility is very important for me.","5"
"2019/02/25 3:37:03 AM AST","College/University","Russia","4","5","C/C++;Fortran (older one than Fortran 90)","more than 10 years","more than 10 years","information structure analysis","Research and development software tool(s);Performance tuning of MPI program(s)","I read most of it.","I read the MPI standard document.;I read book(s).;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Using MPI","MPICH;Open MPI;MVAPICH;Intel MPI;IBM MPI (BG/Q, PE, Spectrum)","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).;I search the Internet (Google / Stack Overflow).","Debugging","","Point-to-point communications;Collective communications;MPI datatypes;Persistent communications;PMPI interface","I have never called MPI_INIT_THREAD","I have no obstacles.","Sometimes","No, my program is too small to do that.","OpenMP","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A framework or library using MPI.","MPI provides all semantics I need","Latency hiding (including asynchronous completion);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","One-sided communication;Dynamic process creation","Yes, compatibility is very important for me.","4"
"2019/02/25 5:56:28 AM AST","College/University","Germany","5","4","C/C++;Python","more than 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s);Parallelization of sequential program(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).;I read articles found on Internet.","Using MPI","Open MPI;MVAPICH","I like to use it.","I read the MPI Standard document (web/book).","Debugging","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);Persistent communications","I have never called MPI_INIT_THREAD","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","No, my program is too small to do that.","OpenMP;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","One-sided communication;Datatypes","API should be clearly versioned.","4"
"2019/02/25 7:39:03 AM AST","College/University","Germany","5","3","C/C++;Python","between 2 and 5 years","less than 2 years","Numerical application and/or library","Performance tuning of MPI program(s);Fault-tolerance for future HPC systems","","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","I have never read any MPI books","MPICH;Open MPI","I have no special reason.","I ask colleagues.;I search the Internet (Google / Stack Overflow).","Other","Dynamic process creation","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;PMPI interface","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","I have nobody to ask.","Mostly","Yes, to minimize the changes of communication API.","OpenMP;TBB","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Resilience (fault tolerance)","There are no unnecessary features","API should be clearly versioned.","2"
"2019/02/25 9:56:33 AM AST","College/University","United Kingdom","4","2","C/C++;Python","more than 10 years","between 2 and 5 years","System software development (OS, runtime library, communication library, etc.)","Research and development of application(s);Research and development on system software (OS and/or runtime library);Research and development software tool(s)","I read all.","I read the MPI standard document.;I read book(s).;I read articles found on Internet.","Using MPI;MPI: The Complete Reference","MPICH;Open MPI;MS MPI","I am familiar with it.","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Implementation issue workaround","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);Dynamic process creation;Persistent communications;PMPI interface","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","Discrepancies between specification and real implementations/implementation quirks;unpredictable interactions between application and MPI implementation behaviour","Sometimes","Yes, to minimize the changes of communication API.","Pthread","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A Domain Specific Language (DSL).;Low-level communication layer provided by vendor (Verbs, DCMF, ...).","Multi-threading support","Latency hiding (including asynchronous completion);Endpoints (multi-thread, sessions);Multiplatform support - this is technically not the specification, but the implementations, most of which are becoming VERY single-platform","One-sided communication;Process topologies","Yes, compatibility is very important for me.","1"
"2019/02/26 12:31:51 AM AST","Governmental institute","Russia","4","4","C/C++;Java","more than 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s);Parallelization of sequential program(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).","В.В.Воеводин Вл.В.Воеводин Параллельные вычисления","MPICH;Open MPI;Intel MPI","I have no special reason.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).","Algorithm design","PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","Too many routines.","Sometimes","Yes, to minimize the changes of communication API.","OpenMP","I think there is room but I do not know how to tune it.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","There are no unnecessary features","I do not know or I do not care.","4"
"2019/02/26 2:54:55 AM AST","Software vendor","Russia","5","3","C/C++;Bash, Lua, Ruby","more than 10 years","between 2 and 5 years","System software development (OS, runtime library, communication library, etc.);Numerical application and/or library","Research and development of application(s);Research and development on system software (OS and/or runtime library)","I read only the chapters of interest for my work.","I had lecture(s) at school.;I read articles found on Internet.","I have never read any MPI books","Open MPI;Intel MPI","I was said to use it.","I ask colleagues.;I search the Internet (Google / Stack Overflow).","Performance tuning","Persistent communication;PMPI interface","no one","I do not know or I do not care.","","Never","No, MPI calls are scattered in my programs.","No","I do not know if there is room for performance tuning.","I am not investigating any alternatives.","","","","",""
"2019/02/26 2:55:49 AM AST","College/University","Russia","3","3","C/C++;Python","between 5 and 10 years","between 5 and 10 years","System software development (OS, runtime library, communication library, etc.);Big data;Tool development (performance tuning, debugging, etc.);machine learning","Research and development software tool(s);Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","I read only the chapters of interest for my work.","I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","","Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read book(s) (except the MPI standard).;I search the Internet (Google / Stack Overflow).","Performance tuning","Communicator operations (split, duplicate, and so on);One-sided communications;Dynamic process creation;Persistent communication","Point-to-point communications;Collective communications;MPI datatypes;PMPI interface","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED;MPI_THREAD_MULTIPLE","Too complicated and hard to understand.","Sometimes","No, my program is too small to do that.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Resilience (fault tolerance);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.);Another API which is easier and/or simpler to use","Datatypes;Communicator and group management","I prefer to have new API which is simpler and/or easier-to-use.","4"
"2019/02/26 2:57:48 AM AST","College/University","Russia","5","2","Fortran (older one than Fortran 90);Fortran 90 or newer;Python","more than 10 years","between 2 and 5 years","Numerical application and/or library;Workflow and/or In-situ;Visualization","Research and development of application(s);Research and development software tool(s)","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Parallel Programming in C with MPI and OpenMP","MPICH","I have no special reason.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","MPI datatypes","","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","Too complicated and hard to understand.;I do not like the API.","","Yes, to minimize the changes of communication API.","No","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","","","","","5"
"2019/02/26 2:59:47 AM AST","Governmental institute","Russia","4","4","C/C++;Fortran 90 or newer","more than 10 years","between 5 and 10 years","Numerical application and/or library","Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","","I read the MPI standard document.;I had lecture(s) at school.;I read articles found on Internet.","I have never read any MPI books","MPICH;Open MPI;MVAPICH;Intel MPI","I have no special reason.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).;I know almost all MPI routines.","Algorithm design","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED;MPI_THREAD_MULTIPLE","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","No, MPI calls are scattered in my programs.","OpenMP;Pthread;CUDA","No, my MPI programs are well-tuned.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","One-sided communication;Process topologies;Dynamic process creation","Yes, compatibility is very important for me.","5"
"2019/02/26 3:00:57 AM AST","Governmental institute","Russia","4","3","C/C++;Python","more than 10 years","less than 2 years","Big data;Visualization","Parallelization of sequential program(s);Debugging MPI programs","I read only the chapters of interest for my work.","I read articles found on Internet.","Beginning MPI (An Introduction in C)","Open MPI;Intel MPI","","I read online documents (such as man pages).","Finding appropriate MPI routines","MPI datatypes;PMPI interface","Communicator operations (split, duplicate, and so on)","MPI_THREAD_SERIALIZED","No appropriate lecture / book / info.","Mostly","No, MPI calls are scattered in my programs.","CUDA","I have no chance to investigate.","A framework or library using MPI.","Latency","Resilience (fault tolerance)","Dynamic process creation","I prefer to have new API for better performance.","4"
"2019/02/26 3:04:52 AM AST","College/University","Russia","4","4","C/C++","more than 10 years","between 5 and 10 years","scientific research","astrophysical codes","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).","Voevodin et al. Parallel programming","MPICH;Open MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","One-sided communications;Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes","I have never called MPI_INIT_THREAD","I have no obstacles.","Sometimes","No, MPI calls are scattered in my programs.","No","I do not have (know) tools to find performance bottlenecks.","I am not investigating any alternatives.","Bandwidth","MPI is providing all the communication semantics required by my application","One-sided communication;Process topologies;Dynamic process creation;Error handlers","Yes, compatibility is very important for me.","4"
"2019/02/26 3:05:19 AM AST","College/University","Russia","5","4","C/C++;Python","between 2 and 5 years","between 2 and 5 years","System software development (OS, runtime library, communication library, etc.);Parallel language (incl. domain specific language);AI (Deep Learning)","Research and development of application(s);Research and development software tool(s);Performance tuning of MPI program(s)","I read most of it.","I read book(s).;I had lecture(s) at school.","Using MPI;Parallel Programming in C with MPI and OpenMP","MPICH;Open MPI;Intel MPI;IBM MPI (BG/Q, PE, Spectrum);MS MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).","Finding appropriate MPI routines","Dynamic process creation;Persistent communication","","MPI_THREAD_SINGLE;MPI_THREAD_SERIALIZED;MPI_THREAD_MULTIPLE","Too many routines.;Too complicated and hard to understand.;I do not like the API.","Mostly","Yes, to minimize the changes of communication API.","OpenMP;OpenCL;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.;A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).;A Domain Specific Language (DSL).","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","MPI is providing all the communication semantics required by my application","There are no unnecessary features","API should be clearly versioned.","3"
"2019/02/26 3:10:15 AM AST","Software vendor","Russia","4","4","C/C++;Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I read articles found on Internet.","","Open MPI","I like to use it.","I read the MPI Standard document (web/book).","Other","PMPI interface","MPI with OpenMP (or multithread)","I do not know or I do not care.","I have nobody to ask.","Sometimes","Yes, but I have no special reason for doing that.","OpenMP;CUDA","I think there is room but I do not know how to tune it.","A framework or library using MPI.","Multi-threading support","Another API which is easier and/or simpler to use","Dynamic process creation","API should be clearly versioned.","4"
"2019/02/26 3:11:01 AM AST","Software vendor","Russia","5","5","C/C++;Python","more than 10 years","between 2 and 5 years","System software development (OS, runtime library, communication library, etc.);Parallel language (incl. domain specific language);Numerical application and/or library;Visualization;Tool development (performance tuning, debugging, etc.)","Research and development of application(s);Research and development software tool(s);Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","I read only the chapters of interest for my work.","I read book(s).;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Russian books","Open MPI","I like to use it.","I read book(s) (except the MPI standard).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Debugging","PMPI interface","Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD;I do not know or I do not care.","","Never","No, MPI calls are scattered in my programs.","OpenMP;CUDA","No, my MPI programs are well-tuned.","I am not investigating any alternatives.","Latency","Latency hiding (including asynchronous completion)","One-sided communication;Dynamic process creation;Error handlers","Yes, compatibility is very important for me.","5"
"2019/02/26 3:12:24 AM AST","College/University","Russia","4","3","Fortran 90 or newer;Pascal/Delphi","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","MPICH;Open MPI","I have no special reason.","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).;I read online documents (such as man pages).","Debugging","PMPI interface","Point-to-point communications;Collective communications","I do not know or I do not care.","I have no obstacles.","Sometimes","No, my program is too small to do that.","OpenMP","No, my MPI programs are well-tuned.","I am not investigating any alternatives.","Multi-threading support","MPI is providing all the communication semantics required by my application","There are no unnecessary features","Yes, compatibility is very important for me.","3"
"2019/02/26 3:15:05 AM AST","College/University","Russia","3","2","C/C++;Python","between 2 and 5 years","between 2 and 5 years","Scientific computing","Research and development of application(s)","I have not read it, but I plan to.","Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","Open MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Performance tuning","Communicator operations (split, duplicate, and so on)","Communicator operations (split, duplicate, and so on)","I do not know or I do not care.","No appropriate lecture / book / info.;I have nobody to ask.","Never","No, my program is too small to do that.","No","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Another API which is easier and/or simpler to use","There are no unnecessary features","API should be clearly versioned.","2"
"2019/02/26 3:17:56 AM AST","College/University","Russia","6","4","C/C++;Python","more than 10 years","between 5 and 10 years","Parallel language (incl. domain specific language);High-performance simulations in applied science","Research and development of application(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","MPI: The Complete Reference","Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Domain decomposition","Dynamic process creation;PMPI interface","Point-to-point communications;MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED","Too many routines.","Mostly","Yes, to minimize the changes of communication API.","OpenMP","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","Process topologies;Dynamic process creation","API should be clearly versioned.","2"
"2019/02/26 3:18:28 AM AST","College/University","Russia","4","6","C/C++","more than 10 years","between 5 and 10 years","System software development (OS, runtime library, communication library, etc.);Parallel language (incl. domain specific language)","Research and development on system software (OS and/or runtime library);Research and development software tool(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Using MPI;Parallel Programming in C with MPI and OpenMP","MPICH;Open MPI","I like to use it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread);PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);One-sided communications;MPI with OpenMP (or multithread);PMPI interface","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","No appropriate lecture / book / info.","Never","No, my program is too small to do that.","Pthread","No, my MPI programs are well-tuned.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Multi-threading support","Endpoints (multi-thread, sessions);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","Datatypes;Communicator and group management;Dynamic process creation","I prefer to have new API which is simpler and/or easier-to-use.","4"
"2019/02/26 3:21:26 AM AST","College/University","Russia","6","4","C/C++;Python","less than 2 years","less than 2 years","AI (Deep Learning);Image processing","Research and development of application(s);Research and development software tool(s)","I read most of it.","I read the MPI standard document.","I have never read any MPI books","Intel MPI","I like to use it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).","Debugging","Dynamic process creation;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","Too many routines.","Never","No, my program is too small to do that.","OpenMP;CUDA","I think there is room but I do not know how to tune it.","A framework or library using MPI.","Latency","Latency hiding (including asynchronous completion)","","I prefer to have new API which is simpler and/or easier-to-use.","5"
"2019/02/26 3:27:34 AM AST","Governmental institute","Russia","3","1","C/C++;Python","less than 2 years","less than 2 years","AI (Deep Learning);Big data","Research and development of application(s)","I have not read it, but I plan to.","I had lecture(s) at school.","I have never read any MPI books","MPICH;Intel MPI","I like to use it.","I read the MPI Standard document (web/book).","Performance tuning","One-sided communications;Dynamic process creation;Persistent communication;MPI with OpenMP (or multithread);PMPI interface","MPI with OpenMP (or multithread)","MPI_THREAD_SERIALIZED","No appropriate lecture / book / info.","Sometimes","Yes, to minimize the changes of communication API.","CUDA","No, my MPI programs are well-tuned.","A framework or library using MPI.;A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Bandwidth","Latency hiding (including asynchronous completion)","One-sided communication","Yes, compatibility is very important for me.","2"
"2019/02/26 3:29:03 AM AST","Governmental institute","Russia","4","3","C/C++;Python;CUDA","between 5 and 10 years","between 5 and 10 years","Numerical application and/or library;plasma simulations","Research and development of application(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).","I have never read any MPI books","Open MPI","I have no special reason.","I read online documents (such as man pages).","Domain decomposition","Communicator operations (split, duplicate, and so on);Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","I have nobody to ask.","Never","No, MPI calls are scattered in my programs.","OpenMP;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Latency","MPI is providing all the communication semantics required by my application","Dynamic process creation","I prefer to have new API which is simpler and/or easier-to-use.","5"
"2019/02/26 3:30:34 AM AST","College/University","Russia","5","5","C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer","between 2 and 5 years","less than 2 years","Numerical application and/or library","Research and development of application(s);Parallelization of sequential program(s)","I read most of it.","I read the MPI standard document.;I had lecture(s) at school.;I read articles found on Internet.","I have never read any MPI books","Open MPI","I like to use it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Algorithm design","Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;Dynamic process creation","I have never called MPI_INIT_THREAD","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","No, my program is too small to do that.","No","No, my MPI programs are well-tuned.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","There are no unnecessary features","I do not know or I do not care.","3"
"2019/02/26 3:30:38 AM AST","College/University","Russia","5","5","C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer","between 2 and 5 years","less than 2 years","Numerical application and/or library","Research and development of application(s);Parallelization of sequential program(s)","I read most of it.","I read the MPI standard document.;I had lecture(s) at school.;I read articles found on Internet.","I have never read any MPI books","Open MPI","I like to use it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Algorithm design","Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;Dynamic process creation","I have never called MPI_INIT_THREAD","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","No, my program is too small to do that.","No","No, my MPI programs are well-tuned.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","There are no unnecessary features","I do not know or I do not care.","3"
"2019/02/26 3:39:05 AM AST","Governmental institute","Russia","6","4","C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer","more than 10 years","between 2 and 5 years","Numerical application and/or library","Research and development of application(s)","I have not read it, but I plan to.","I read book(s).;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","MPICH;Intel MPI","I have no special reason.","I read book(s) (except the MPI standard).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Algorithm design","Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","I do not know or I do not care.","I have no obstacles.","Mostly","No, MPI calls are scattered in my programs.","OpenMP","No, my MPI programs are well-tuned.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","","MPI is providing all the communication semantics required by my application","","I do not know or I do not care.","4"
"2019/02/26 3:39:34 AM AST","Governmental institute","Russia","4","4","Fortran (older one than Fortran 90);Fortran 90 or newer;Python","more than 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I had lecture(s) at school.;I read articles found on Internet.","","MPICH;Intel MPI;Cray MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD;I do not know or I do not care.","I have no obstacles.","Sometimes","Yes, to minimize the changes of communication API.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","A Domain Specific Language (DSL).","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","There are no unnecessary features","Yes, compatibility is very important for me.","4"
"2019/02/26 3:42:02 AM AST","College/University","Russia","6","6","C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I read book(s).","Parallel Programming with MPI;Parallel Programming in C with MPI and OpenMP","MPICH;Open MPI;Intel MPI","I have no special reason.","I read the MPI Standard document (web/book).","Domain decomposition","Collective communications","Point-to-point communications;Communicator operations (split, duplicate, and so on)","MPI_THREAD_MULTIPLE","Too complicated and hard to understand.","","Yes, to minimize the changes of communication API.","OpenMP","I think there is room but I do not know how to tune it.","A framework or library using MPI.","Multi-threading support","MPI is providing all the communication semantics required by my application","Dynamic process creation","I prefer to have new API which is simpler and/or easier-to-use.","4"
"2019/02/26 3:44:19 AM AST","Governmental institute","Russia","5","4","C/C++;Python","more than 10 years","less than 2 years","Numerical application and/or library","Research and development of application(s)","No, and I will not read it.","Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","Open MPI;Intel MPI;MS MPI","I have no special reason.","I read book(s) (except the MPI standard).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Domain decomposition","Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes","I have never called MPI_INIT_THREAD","GPU programming becomes too complicated","Sometimes","Yes, to minimize the changes of communication API.","OpenMP;OpenCL;CUDA","I do not have (know) tools to find performance bottlenecks.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Resilience (fault tolerance);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.);Another API which is easier and/or simpler to use","There are no unnecessary features","I prefer to have new API which is simpler and/or easier-to-use.","3"
"2019/02/26 3:46:13 AM AST","College/University","Russia","2","2","C/C++;Java","between 5 and 10 years","less than 2 years","Numerical application and/or library","Parallelization of sequential program(s)","No, and I will not read it.","I read articles found on Internet.","","MPICH;Open MPI;Intel MPI","I have no special reason.","I ask colleagues.","Domain decomposition","PMPI interface","Point-to-point communications;Collective communications","I do not know or I do not care.","Too complicated and hard to understand.","","","","","","","","","","5"
"2019/02/26 3:54:58 AM AST","College/University","Russia","4","5","Fortran 90 or newer","more than 10 years","more than 10 years","Image processing;Big data","Research and development of application(s);Parallelization of sequential program(s)","I read only the chapters of interest for my work.","I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","I have never read any MPI books","Intel MPI","I am familiar with it.","I search the Internet (Google / Stack Overflow).","Performance tuning","One-sided communications;Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications","I have never called MPI_INIT_THREAD","I have nobody to ask.","Sometimes","No, MPI calls are scattered in my programs.","CUDA","I think there is room but I do not know how to tune it.","I am not investigating any alternatives.","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Latency hiding (including asynchronous completion);Endpoints (multi-thread, sessions);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.);Another API which is easier and/or simpler to use","Communicator and group management;Process topologies;Dynamic process creation;Error handlers","I prefer to have new API for better performance.","1"
"2019/02/26 4:00:47 AM AST","College/University","Russia","4","3","C/C++","more than 10 years","between 2 and 5 years","Numerical application and/or library;science modeling","scientist","","I read articles found on Internet.","","MPICH;Intel MPI","I have no special reason.","I search the Internet (Google / Stack Overflow).","Debugging","Communicator operations (split, duplicate, and so on);Dynamic process creation;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;One-sided communications","I have never called MPI_INIT_THREAD","I have nobody to ask.","Sometimes","No, my program is too small to do that.","No","I do not have (know) tools to find performance bottlenecks.","I am not investigating any alternatives.","MPI provides all semantics I need","","Communicator and group management;Dynamic process creation","I do not know or I do not care.","5"
"2019/02/26 4:01:18 AM AST","College/University","Russia","5","5","C/C++;Python","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s)","I read most of it.","I read the MPI standard document.;I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Using MPI","MPICH;Open MPI;MVAPICH;Intel MPI","I like to use it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).;I know almost all MPI routines.","Performance tuning","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread);PMPI interface","I have never called MPI_INIT_THREAD","No appropriate lecture / book / info.;I have nobody to ask.","Sometimes","No, MPI calls are scattered in my programs.","OpenMP;Pthread","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A framework or library using MPI.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","One-sided communication;Dynamic process creation","Yes, compatibility is very important for me.","3"
"2019/02/26 4:03:28 AM AST","College/University","Russia","3","3","C/C++;Python","between 2 and 5 years","less than 2 years","Image processing","Parallelization of sequential program(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I had lecture(s) at school.;I read articles found on Internet.","","Open MPI;Intel MPI","I am familiar with it.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Domain decomposition","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);One-sided communications","I have never called MPI_INIT_THREAD","I have nobody to ask.","Mostly","No, my program is too small to do that.","No","I do not know how to find bottlenecks.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","There are no unnecessary features","API should be clearly versioned.","4"
"2019/02/26 4:20:26 AM AST","College/University","Russia","5","4","C/C++;Python","between 2 and 5 years","less than 2 years","Numerical application and/or library","Research and development of application(s);Research and development software tool(s)","","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).","","Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes","I have never called MPI_INIT_THREAD","I have nobody to ask.","Sometimes","No, my program is too small to do that.","No","I have no chance to investigate.","A framework or library using MPI.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","MPI is providing all the communication semantics required by my application","There are no unnecessary features","I do not know or I do not care.","3"
"2019/02/26 4:22:07 AM AST","College/University","Russia","5","4","C/C++;Python","between 5 and 10 years","between 2 and 5 years","Big data;Workflow and/or In-situ","Research and development of application(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I had lecture(s) at school.;I read articles found on Internet.","I have never read any MPI books","MPICH;Open MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","I do not know or I do not care.","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","No, MPI calls are scattered in my programs.","OpenMP","No, my MPI programs are well-tuned.","A framework or library using MPI.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","There are no unnecessary features","I prefer to have new API which is simpler and/or easier-to-use.","3"
"2019/02/26 4:23:51 AM AST","College/University","Russia","4","3","C/C++;Python","between 5 and 10 years","between 2 and 5 years","System software development (OS, runtime library, communication library, etc.);Numerical application and/or library","Research and development of application(s);Research and development on system software (OS and/or runtime library)","I read only the chapters of interest for my work.","I read the MPI standard document.;I had lecture(s) at school.;I read articles found on Internet.","I have never read any MPI books","Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Algorithm design","Dynamic process creation;MPI with OpenMP (or multithread);PMPI interface","Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;Persistent communications","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","I have no obstacles.","Mostly","No, my program is too small to do that.","No","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A framework or library using MPI.","MPI provides all semantics I need","","Dynamic process creation","API should be clearly versioned.","3"
"2019/02/26 4:26:10 AM AST","Private research institute","Russia","2","4","Fortran 90 or newer","less than 2 years","less than 2 years","Numerical application and/or library","Parallelization of sequential program(s);Debugging MPI programs","I read all.","Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","https://parallel.ru/sites/default/files/tech/tech_dev/MPI/mpibook.pdf","MPICH","I have no special reason.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Algorithm design","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes","I have never called MPI_INIT_THREAD","I have nobody to ask.","Sometimes","No, my program is too small to do that.","OpenMP","I think there is room but I do not know how to tune it.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","MPI is providing all the communication semantics required by my application","There are no unnecessary features","I do not know or I do not care.","3"
"2019/02/26 4:27:07 AM AST","College/University","Russia","5","3","C/C++;D, C#","more than 10 years","less than 2 years","Numerical application and/or library","Research and development of application(s)","I have not read it, but I plan to.","I read book(s).;I read articles found on Internet.","","MPICH;Intel MPI","I have no special reason.","I read book(s) (except the MPI standard).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Finding appropriate MPI routines","Persistent communication;MPI with OpenMP (or multithread);PMPI interface","Point-to-point communications;Collective communications","I have never called MPI_INIT_THREAD","I have no obstacles.","Always","Yes, to minimize the changes of communication API.","CUDA","I think there is room but I do not know how to tune it.","I am not investigating any alternatives.","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Resilience (fault tolerance)","Datatypes;Process topologies;Dynamic process creation;Error handlers","Yes, compatibility is very important for me.","1"
"2019/02/26 4:38:37 AM AST","College/University","Russia","4","1","C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer","more than 10 years","less than 2 years","Numerical application and/or library;Big data","teaching in physics & math","I have not read it, but I plan to.","I read articles found on Internet.","","Open MPI","I am familiar with it.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Implementation issue workaround","Persistent communication;PMPI interface","One-sided communications;MPI with OpenMP (or multithread)","I do not know or I do not care.","No appropriate lecture / book / info.","I rely on the default ‘Errors abort’ error handling","No, MPI calls are scattered in my programs.","No","I do not know if there is room for performance tuning.","I am not investigating any alternatives.","Multi-threading support","Another API which is easier and/or simpler to use","There are no unnecessary features","I prefer to have new API which is simpler and/or easier-to-use.","3"
"2019/02/26 4:39:09 AM AST","Private research institute","Russia","4","3","C/C++","between 2 and 5 years","between 2 and 5 years","Numerical application and/or library;fault tolerance of parallel computation","Research and development of application(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).;I read articles found on Internet.","Parallel Programming with MPI","Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes","I have never called MPI_INIT_THREAD","I have no obstacles.","Mostly","No, my program is too small to do that.","OpenMP","I think there is room but I do not know how to tune it.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Resilience (fault tolerance)","One-sided communication","I prefer to have new API for better performance. But now I have small parallel programmes.","5"
"2019/02/26 4:40:08 AM AST","College/University","Russia","1","1","C/C++;Python","more than 10 years","between 2 and 5 years","Numerical application and/or library;Visualization;Life Science, Biochemistry","Application of MPI and non-MPI programs","No, and I will not read it.","I have not learned MPI.","I have never read any MPI books","Open MPI;Intel MPI;MS MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Domain decomposition","Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;Persistent communication;PMPI interface","Point-to-point communications;Collective communications","MPI_THREAD_MULTIPLE","I have no obstacles.;I have no reason to improve my skills (right now)","Always","No, my program is too small to do that.","No","I have no chance to investigate.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Endpoints (multi-thread, sessions)","I'm not sure","Yes, compatibility is very important for me.","4"
"2019/02/26 4:43:32 AM AST","College/University","Russia","4","1","C/C++;JavaScript","more than 10 years","between 2 and 5 years","Numerical application and/or library;Visualization","Research and development of application(s)","I read only the chapters of interest for my work.","I read book(s).;Other lectures or tutorials (workplace, conference).","Books on Russian language","MPICH","I have no special reason.","I read book(s) (except the MPI standard).","Algorithm design","PMPI interface","Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","No appropriate lecture / book / info.","Mostly","No, MPI calls are scattered in my programs.","OpenMP","I do not have (know) tools to find performance bottlenecks.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Latency hiding (including asynchronous completion)","There are no unnecessary features","API should be clearly versioned.","5"
"2019/02/26 4:49:08 AM AST","College/University","Russia","5","3","C/C++;Python","more than 10 years","between 2 and 5 years","System software development (OS, runtime library, communication library, etc.);Numerical application and/or library;Big data","Research and development of application(s);Parallelization of sequential program(s)","","I read the MPI standard document.;I read book(s).","Beginning MPI (An Introduction in C)","Open MPI;Intel MPI","I am familiar with it.","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Finding appropriate MPI routines","Collective communications;MPI datatypes","MPI with OpenMP (or multithread)","I do not know or I do not care.","Too many routines.","Always","No, my program is too small to do that.","OpenMP;CUDA","No, my MPI programs are well-tuned.","A framework or library using MPI.","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","","There are no unnecessary features","API should be clearly versioned.","4"
"2019/02/26 4:54:43 AM AST","Governmental institute","Russia","5","3","Fortran 90 or newer;Python;ncl","more than 10 years","less than 2 years","Numerical application and/or library;Big data","Research and development of application(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Beginning MPI (An Introduction in C)","MPICH;Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).","Algorithm design","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","I do not know or I do not care.","No appropriate lecture / book / info.;I have nobody to ask.","Always","Yes, to minimize the changes of communication API.","No","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Latency","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","There are no unnecessary features","I prefer to have new API which is simpler and/or easier-to-use.","3"
"2019/02/26 5:06:48 AM AST","Governmental institute","Russia","5","4","C/C++","more than 10 years","more than 10 years","Numerical application and/or library","","I read only the chapters of interest for my work.","I had lecture(s) at school.;I read articles found on Internet.","I have never read any MPI books","Intel MPI","I could not have any choice (the one provided by a vendor).","I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation;MPI with OpenMP (or multithread);PMPI interface","Point-to-point communications;Collective communications;MPI datatypes","I do not know or I do not care.","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","No, MPI calls are scattered in my programs.","No","I do not know if there is room for performance tuning.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","Dynamic process creation","Yes, compatibility is very important for me.","3"
"2019/02/26 5:18:07 AM AST","College/University","Russia","4","5","C/C++","more than 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","I read most of it.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).","","MPICH;Open MPI;Intel MPI","I have no special reason.","I read the MPI Standard document (web/book).;I search the Internet (Google / Stack Overflow).","Algorithm design","Dynamic process creation","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on)","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","I have no obstacles.","Sometimes","Yes, to minimize the changes of communication API.","CUDA;Posix ShM","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Latency","Latency hiding (including asynchronous completion)","There are no unnecessary features","API should be clearly versioned.","5"
"2019/02/26 5:58:18 AM AST","Governmental institute","Russia","5","5","C/C++","more than 10 years","more than 10 years","Numerical application and/or library;Visualization","Research and development of application(s);Research and development software tool(s);Parallelization of sequential program(s)","","I read the MPI standard document.","","","","","","Dynamic process creation;Persistent communication","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","I have no obstacles.","Sometimes","No, MPI calls are scattered in my programs.","Pthread","Yes, I know there is room for tuning but I do not have enough resources to do that.","DVM, NORMA","Latency","MPI is providing all the communication semantics required by my application","There are no unnecessary features","Yes, compatibility is very important for me.","5"
"2019/02/26 6:18:43 AM AST","Governmental institute","Russia","5","4","C/C++;Python","more than 10 years","between 5 and 10 years","System software development (OS, runtime library, communication library, etc.)","Research and development of application(s)","I read only the chapters of interest for my work.","I had lecture(s) at school.;I read articles found on Internet.","I have never read any MPI books","MPICH;Open MPI;Intel MPI;IBM MPI (BG/Q, PE, Spectrum)","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","No appropriate lecture / book / info.;Lack of time","Sometimes","Yes, but I have no special reason for doing that.","OpenMP;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","There are no unnecessary features","I do not know or I do not care.","5"
"2019/02/26 6:33:32 AM AST","Governmental institute","Russia","5","5","C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library","Parallelization of sequential program(s)","I read only the chapters of interest for my work.","I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","I have never read any MPI books","MPICH;Intel MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_FUNNELED","I have no obstacles.","Sometimes","No, MPI calls are scattered in my programs.","OpenMP;Pthread;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.","MPI provides all semantics I need","Resilience (fault tolerance)","Dynamic process creation","Yes, compatibility is very important for me.","2"
"2019/02/26 6:35:35 AM AST","College/University","Russia","4","4","Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s);Research and development software tool(s)","I read most of it.","I read the MPI standard document.;I read book(s).","Parallel Programming in C with MPI and OpenMP;MPI: The Complete Reference","Open MPI;MVAPICH","I have no special reason.","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).;I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation;PMPI interface","Point-to-point communications;Collective communications","I have never called MPI_INIT_THREAD;I do not know or I do not care.","I have no obstacles.;Too many routines.","Always","No, MPI calls are scattered in my programs.","OpenMP","I think there is room but I do not know how to tune it.","A framework or library using MPI.","Latency","MPI is providing all the communication semantics required by my application","Process topologies","Yes, compatibility is very important for me.","3"
"2019/02/26 6:43:15 AM AST","College/University","Russia","3","3","C/C++","between 2 and 5 years","less than 2 years","Parallel language (incl. domain specific language);Big data","Research and development of application(s);Parallelization of sequential program(s)","I have not read it, but I plan to.","I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","I have never read any MPI books","MPICH;Open MPI;IBM MPI (BG/Q, PE, Spectrum)","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Algorithm design","Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","Too many routines.","Mostly","No, my program is too small to do that.","OpenMP;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Bandwidth","MPI is providing all the communication semantics required by my application","There are no unnecessary features","Yes, compatibility is very important for me.","4"
"2019/02/26 6:45:45 AM AST","Governmental institute","Russia","4","3","C/C++;Fortran 90 or newer","more than 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s);Parallelization of sequential program(s)","I read only the chapters of interest for my work.","I read book(s).;I had lecture(s) at school.","Parallel Programming in C with MPI and OpenMP","MPICH;Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Performance tuning","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_FUNNELED","I have no obstacles.","Sometimes","No, my program is too small to do that.","OpenMP","I do not have (know) tools to find performance bottlenecks.","A framework or library using MPI.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","Dynamic process creation","API should be clearly versioned.","4"
"2019/02/26 7:04:43 AM AST","Software vendor","Russia","5","3","C/C++","between 5 and 10 years","between 2 and 5 years","Numerical application and/or library;AI (Deep Learning)","Research and development of application(s);Research and development software tool(s)","","I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","I have never read any MPI books","MPICH;Open MPI","I have no special reason.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Domain decomposition","Communicator operations (split, duplicate, and so on);Dynamic process creation;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;One-sided communications;Persistent communications;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","I have no obstacles.","Never","No, my program is too small to do that.","OpenMP","No, my MPI programs are well-tuned.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","Dynamic process creation","API should be clearly versioned.","5"
"2019/02/26 7:08:29 AM AST","Software vendor","Russia","5","4","C/C++","more than 10 years","between 2 and 5 years","Parallel language (incl. domain specific language)","Research and development of application(s);Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I had lecture(s) at school.","I have never read any MPI books","MPICH;MS MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","One-sided communications;Dynamic process creation;Persistent communication","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","Too complicated and hard to understand.;I do not like the API.","Always","No, MPI calls are scattered in my programs.","OpenMP;CUDA","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","Datatypes;Process topologies","Yes, compatibility is very important for me.","5"
"2019/02/26 7:12:44 AM AST","Governmental institute","Russia","6","6","Fortran (older one than Fortran 90);Fortran 90 or newer","more than 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s)","I read most of it.","I read the MPI standard document.;I read articles found on Internet.","I have never read any MPI books","MPICH;Intel MPI","I like to use it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Debugging","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes","I have never called MPI_INIT_THREAD","I have no obstacles.","Sometimes","No, MPI calls are scattered in my programs.","No","I think there is room but I do not know how to tune it.","A framework or library using MPI.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","There are no unnecessary features","Yes, compatibility is very important for me.","5"
"2019/02/26 7:29:30 AM AST","College/University","Russia","3","3","C/C++","more than 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes","I have never called MPI_INIT_THREAD","I have no obstacles.","Never","No, my program is too small to do that.","No","I do not have (know) tools to find performance bottlenecks.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","Dynamic process creation","Yes, compatibility is very important for me.","4"
"2019/02/26 8:02:59 AM AST","College/University","Russia","3","3","C/C++","between 2 and 5 years","less than 2 years","Numerical application and/or library","Research and development of application(s)","No, and I will not read it.","I read book(s).","Antonov (in Russian)","Open MPI","I have no special reason.","I read book(s) (except the MPI standard).;I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications","I have never called MPI_INIT_THREAD;I do not know or I do not care.","No appropriate lecture / book / info.","Sometimes","Yes, but I have no special reason for doing that.","OpenMP;CUDA","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","I am not investigating any alternatives.","Too stupid to give an educated opinion","Too stupid to give an educated opinion","There are no unnecessary features","I prefer to have new API which is simpler and/or easier-to-use.","5"
"2019/02/26 8:03:16 AM AST","College/University","Russia","3","2","C/C++;Python","between 2 and 5 years","less than 2 years","Numerical application and/or library","Parallelization of sequential program(s);Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","I have never read any MPI books","Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Persistent communication;PMPI interface","Point-to-point communications;Collective communications;One-sided communications","I have never called MPI_INIT_THREAD","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","No, my program is too small to do that.","OpenMP","I do not know how to find bottlenecks.","I am not investigating any alternatives.","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","MPI is providing all the communication semantics required by my application","Communicator and group management;Process topologies;Dynamic process creation","API should be clearly versioned.","4"
"2019/02/26 8:11:58 AM AST","College/University","Russia","4","3","C/C++;Python","between 2 and 5 years","between 2 and 5 years","AI (Deep Learning)","Research and development of application(s)","I read only the chapters of interest for my work.","I had lecture(s) at school.;I read articles found on Internet.","I have never read any MPI books","MPICH;Open MPI","I like to use it.","I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","I do not know or I do not care.","No time to do so","Sometimes","No, my program is too small to do that.","OpenMP;CUDA","I have no chance to investigate.","A framework or library using MPI.","Bandwidth","Another API which is easier and/or simpler to use","Dynamic process creation","I prefer to have new API which is simpler and/or easier-to-use.","4"
"2019/02/26 8:55:19 AM AST","College/University","Russia","4","4","C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer","between 2 and 5 years","between 2 and 5 years","Numerical application and/or library","Parallelization of sequential program(s)","I read only the chapters of interest for my work.","I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Using MPI","MPICH;Open MPI;Intel MPI;IBM MPI (BG/Q, PE, Spectrum)","I am familiar with it.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;One-sided communications;MPI with OpenMP (or multithread)","I do not know or I do not care.","I have no obstacles.","Never","Yes, to minimize the changes of communication API.","OpenMP;CUDA","I think there is room but I do not know how to tune it.","A framework or library using MPI.","Multi-threading support","Latency hiding (including asynchronous completion);Endpoints (multi-thread, sessions)","Dynamic process creation","I prefer to have new API for better performance.","5"
"2019/02/26 8:58:00 AM AST","College/University","Russia","4","2","Fortran (older one than Fortran 90);Fortran 90 or newer","more than 10 years","between 5 and 10 years","Big data","Research and development on system software (OS and/or runtime library)","I read only the chapters of interest for my work.","I read the MPI standard document.","I have never read any MPI books","Intel MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).","Debugging","Point-to-point communications;Persistent communication;PMPI interface","MPI datatypes;Dynamic process creation","I do not know or I do not care.","too busy with other tasks/duties","Never","No, my program is too small to do that.","No","I have no chance to investigate.","I am not investigating any alternatives.","Don't know ","Don't know","Don't know (too little experience with MPI)","Yes, compatibility is very important for me.","3"
"2019/02/26 9:48:22 AM AST","Governmental institute","Russia","4","4","C/C++;Java;Python","between 2 and 5 years","between 2 and 5 years","Parallel language (incl. domain specific language);Big data","Research and development of application(s);Research and development on system software (OS and/or runtime library)","I read only the chapters of interest for my work.","I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","","MPICH;Open MPI","I am familiar with it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).","Debugging","Point-to-point communications","MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","I have no obstacles.","Mostly","No, my program is too small to do that.","No","No, my MPI programs are well-tuned.","A framework or library using MPI.","MPI provides all semantics I need","Resilience (fault tolerance)","One-sided communication","Yes, compatibility is very important for me.","4"
"2019/02/26 9:49:33 AM AST","College/University","Russia","4","3","C/C++","more than 10 years","between 5 and 10 years","Numerical application and/or library;Workflow and/or In-situ","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s);System administrator","","I read the MPI standard document.;I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","Open MPI;IBM MPI (BG/Q, PE, Spectrum)","I have no special reason.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Algorithm design","Persistent communication;MPI with OpenMP (or multithread);PMPI interface","Point-to-point communications;Collective communications;MPI datatypes","I do not know or I do not care.","I have no obstacles.","Never","No, my program is too small to do that.","OpenMP","I have no chance to investigate.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Resilience (fault tolerance);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","There are no unnecessary features","Yes, compatibility is very important for me.","1"
"2019/02/26 10:24:25 AM AST","Private research institute","Russia","6","5","C/C++;Java;Python","more than 10 years","more than 10 years","System software development (OS, runtime library, communication library, etc.);Numerical application and/or library;AI (Deep Learning);Big data","Research and development on system software (OS and/or runtime library)","I read only the chapters of interest for my work.","I read the MPI standard document.;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","MPICH;Open MPI","I am familiar with it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).;I know almost all MPI routines.","Performance tuning","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_MULTIPLE","I have no obstacles.","Always","Yes, to minimize the changes of communication API.","OpenMP","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A framework or library using MPI.","Latency","MPI is providing all the communication semantics required by my application","Communicator and group management;Process topologies;Dynamic process creation","I prefer to have new API for better performance.","5"
"2019/02/26 10:27:33 AM AST","Governmental institute","Russia","5","4","C/C++","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s)","","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).","Introduction to MPI – created by the PACS Training Group, ©2001 Board of Trustees of the University of Illinois","MPICH;MS MPI","I have no special reason.","I read the MPI Standard document (web/book).","Debugging","","Point-to-point communications;Collective communications;MPI datatypes","I have never called MPI_INIT_THREAD","I have no obstacles.","Sometimes","Yes, to minimize the changes of communication API.","No","No, my MPI programs are well-tuned.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","One-sided communication;Communicator and group management;Process topologies;Dynamic process creation;Error handlers","Yes, compatibility is very important for me.","2"
"2019/02/26 11:37:24 AM AST","Governmental institute","Russia","4","3","C/C++","between 2 and 5 years","less than 2 years","Numerical application and/or library;Visualization","Research and development of application(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I had lecture(s) at school.;I read articles found on Internet.","I have never read any MPI books","MPICH","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes","I have never called MPI_INIT_THREAD","I have no obstacles.","Never","No, MPI calls are scattered in my programs.","Pthread","I have no chance to investigate.","A framework or library using MPI.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","Communicator and group management","Yes, compatibility is very important for me.","3"
"2019/02/26 11:53:42 AM AST","Governmental institute","Russia","4","5","C/C++;Fortran (older one than Fortran 90)","more than 10 years","more than 10 years","Numerical application and/or library;Tool development (performance tuning, debugging, etc.)","Research and development of application(s);Performance tuning of MPI program(s)","","I read the MPI standard document.;I read articles found on Internet.","","MPICH;Open MPI","I have no special reason.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","Persistent communication;PMPI interface","Point-to-point communications;Collective communications","I have never called MPI_INIT_THREAD","I have no obstacles.","Sometimes","Yes, but I have no special reason for doing that.","OpenMP;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","Communicator and group management;Process topologies;Dynamic process creation","Yes, compatibility is very important for me.","1"
"2019/02/26 12:13:14 PM AST","College/University","Russia","4","3","C/C++;Python","more than 10 years","between 5 and 10 years","Numerical application and/or library","Research and development software tool(s);Parallelization of sequential program(s)","I read only the chapters of interest for my work.","I had lecture(s) at school.;I read articles found on Internet.","I have never read any MPI books","Open MPI;Intel MPI","I have no special reason.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Domain decomposition","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","Too many routines.","Never","No, my program is too small to do that.","OpenMP","I do not know if there is room for performance tuning.","A framework or library using MPI.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","Communicator and group management;Process topologies;Dynamic process creation","I prefer to have new API for better performance.","2"
"2019/02/26 1:31:15 PM AST","Governmental institute","Russia","2","1","C/C++","between 5 and 10 years","between 2 and 5 years","Tool development (performance tuning, debugging, etc.)","Performance tuning of MPI program(s)","No, and I will not read it.","I read articles found on Internet.","I have never read any MPI books","Open MPI","I have no special reason.","I read the MPI Standard document (web/book).","Algorithm design","PMPI interface","MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE","I have nobody to ask.","I rely on the default ‘Errors abort’ error handling","No, my program is too small to do that.","No","I have no chance to investigate.","I am not investigating any alternatives.","Bandwidth","Resilience (fault tolerance)","There are no unnecessary features","I do not know or I do not care.","2"
"2019/02/26 1:54:23 PM AST","College/University","Russia","4","4","C/C++;Python","between 5 and 10 years","between 2 and 5 years","Numerical application and/or library;Image processing","Research and development of application(s);Parallelization of sequential program(s)","I have not read it, but I plan to.","I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","I have never read any MPI books","MPICH;Open MPI;MS MPI","I am familiar with it.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes","I have never called MPI_INIT_THREAD","No appropriate lecture / book / info.","Mostly","Yes, but I have no special reason for doing that.","OpenMP;CUDA","I think there is room but I do not know how to tune it.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","MPI is providing all the communication semantics required by my application","There are no unnecessary features","Yes, compatibility is very important for me.","1"
"2019/02/26 2:36:11 PM AST","College/University","Russia","4","3","C/C++","between 5 and 10 years","between 2 and 5 years","Numerical application and/or library","Research and development of application(s)","I have not read it, but I plan to.","I had lecture(s) at school.;I read articles found on Internet.","I have never read any MPI books","MPICH;IBM MPI (BG/Q, PE, Spectrum)","I have no special reason.","I search the Internet (Google / Stack Overflow).","Finding appropriate MPI routines","Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","I have no obstacles.","Sometimes","No, my program is too small to do that.","OpenMP;CUDA","I do not know if there is room for performance tuning.","A framework or library using MPI.","","","","",""
"2019/02/26 3:22:22 PM AST","Hardware vendor","Russia","6","5","C/C++;Fortran 90 or newer;Java;Python","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s);Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).;I had lecture(s) at school.","MPI: The Complete Reference","Open MPI;IBM MPI (BG/Q, PE, Spectrum)","I am familiar with it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;Dynamic process creation;Persistent communication;MPI with OpenMP (or multithread);PMPI interface","Point-to-point communications;Collective communications;MPI with OpenMP (or multithread)","I do not know or I do not care.","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","Yes, but I have no special reason for doing that.","OpenMP;CUDA","I think there is room but I do not know how to tune it.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","Dynamic process creation;Error handlers","API should be clearly versioned.","4"
"2019/02/26 4:19:05 PM AST","College/University","Russia","5","5","Fortran (older one than Fortran 90);Fortran 90 or newer;Python","more than 10 years","more than 10 years","Numerical application and/or library;Image processing;Visualization","Research and development of application(s);Research and development software tool(s);Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","","I read the MPI standard document.;I read book(s).;I read articles found on Internet.","Using MPI","MPICH;Open MPI;Intel MPI","I like to use it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Domain decomposition","PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_SERIALIZED;MPI_THREAD_MULTIPLE","I have nobody to ask.","Sometimes","No, MPI calls are scattered in my programs.","","No, my MPI programs are well-tuned.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","There are no unnecessary features","I do not know or I do not care.","4"
"2019/02/26 4:37:50 PM AST","Hardware vendor","Russia","4","4","C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer","more than 10 years","more than 10 years","System software development (OS, runtime library, communication library, etc.);Parallel language (incl. domain specific language);Numerical application and/or library","Research and development of application(s);Performance tuning of MPI program(s);Debugging MPI programs","","I read the MPI standard document.;I read book(s).;I read articles found on Internet.","Using MPI","MPICH;Open MPI;MVAPICH;Intel MPI","I like to use it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Performance tuning","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;Dynamic process creation;MPI with OpenMP (or multithread);PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","Too complicated and hard to understand.;I have nobody to ask.","Mostly","No, MPI calls are scattered in my programs.","OpenMP;Pthread","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A framework or library using MPI.;A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).;Low-level communication layer provided by vendor (Verbs, DCMF, ...).","Multi-threading support","Resilience (fault tolerance);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","","API should be clearly versioned.","3"
"2019/02/26 5:05:27 PM AST","Governmental institute","Russia","4","4","C/C++;Fortran 90 or newer","more than 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s);Research and development software tool(s);Parallelization of sequential program(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).","Parallel Programming with MPI;MPI: The Complete Reference","Intel MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Performance tuning","PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_FUNNELED","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","There are no unnecessary features","API should be clearly versioned.","4"
"2019/02/26 7:34:33 PM AST","Software vendor","Russia","5","4","C/C++;Python","more than 10 years","between 5 and 10 years","Numerical application and/or library;Visualization","Research and development of application(s)","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","I have never read any MPI books","Open MPI;Intel MPI","I am familiar with it.","I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Algorithm design","One-sided communications;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","Too many routines.","Sometimes","No, MPI calls are scattered in my programs.","OpenMP;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.;A Domain Specific Language (DSL).","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","One-sided communication;Process topologies","I prefer to have new API for better performance.","5"
"2019/02/26 9:21:08 PM AST","College/University","Japan","5","4","C/C++;Java;Python","more than 10 years","between 2 and 5 years","Parallel language (incl. domain specific language)","Research and development of application(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).;I read articles found on Internet.","Using MPI","MPICH","I have no special reason.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Domain decomposition","One-sided communications;PMPI interface","Point-to-point communications;Collective communications;Dynamic process creation","I do not know or I do not care.","Too complicated and hard to understand.","Mostly","Yes, but I have no special reason for doing that.","No","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","There are no unnecessary features","API should be clearly versioned.","3"
"2019/02/26 9:28:58 PM AST","College/University","Japan","5","5","C/C++","more than 10 years","more than 10 years","Parallel language (incl. domain specific language);Numerical application and/or library","Research and development of application(s);Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","Using MPI;MPI: The Complete Reference","MPICH;Open MPI;Fujistu MPI;NEC MPI","I am familiar with it.","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).","Debugging","Dynamic process creation;Persistent communication","Point-to-point communications;Collective communications","I do not know or I do not care.","I have no obstacles.","Sometimes","Yes, but I have no special reason for doing that.","OpenMP;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Latency hiding (including asynchronous completion);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","There are no unnecessary features","API should be clearly versioned.","5"
"2019/02/26 9:41:55 PM AST","College/University","Japan","3","2","C/C++;Python","more than 10 years","more than 10 years","Tool development (performance tuning, debugging, etc.)","Research and development on system software (OS and/or runtime library)","No, and I will not read it.","I read book(s).;I had lecture(s) at school.","Parallel Programming with MPI","MVAPICH","I could not have any choice (the one provided by a vendor).","I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation","Point-to-point communications;Collective communications","I have never called MPI_INIT_THREAD","Too many routines.;Too complicated and hard to understand.","I rely on the default ‘Errors abort’ error handling","No, my program is too small to do that.","No","I think there is room but I do not know how to tune it.","I am not investigating any alternatives.","Latency","Latency hiding (including asynchronous completion)","Process topologies;Error handlers","Yes, compatibility is very important for me.","1"
"2019/02/26 9:54:16 PM AST","College/University","Sweden","4","3","C/C++","between 5 and 10 years","less than 2 years","Workflow and/or In-situ;Visualization","Research and development software tool(s)","I read only the chapters of interest for my work.","I read articles found on Internet.","","Open MPI","I like to use it.","I read online documents (such as man pages).","Debugging","Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","Too complicated and hard to understand.;I have nobody to ask.","Sometimes","Yes, to minimize the changes of communication API.","OpenMP;CUDA","I think there is room but I do not know how to tune it.","I am not investigating any alternatives.","Bandwidth","Endpoints (multi-thread, sessions)","Process topologies;Dynamic process creation","Yes, compatibility is very important for me.","3"
"2019/02/26 10:22:40 PM AST","College/University","Japan","5","5","C/C++","more than 10 years","more than 10 years","Parallel language (incl. domain specific language);Numerical application and/or library","Research and development of application(s);Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","Using MPI;MPI: The Complete Reference","MPICH;Open MPI;Fujistu MPI;NEC MPI","I am familiar with it.","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).","Debugging","Dynamic process creation;Persistent communication","Point-to-point communications;Collective communications","I do not know or I do not care.","I have no obstacles.","Sometimes","Yes, but I have no special reason for doing that.","OpenMP;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Latency hiding (including asynchronous completion);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","There are no unnecessary features","API should be clearly versioned.","5"
"2019/02/26 10:28:58 PM AST","College/University","Japan","6","4","C/C++;Python","more than 10 years","between 2 and 5 years","System software development (OS, runtime library, communication library, etc.);Image processing","Research and development of application(s);Research and development on system software (OS and/or runtime library)","I read most of it.","I read the MPI standard document.;I read articles found on Internet.","Beginning MPI (An Introduction in C);Parallel Programming in C with MPI and OpenMP;MPI: The Complete Reference","Open MPI","I like to use it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation;Persistent communication","Persistent communications","MPI_THREAD_MULTIPLE","No appropriate lecture / book / info.","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","CUDA","I do not know if there is room for performance tuning.","I am not investigating any alternatives.","Bandwidth","MPI is providing all the communication semantics required by my application","One-sided communication","I prefer to have new API which is simpler and/or easier-to-use.","5"
"2019/02/26 11:28:45 PM AST","College/University","Japan","4","4","C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer;Python","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s)","I have not read it, but I plan to.","I read book(s).","Parallel Programming ""Tora-no-maki"" for MPI","MPICH;Open MPI;MVAPICH;Intel MPI","I have no special reason.","I read book(s) (except the MPI standard).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Performance tuning","Persistent communication","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_FUNNELED","I have no obstacles.","Sometimes","No, MPI calls are scattered in my programs.","OpenMP;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).;A Domain Specific Language (DSL).","MPI provides all semantics I need","Resilience (fault tolerance)","There are no unnecessary features","I prefer to have new API which is simpler and/or easier-to-use.","2"
"2019/02/27 12:17:12 AM AST","College/University","Russia","5","3","C/C++;Java","between 5 and 10 years","between 2 and 5 years","Numerical application and/or library;Big data","Research and development of application(s)","I have not read it, but I plan to.","Other lectures or tutorials (workplace, conference).","I have never read any MPI books","Open MPI","I am familiar with it.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Finding appropriate MPI routines","One-sided communications;Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Communicator operations (split, duplicate, and so on)","MPI_THREAD_SINGLE;MPI_THREAD_SERIALIZED","I have no obstacles.","Sometimes","No, MPI calls are scattered in my programs.","No","I think there is room but I do not know how to tune it.","A framework or library using MPI.","MPI provides all semantics I need","","There are no unnecessary features","I prefer to have new API for better performance.","3"
"2019/02/27 12:37:16 AM AST","College/University","Japan","5","5","C/C++","more than 10 years","more than 10 years","Parallel language (incl. domain specific language)","Research and development software tool(s)","I read most of it.","I read the MPI standard document.","MPI: The Complete Reference","Open MPI;Intel MPI","I like to use it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).","Performance tuning","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;Dynamic process creation;MPI with OpenMP (or multithread)","Point-to-point communications;Collective communications;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","Too many routines.","Sometimes","Yes, to minimize the changes of communication API.","OpenMP","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Latency hiding (including asynchronous completion);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","Communicator and group management;Process topologies;Dynamic process creation","API should be clearly versioned.","4"
"2019/02/27 1:07:23 AM AST","Governmental institute","India","5","5","C/C++;Python","more than 10 years","more than 10 years","Numerical application and/or library;Bioinformatics Applications","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","","I read articles found on Internet.","I have never read any MPI books","MPICH;MVAPICH;Intel MPI","I have no special reason.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Performance tuning","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_FUNNELED;MPI_THREAD_MULTIPLE","No appropriate lecture / book / info.","Mostly","No, MPI calls are scattered in my programs.","OpenMP","I think there is room but I do not know how to tune it.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","There are no unnecessary features","I prefer to have new API for better performance.","5"
"2019/02/27 1:23:39 AM AST","","India","6","3","C/C++","more than 10 years","less than 2 years","System software development (OS, runtime library, communication library, etc.);Big data;Tool development (performance tuning, debugging, etc.)","Research and development of application(s);Research and development on system software (OS and/or runtime library);Research and development software tool(s)","","I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","Parallel Programming in C with MPI and OpenMP","Open MPI","I have no special reason.","I read online documents (such as man pages).","Debugging","MPI with OpenMP (or multithread)","Point-to-point communications;Collective communications;MPI datatypes","MPI_THREAD_SINGLE","","Mostly","Yes, but I have no special reason for doing that.","No","I have no chance to investigate.","I am not investigating any alternatives.","","dynamicportability of MPI programs virtual commuication ID","","Yes, compatibility is very important for me.","3"
"2019/02/27 1:32:02 AM AST","Governmental institute","India","5","5","C/C++","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Parallel Programming with MPI","MPICH;Intel MPI","I like to use it.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Performance tuning","Dynamic process creation","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","Too many routines.;No appropriate lecture / book / info.","Sometimes","No, MPI calls are scattered in my programs.","OpenMP;CUDA","I do not have (know) tools to find performance bottlenecks.","I am not investigating any alternatives.","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","Process topologies;Dynamic process creation","I prefer to have new API for better performance.","3"
"2019/02/27 1:44:35 AM AST","College/University","Japan","4","4","C/C++;Python","more than 10 years","between 2 and 5 years","Numerical application and/or library","Research and development software tool(s);Parallelization of sequential program(s)","","I read the MPI standard document.;I read book(s).;I read articles found on Internet.","Parallel Programming with MPI;Using MPI","MPICH;Open MPI","I have no special reason.","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).;I search the Internet (Google / Stack Overflow).","Performance tuning","PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","Too many routines.;No appropriate lecture / book / info.","Never","No, MPI calls are scattered in my programs.","OpenMP;Pthread","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.;I am not investigating any alternatives.","Bandwidth","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","There are no unnecessary features","I prefer to have new API for better performance.","1"
"2019/02/27 2:57:57 AM AST","College/University","Japan","5","3","C/C++;Python","between 5 and 10 years","between 2 and 5 years","System software development (OS, runtime library, communication library, etc.);Parallel language (incl. domain specific language);Tool development (performance tuning, debugging, etc.);Scientific software","Research and development of application(s);Research and development on system software (OS and/or runtime library)","I have not read it, but I plan to.","I read book(s).;I had lecture(s) at school.;I read articles found on Internet.","Beginning MPI (An Introduction in C)","Open MPI","I like to use it.","I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Performance tuning","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","I do not know or I do not care.","Too complicated and hard to understand.","Sometimes","Yes, to minimize the changes of communication API.","OpenMP;OpenACC;CUDA","I think there is room but I do not know how to tune it.","A framework or library using MPI.","Bandwidth","Endpoints (multi-thread, sessions)","Error handlers","Yes, compatibility is very important for me.","3"
"2019/02/27 3:32:35 AM AST","Software vendor","Japan","6","5","C/C++;Python","between 5 and 10 years","between 2 and 5 years","System software development (OS, runtime library, communication library, etc.);Parallel language (incl. domain specific language);Numerical application and/or library;AI (Deep Learning);Big data","Research and development on system software (OS and/or runtime library);Parallelization of sequential program(s)","I have not read it, but I plan to.","I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","Open MPI","I have no special reason.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","OpenMP;Pthread;CUDA","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A framework or library using MPI.;Low-level communication layer provided by vendor (Verbs, DCMF, ...).","Multi-threading support","Latency hiding (including asynchronous completion);Endpoints (multi-thread, sessions);Resilience (fault tolerance);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","Dynamic process creation","Yes, compatibility is very important for me.","4"
"2019/02/27 4:16:41 AM AST","College/University","Japan","5","5","C/C++;Fortran 90 or newer;Python","more than 10 years","more than 10 years","Numerical application and/or library;Big data;Workflow and/or In-situ","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s)","","I read the MPI standard document.","I have never read any MPI books","MPICH;Open MPI;Fujistu MPI","I have no special reason.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","No appropriate lecture / book / info.","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.","Latency","Another API which is easier and/or simpler to use","There are no unnecessary features","Yes, compatibility is very important for me.","1"
"2019/02/27 4:50:49 AM AST","College/University","Japan","4","5","C/C++;Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s);Research and development software tool(s);Parallelization of sequential program(s);Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","I read book(s).;I had lecture(s) at school.","Parallel Programming with MPI;Using MPI;Parallel Programming in C with MPI and OpenMP","MPICH;Open MPI;Intel MPI;Fujistu MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).;I ask colleagues.","Domain decomposition","PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);One-sided communications;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","I have no obstacles.","Sometimes","Yes, to minimize the changes of communication API.","OpenMP;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.;Low-level communication layer provided by vendor (Verbs, DCMF, ...).","Multi-threading support","Latency hiding (including asynchronous completion)","Datatypes;Dynamic process creation","I prefer to have new API which is simpler and/or easier-to-use.","3"
"2019/02/27 5:16:37 AM AST","College/University","Russia","5","5","C/C++","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).","I have never read any MPI books","MPICH;Intel MPI","I have no special reason.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI with OpenMP (or multithread)","MPI_THREAD_SERIALIZED;MPI_THREAD_MULTIPLE","I have no obstacles.;Too many routines.","Sometimes","Yes, but I have no special reason for doing that.","OpenMP;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","Dynamic process creation","I prefer to have new API for better performance.","4"
"2019/02/27 6:03:58 AM AST","College/University","United Kingdom","6","5","C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer;Python","more than 10 years","between 5 and 10 years","Numerical application and/or library;Big data;Visualization","Research and development of application(s);Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Using MPI;MPI: The Complete Reference","MPICH;Open MPI;Intel MPI","I am familiar with it.","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Performance tuning","Persistent communication","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","I have nobody to ask.","Sometimes","No, MPI calls are scattered in my programs.","OpenMP;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","MPI is providing all the communication semantics required by my application","Datatypes;Dynamic process creation","Yes, compatibility is very important for me.","4"
"2019/02/27 6:04:32 AM AST","Governmental institute","France","6","4","C/C++","more than 10 years","more than 10 years","System software development (OS, runtime library, communication library, etc.);Parallel language (incl. domain specific language);Tool development (performance tuning, debugging, etc.)","Research and development on system software (OS and/or runtime library);Research and development software tool(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","MPICH;Open MPI;Intel MPI","I like to use it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Performance tuning","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;Dynamic process creation;Persistent communication;MPI with OpenMP (or multithread);PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED;MPI_THREAD_SERIALIZED;MPI_THREAD_MULTIPLE","Too many routines.;Too complicated and hard to understand.","Mostly","No, MPI calls are scattered in my programs.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Endpoints (multi-thread, sessions);Resilience (fault tolerance)","Datatypes;Dynamic process creation","I prefer to have new API for better performance.","4"
"2019/02/27 6:05:53 AM AST","College/University","France","5","3","C/C++;Fortran 90 or newer;Python","between 5 and 10 years","between 2 and 5 years","Numerical application and/or library","Research and development of application(s)","No, and I will not read it.","I had lecture(s) at school.;I read articles found on Internet.","I have never read any MPI books","Open MPI;Intel MPI","I have no special reason.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","MPI datatypes;Persistent communication;PMPI interface","Point-to-point communications;Collective communications","I have never called MPI_INIT_THREAD","I have no obstacles.","Sometimes","No, my program is too small to do that.","No","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","There are no unnecessary features","Yes, compatibility is very important for me.","3"
"2019/02/27 6:06:40 AM AST","College/University","France","4","2","C/C++;Fortran (older one than Fortran 90);Python","between 5 and 10 years","between 2 and 5 years","Parallel language (incl. domain specific language);Numerical application and/or library","Research and development software tool(s)","I read only the chapters of interest for my work.","I read book(s).;I read articles found on Internet.","Using MPI","MPICH;Open MPI;Intel MPI","I have no special reason.","I read book(s) (except the MPI standard).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Performance tuning","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes","","","","","","","","","","","",""
"2019/02/27 6:08:50 AM AST","Governmental institute","France","5","4","Fortran (older one than Fortran 90);Fortran 90 or newer;Python","between 5 and 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s)","No, and I will not read it.","Other lectures or tutorials (workplace, conference).;by example working on a code which was using MPI","","MPICH;Open MPI;MVAPICH","I like to use it.","I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Performance tuning","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED","I have nobody to ask.","Always","No, MPI calls are scattered in my programs.","OpenMP","No, my MPI programs are well-tuned.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","things I don't know like Dynamic process creation etc","I prefer to have new API which is simpler and/or easier-to-use.","2"
"2019/02/27 6:09:07 AM AST","College/University","France","5","4","Fortran 90 or newer;Python;js","between 5 and 10 years","between 5 and 10 years","Parallel language (incl. domain specific language);Numerical application and/or library;Visualization","Research and development of application(s);Research and development software tool(s);Parallelization of sequential program(s);Performance tuning of MPI program(s)","I have not read it, but I plan to.","I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","MPI: The Complete Reference","MPICH;Open MPI;NEC MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).","Debugging","Communicator operations (split, duplicate, and so on);PMPI interface","Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_FUNNELED","I have no obstacles.","Never","Yes, but I have no special reason for doing that.","OpenMP;CUDA","No, my MPI programs are well-tuned.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","","MPI is providing all the communication semantics required by my application","There are no unnecessary features","I prefer to have new API for better performance.","4"
"2019/02/27 6:10:54 AM AST","Governmental institute","France","6","6","C/C++;Fortran 90 or newer","between 5 and 10 years","between 5 and 10 years","Parallel language (incl. domain specific language);Numerical application and/or library","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","I read only the chapters of interest for my work.","I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","Open MPI;Intel MPI;IBM MPI (BG/Q, PE, Spectrum);HPE MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Algorithm design","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_FUNNELED;MPI_THREAD_SERIALIZED;MPI_THREAD_MULTIPLE","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","Yes, but I have no special reason for doing that.","OpenMP;OpenACC","I have no chance to investigate.","A framework or library using MPI.","Message injection rate","Endpoints (multi-thread, sessions);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","Dynamic process creation","API should be clearly versioned.","3"
"2019/02/27 6:11:38 AM AST","Governmental institute","France","6","4","C/C++;Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).","Using MPI","MPICH;Open MPI;Intel MPI","I have no special reason.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Domain decomposition","Dynamic process creation","Point-to-point communications;Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_FUNNELED;MPI_THREAD_MULTIPLE","I have no obstacles.","Always","Yes, to minimize the changes of communication API.","OpenMP","No, my MPI programs are well-tuned.","","Multi-threading support","","There are no unnecessary features","Yes, compatibility is very important for me.","3"
"2019/02/27 6:14:17 AM AST","Other","France","3","1","C/C++;Fortran 90 or newer;Python","between 2 and 5 years","less than 2 years","Numerical application and/or library","Research and development software tool(s)","I read only the chapters of interest for my work.","I read book(s).;I read articles found on Internet.","Using MPI","I do not know","I have no special reason.","I read book(s) (except the MPI standard).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Point-to-point communications;Communicator operations (split, duplicate, and so on);One-sided communications;Dynamic process creation;Persistent communication;MPI with OpenMP (or multithread);PMPI interface","Collective communications;MPI datatypes","I do not know or I do not care.","I have no obstacles.;It requires time","Never","No, my program is too small to do that.","No","I think there is room but I do not know how to tune it.","I am not investigating any alternatives.","I do not know","I do not know","One-sided communication;Process topologies;Dynamic process creation","I do not know or I do not care.","4"
"2019/02/27 6:15:36 AM AST","Private research institute","France","5","5","C/C++;Python","between 5 and 10 years","less than 2 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","I have never read any MPI books","Open MPI;Intel MPI","I am familiar with it.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","One-sided communications;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","I have no obstacles.","Never","No, MPI calls are scattered in my programs.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Resilience (fault tolerance)","There are no unnecessary features","Yes, compatibility is very important for me.","4"
"2019/02/27 6:21:42 AM AST","Governmental institute","France","5","4","C/C++;Fortran 90 or newer;julia","more than 10 years","between 5 and 10 years","Numerical application and/or library;Image processing","Research and development of application(s);Parallelization of sequential program(s)","","I read book(s).;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Using MPI","MPICH;Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read book(s) (except the MPI standard).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","Persistent communication","Point-to-point communications;Collective communications","I have never called MPI_INIT_THREAD","I have no obstacles.","Sometimes","Yes, to minimize the changes of communication API.","OpenMP;CUDA;kokkos","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","There are no unnecessary features","I prefer to have new API for better performance.","3"
"2019/02/27 6:25:43 AM AST","Governmental institute","France","6","5","C/C++;Fortran 90 or newer","more than 10 years","between 5 and 10 years","Parallel language (incl. domain specific language);Numerical application and/or library","Research and development of application(s);Research and development software tool(s)","I read only the chapters of interest for my work.","I read the MPI standard document.","I have never read any MPI books","Open MPI;Intel MPI","I like to use it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation;Persistent communication","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);One-sided communications;MPI with OpenMP (or multithread);PMPI interface","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","I do not like the API.","Always","Yes, to minimize the changes of communication API.","OpenMP;tbb GASPI","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Multi-threading support","Latency hiding (including asynchronous completion)","Datatypes","I prefer to have new API which is simpler and/or easier-to-use.","2"
"2019/02/27 6:27:53 AM AST","College/University","Russia","4","4","C/C++;Fortran (older one than Fortran 90);Python","between 5 and 10 years","between 2 and 5 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I had lecture(s) at school.;I read articles found on Internet.","","Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I search the Internet (Google / Stack Overflow).","Debugging","Communicator operations (split, duplicate, and so on);Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications","","Too many routines.","Sometimes","No, my program is too small to do that.","","I think there is room but I do not know how to tune it.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","","Yes, compatibility is very important for me.","4"
"2019/02/27 6:28:50 AM AST","Governmental institute","France","4","5","C/C++;Fortran 90 or newer","more than 10 years","more than 10 years","System software development (OS, runtime library, communication library, etc.);Parallel language (incl. domain specific language);Numerical application and/or library;Tool development (performance tuning, debugging, etc.)","Research and development software tool(s);Performance tuning of MPI program(s);Debugging MPI programs","I read only the chapters of interest for my work.","by programming and my friend ""Google""","Using MPI;MPI: The Complete Reference","MPICH;Open MPI;MVAPICH;Intel MPI;MPC MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Implementation issue workaround","","Point-to-point communications;Collective communications;MPI with OpenMP (or multithread);PMPI interface","MPI_THREAD_FUNNELED;MPI_THREAD_MULTIPLE","Too many routines.","Never","Yes, to minimize the changes of communication API.","OpenMP","There is room but it's hardware dependant","A framework or library using MPI.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Resilience (fault tolerance);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","One-sided communication;Datatypes;Dynamic process creation","Yes, compatibility is very important for me.","2"
"2019/02/27 6:29:03 AM AST","Governmental institute","France","3","1","C/C++;Python","more than 10 years","between 5 and 10 years","Numerical application and/or library","Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","I read only the chapters of interest for my work.","I read book(s).;Help from collegues","Parallel Programming with MPI;Using MPI","Open MPI","I was said to use it.","I ask colleagues.;I search the Internet (Google / Stack Overflow).","Debugging","Point-to-point communications;Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","Point-to-point communications;Collective communications","I have never called MPI_INIT_THREAD","Too complicated and hard to understand.","Sometimes","No, MPI calls are scattered in my programs.","No","I think there is room but I do not know how to tune it.","I am not investigating any alternatives.","","","","I prefer to have new API for better performance.","4"
"2019/02/27 6:34:48 AM AST","Other","India","6","5","C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer;Python","more than 10 years","more than 10 years","Numerical application and/or library;Visualization","Research and development of application(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Parallel Programming with MPI;Using MPI","MPICH;Open MPI;Intel MPI","I have no special reason.","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Performance tuning","","Point-to-point communications;Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","with the demand of production, it's difficult to spend significant time in learning and practising new APIs","Sometimes","Yes, to minimize the changes of communication API.","OpenMP;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Multi-threading support","","Process topologies","Yes, compatibility is very important for me.","4"
"2019/02/27 6:38:39 AM AST","Governmental institute","Greece","5","3","Fortran 90 or newer;Python","more than 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s)","I have not read it, but I plan to.","I read book(s).;I had lecture(s) at school.;I read articles found on Internet.","Using MPI","Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Point-to-point communications;Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","Point-to-point communications;Collective communications;MPI with OpenMP (or multithread)","MPI_THREAD_FUNNELED","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","No, MPI calls are scattered in my programs.","OpenMP","No, my MPI programs are well-tuned.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","One-sided communication;Datatypes;Communicator and group management;Collective operations;Process topologies;Dynamic process creation;Error handlers","I prefer to have new API which is simpler and/or easier-to-use.","3"
"2019/02/27 6:53:16 AM AST","College/University","France","6","5","C/C++;Python","more than 10 years","more than 10 years","Parallel language (incl. domain specific language);Numerical application and/or library","Research and development of application(s)","I have not read it, but I plan to.","I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","Parallel Programming with MPI","Open MPI;IBM MPI (BG/Q, PE, Spectrum)","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).","Algorithm design","PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on)","I have never called MPI_INIT_THREAD","Lack of time","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","OpenCL;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Endpoints (multi-thread, sessions)","There are no unnecessary features","I prefer to have new API for better performance.","5"
"2019/02/27 6:59:11 AM AST","College/University","France","4","4","Fortran 90 or newer;Python","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I read book(s).;I read articles found on Internet.","Using MPI","Open MPI;Intel MPI","I have no special reason.","I read online documents (such as man pages).","Implementation issue workaround","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes","I have never called MPI_INIT_THREAD","lack of time","I rely on the default ‘Errors abort’ error handling","No, MPI calls are scattered in my programs.","OpenMP","I do not know if there is room for performance tuning.","I am not investigating any alternatives.","MPI provides all semantics I need","","Dynamic process creation","Yes, compatibility is very important for me.","3"
"2019/02/27 6:59:28 AM AST","Private research institute","France","5","5","C/C++;Fortran 90 or newer;Python","more than 10 years","more than 10 years","Numerical application and/or library;AI (Deep Learning);Workflow and/or In-situ","Research and development of application(s);Performance tuning of MPI program(s);Debugging MPI programs","","Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Using MPI","MPICH;Open MPI;MVAPICH;Intel MPI;Cray MPI;IBM MPI (BG/Q, PE, Spectrum)","I have no special reason.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Implementation issue workaround","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_MULTIPLE","difference of implementation and behavior depending on the system. One thing works perfectly on one system and breaks down on another due to vendor tweaks.","Sometimes","Yes, to minimize the changes of communication API.","OpenMP;OpenACC;ompss","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A Domain Specific Language (DSL).;gaspi ","Multi-threading support","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","There are no unnecessary features","API should be clearly versioned.","4"
"2019/02/27 7:03:43 AM AST","College/University","France","5","4","C/C++;Python","between 5 and 10 years","between 2 and 5 years","Numerical application and/or library","Research and development of application(s)","No, and I will not read it.","I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","MPICH;Open MPI;Intel MPI","I have no special reason.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","MPI datatypes;Dynamic process creation;PMPI interface","Collective communications;Communicator operations (split, duplicate, and so on)","MPI_THREAD_SINGLE","I have no obstacles.","Never","No, my program is too small to do that.","No","I think there is room but I do not know how to tune it.","A framework or library using MPI.","Bandwidth","Another API which is easier and/or simpler to use","One-sided communication;Error handlers","Yes, compatibility is very important for me.","5"
"2019/02/27 7:24:33 AM AST","College/University","Luxembourg","5","5","C/C++;Python","between 5 and 10 years","between 5 and 10 years","System software development (OS, runtime library, communication library, etc.);Parallel language (incl. domain specific language);Numerical application and/or library;AI (Deep Learning)","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","","I read the MPI standard document.;I read book(s).;I had lecture(s) at school.","Parallel Programming with MPI","MPICH;Open MPI;Intel MPI","I am familiar with it.","I read the MPI Standard document (web/book).","Performance tuning","PMPI interface","Point-to-point communications;MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED","I have no obstacles.","Always","Yes, but I have no special reason for doing that.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.;A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","There are no unnecessary features","API should be clearly versioned.","4"
"2019/02/27 7:24:38 AM AST","College/University","Luxembourg","5","3","C/C++;Python;Common Lisp","more than 10 years","more than 10 years","Numerical application and/or library;AI (Deep Learning);Image processing;Big data","Research and development of application(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","","MPICH;Open MPI","I am familiar with it.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Performance tuning","One-sided communications;Dynamic process creation;Persistent communication;MPI with OpenMP (or multithread);PMPI interface","Point-to-point communications;Collective communications;MPI datatypes","I do not know or I do not care.","","Always","Yes, to minimize the changes of communication API.","Pthread;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.","","","","API should be clearly versioned.","4"
"2019/02/27 7:31:16 AM AST","Governmental institute","France","5","5","Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s);Performance tuning of MPI program(s);Debugging MPI programs","I read most of it.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).","Parallel Programming with MPI;Using MPI;MPI: The Complete Reference","Open MPI;Intel MPI;Cray MPI;IBM MPI (BG/Q, PE, Spectrum)","I have no special reason.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_MULTIPLE","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","No, MPI calls are scattered in my programs.","OpenMP;OpenACC","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.;A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","There are no unnecessary features","API should be clearly versioned.","3"
"2019/02/27 7:43:19 AM AST","College/University","France","4","4","Fortran 90 or newer","less than 2 years","less than 2 years","Numerical application and/or library","Research and development of application(s)","No, and I will not read it.","Other lectures or tutorials (workplace, conference).","I have never read any MPI books","MPICH;Open MPI","I have no special reason.","I read online documents (such as man pages).","Debugging","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;One-sided communications","I have never called MPI_INIT_THREAD","I have nobody to ask.","Never","No, MPI calls are scattered in my programs.","No","I think there is room but I do not know how to tune it.","","","","","Yes, compatibility is very important for me.","4"
"2019/02/27 7:48:32 AM AST","Software vendor","India","6","6","C/C++","more than 10 years","between 2 and 5 years","System software development (OS, runtime library, communication library, etc.);Numerical application and/or library;Tool development (performance tuning, debugging, etc.)","Research and development of application(s);Research and development software tool(s);Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Parallel Programming in C with MPI and OpenMP","Open MPI;Intel MPI;IBM MPI (BG/Q, PE, Spectrum)","I am familiar with it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Performance tuning","","Point-to-point communications;Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","I do not know or I do not care.","I have no obstacles.","Always","Yes, to minimize the changes of communication API.","OpenMP;Pthread;CUDA","No, my MPI programs are well-tuned.","A framework or library using MPI.;A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","","","","3"
"2019/02/27 7:51:03 AM AST","Private research institute","France","4","4","C/C++;Python","between 5 and 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s);Research and development software tool(s);Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","I have not read it, but I plan to.","Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","Open MPI;Intel MPI","I like to use it.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Performance tuning","Persistent communication","Point-to-point communications;Collective communications","I have never called MPI_INIT_THREAD","I have no obstacles.;No appropriate lecture / book / info.","Sometimes","Yes, to minimize the changes of communication API.","OpenMP;Pthread","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A framework or library using MPI.;A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Latency hiding (including asynchronous completion);Resilience (fault tolerance);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","There are no unnecessary features","I prefer to have new API for better performance.","3"
"2019/02/27 7:53:00 AM AST","Governmental institute","France","6","4","C/C++;Python","more than 10 years","between 5 and 10 years","Parallel language (incl. domain specific language);Bioinformatics","Research and development of application(s);Research and development software tool(s);Parallelization of sequential program(s);Performance tuning of MPI program(s)","I have not read it, but I plan to.","I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","MPICH;Open MPI;MadMPI","I have no special reason.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","One-sided communications;Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","No appropriate lecture / book / info.","Never","Yes, to minimize the changes of communication API.","OpenMP;Pthread","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.;A Domain Specific Language (DSL).","MPI provides all semantics I need","Another API which is easier and/or simpler to use","Communicator and group management;Process topologies;Dynamic process creation;Error handlers","I prefer to have new API which is simpler and/or easier-to-use.","3"
"2019/02/27 8:07:20 AM AST","Governmental institute","France","6","5","C/C++","more than 10 years","more than 10 years","Big data;cryptanalysis","Research and development of application(s)","I read most of it.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","I have never read any MPI books","Open MPI;MVAPICH;Intel MPI","I have no special reason.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).;I know almost all MPI routines.","Debugging","One-sided communications;Dynamic process creation;Persistent communication","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED;MPI_THREAD_SERIALIZED;MPI_THREAD_MULTIPLE","I do not like the API.;type signatures of many prototypes suck (int for sizes, missing const qualifiers, for instance).","Sometimes","No, MPI calls are scattered in my programs.","OpenMP;Pthread","Yes, I know there is room for tuning but I do not have enough resources to do that.","Low-level communication layer provided by vendor (Verbs, DCMF, ...).","Multi-threading support","","One-sided communication;Process topologies;Dynamic process creation;Error handlers","I prefer to have new API for better performance.","5"
"2019/02/27 8:27:54 AM AST","Governmental institute","France","5","5","C/C++;Fortran 90 or newer;Python","between 5 and 10 years","between 5 and 10 years","Numerical application and/or library;AI (Deep Learning)","Research and development of application(s);Research and development on system software (OS and/or runtime library);Performance tuning of MPI program(s);Debugging MPI programs;support","I read only the chapters of interest for my work.","I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I used online resources","","Open MPI;Intel MPI;IBM MPI (BG/Q, PE, Spectrum)","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).;I am quite familiar with part of the MPI routines","Algorithm design","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread);PMPI interface","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED;MPI_THREAD_SERIALIZED;MPI_THREAD_MULTIPLE","Too many routines.;for very specific problems, tasks or optimizations, the implementations are not well documented enough","Sometimes","I tried to, but such a design is not always easy to implement efficiently without losing too much in readablity","OpenMP;OpenACC;CUDA","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A framework or library using MPI.;A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).;A Domain Specific Language (DSL).","Multi-threading support","Resilience (fault tolerance);Another API which is easier and/or simpler to use","There are no unnecessary features","Yes, compatibility is very important for me.","3"
"2019/02/27 8:33:48 AM AST","College/University","France","4","1","Fortran 90 or newer","between 2 and 5 years","less than 2 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I had lecture(s) at school.","I have never read any MPI books","MPICH;Open MPI","I was said to use it.","I ask colleagues.;I search the Internet (Google / Stack Overflow).","Algorithm design","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;Dynamic process creation;Persistent communication;PMPI interface","","I do not know or I do not care.","I have no time","Sometimes","No, my program is too small to do that.","","I have no chance to investigate.","I am not investigating any alternatives.","Multi-threading support","","There are no unnecessary features","I prefer to have new API which is simpler and/or easier-to-use.","4"
"2019/02/27 8:40:58 AM AST","Software vendor","Denmark","5","3","C/C++;Python","more than 10 years","between 5 and 10 years","Numerical application and/or library;Workflow and/or In-situ","Research and development of application(s);Research and development software tool(s);Parallelization of sequential program(s);Performance tuning of MPI program(s)","","I read the MPI standard document.;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","MPICH;Intel MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes","MPI_THREAD_SINGLE;MPI_THREAD_SERIALIZED;MPI_THREAD_MULTIPLE","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","OpenMP;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Bandwidth","MPI is providing all the communication semantics required by my application","Dynamic process creation;Error handlers","I prefer to have new API for better performance.","3"
"2019/02/27 8:42:26 AM AST","College/University","France","6","5","C/C++","more than 10 years","more than 10 years","Parallel language (incl. domain specific language);Numerical application and/or library","Research and development of application(s)","I read most of it.","I read the MPI standard document.;I have not learned MPI.","MPI: A Message-Passing Interface Standard","MPICH;Open MPI;Intel MPI","","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).;I know almost all MPI routines.","Debugging","PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED;MPI_THREAD_SERIALIZED;MPI_THREAD_MULTIPLE","I have no obstacles.","","","Pthread;OpenACC","I do not know if there is room for performance tuning.","","Multi-threading support","Resilience (fault tolerance)","","I prefer to have new API for better performance.","3"
"2019/02/27 8:55:12 AM AST","Other","France","6","4","C/C++;Fortran (older one than Fortran 90);Python","more than 10 years","more than 10 years","Numerical application and/or library","Research and development software tool(s)","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).","I have never read any MPI books","Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I search the Internet (Google / Stack Overflow).","Debugging","PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on)","I have never called MPI_INIT_THREAD","Too complicated and hard to understand.;I do not like the API.","Sometimes","Yes, to minimize the changes of communication API.","OpenMP","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","I am not investigating any alternatives.","platform interoperability (run-time)","Another API which is easier and/or simpler to use;MPI is providing all the communication semantics required by my application","Datatypes","Yes, compatibility is very important for me.","3"
"2019/02/27 9:08:17 AM AST","College/University","Russia","3","4","C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer","more than 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s)","","I read book(s).","Parallel Programming with MPI","Intel MPI","I could not have any choice (the one provided by a vendor).","I read book(s) (except the MPI standard).","Domain decomposition","Point-to-point communications;Collective communications","Point-to-point communications;Collective communications","I have never called MPI_INIT_THREAD","No appropriate lecture / book / info.","Never","Yes, to minimize the changes of communication API.","CUDA","I think there is room but I do not know how to tune it.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","Collective operations","I do not know or I do not care.","3"
"2019/02/27 9:41:26 AM AST","Governmental institute","France","1","1","Python","less than 2 years","less than 2 years","AI (Deep Learning)","associate","","I read articles found on Internet.","","I do not know","I have no special reason.","I read the MPI Standard document (web/book).","Other","Persistent communication;MPI with OpenMP (or multithread)","Collective communications","I do not know or I do not care.","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","No, MPI calls are scattered in my programs.","","No, my MPI programs are well-tuned.","I am not investigating any alternatives.","MPI provides all semantics I need","Another API which is easier and/or simpler to use","Dynamic process creation","I do not know or I do not care.","1"
"2019/02/27 9:42:23 AM AST","Governmental institute","India","5","2","C/C++","between 5 and 10 years","less than 2 years","","Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).;I had lecture(s) at school.","MPI: The Complete Reference","MPICH;Open MPI;Intel MPI","I am familiar with it.","I read online documents (such as man pages).","Debugging","Communicator operations (split, duplicate, and so on);One-sided communications;Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes","I have never called MPI_INIT_THREAD","Other work","I rely on the default ‘Errors abort’ error handling","No, my program is too small to do that.","No","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Multi-threading support","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","There are no unnecessary features","I prefer to have new API for better performance.","3"
"2019/02/27 10:20:12 AM AST","Governmental institute","Russia","4","6","C/C++","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s);Parallelization of sequential program(s);Debugging MPI programs","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","А. С. Антонов ""Параллельное программирование с использованием технологии MPI""","MPICH;Open MPI;MS MPI","I am familiar with it.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).;I know almost all MPI routines.","Debugging","Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on)","I have never called MPI_INIT_THREAD","I have no obstacles.;renovations of MPI implementation (e.g. VisualStudio), need to adjust environment according to them","Sometimes","No, MPI calls are scattered in my programs.","OpenMP","I do not know if there is room for performance tuning.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Latency hiding (including asynchronous completion);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","One-sided communication;Dynamic process creation","Yes, compatibility is very important for me.","2"
"2019/02/27 10:45:21 AM AST","Governmental institute","France","6","5","C/C++;Fortran 90 or newer;Python","more than 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s);Performance tuning of MPI program(s)","I read most of it.","existing code + man pages","I have never read any MPI books","Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).","Algorithm design","Dynamic process creation;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on)","MPI_THREAD_SINGLE;I have never called MPI_INIT_THREAD","I have no obstacles.","Sometimes","Yes, to minimize the changes of communication API.","OpenMP","No, my MPI programs are well-tuned.","Low-level communication layer provided by vendor (Verbs, DCMF, ...).","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","One-sided communication;Datatypes","I prefer to have new API which is simpler and/or easier-to-use.","3"
"2019/02/27 11:10:31 AM AST","College/University","Italy","6","6","C/C++;Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library;AI (Deep Learning);Big data","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","I read only the chapters of interest for my work.","I read book(s).;I had lecture(s) at school.","Parallel Programming with MPI;Using MPI;Parallel Programming in C with MPI and OpenMP;MPI: The Complete Reference","MPICH;Intel MPI","I am familiar with it.","I read online documents (such as man pages).","Debugging","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes","MPI_THREAD_SINGLE","I have no obstacles.","Sometimes","Yes, to minimize the changes of communication API.","OpenMP;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","A Domain Specific Language (DSL).","Multi-threading support","Endpoints (multi-thread, sessions)","Communicator and group management;Dynamic process creation","Yes, compatibility is very important for me.","4"
"2019/02/27 11:25:32 AM AST","College/University","France","6","5","C/C++;Python","more than 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s);Research and development software tool(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).","","Open MPI;MVAPICH;Intel MPI","I have no special reason.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).","Debugging","Dynamic process creation;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_SERIALIZED","I have no obstacles.","Never","Yes, to minimize the changes of communication API.","OpenMP;OpenCL;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.;A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Latency hiding (including asynchronous completion)","One-sided communication;Dynamic process creation;Error handlers","API should be clearly versioned.","4"
"2019/02/27 11:28:27 AM AST","College/University","Luxembourg","3","1","C/C++;Python;R","between 5 and 10 years","less than 2 years","Parallel language (incl. domain specific language);Numerical application and/or library","Research and development software tool(s)","I have not read it, but I plan to.","I had lecture(s) at school.;I read articles found on Internet.","","Open MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Performance tuning","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;Dynamic process creation;Persistent communication;PMPI interface","MPI with OpenMP (or multithread)","I do not know or I do not care.","Too complicated and hard to understand.","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","No","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A framework or library using MPI.","Multi-threading support","Another API which is easier and/or simpler to use","One-sided communication;Datatypes;Communicator and group management;Collective operations","I prefer to have new API for better performance.","4"
"2019/02/27 11:54:41 AM AST","Private research institute","Russia","6","5","C/C++;Python","more than 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","","Open MPI;Intel MPI","I have no special reason.","I search the Internet (Google / Stack Overflow).","Finding appropriate MPI routines","Communicator operations (split, duplicate, and so on);PMPI interface","Point-to-point communications;Collective communications","I do not know or I do not care.","I have no obstacles.","Sometimes","No, MPI calls are scattered in my programs.","OpenMP;CUDA;Python","Yes, I know there is room for tuning but I do not have enough resources to do that.","","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","Dynamic process creation","I prefer to have new API for better performance.","4"
"2019/02/27 12:30:30 PM AST","College/University","Luxembourg","5","5","C/C++","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","No, and I will not read it.","I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.;manpage","I have never read any MPI books","Open MPI;MVAPICH;Intel MPI","I am familiar with it.","manpage","Algorithm design","Persistent communication","Point-to-point communications;Collective communications;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","I do not like the API.","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","OpenMP","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A framework or library using MPI.;A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Multi-threading support","Another API which is easier and/or simpler to use;Better C++ support (with testing and performance assessment)","Process topologies;Dynamic process creation;Error handlers","I prefer to have new API which is simpler and/or easier-to-use.","2"
"2019/02/27 1:02:42 PM AST","College/University","United States","6","4","Python;OCaml","more than 10 years","more than 10 years","Parallel language (incl. domain specific language);Tool development (performance tuning, debugging, etc.)","Research and development software tool(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).","Using MPI;MPI: The Complete Reference","MPICH;Open MPI","I have no special reason.","I read the MPI Standard document (web/book).","Other","PMPI interface","Point-to-point communications;Collective communications","I have never called MPI_INIT_THREAD","I have no obstacles.","Mostly","Yes, to minimize the changes of communication API.","No","I do not know if there is room for performance tuning.","A framework or library using MPI.;A Domain Specific Language (DSL).","Latency","MPI is providing all the communication semantics required by my application","One-sided communication;Dynamic process creation","I prefer to have new API which is simpler and/or easier-to-use.","2"
"2019/02/27 1:27:42 PM AST","Governmental institute","United States","6","4","C/C++;Python","between 5 and 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I had lecture(s) at school.;I read articles found on Internet.","I have never read any MPI books","Open MPI;IBM MPI (BG/Q, PE, Spectrum)","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_SERIALIZED","Incomplete specifications that leave room for interpretation and force me to look into implementation source code therefore worrying me about portability across implementations","Mostly","Yes, to minimize the changes of communication API.","OpenMP;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Multi-threading support","MPI is providing all the communication semantics required by my application","There are no unnecessary features","I prefer to have new API for better performance.","3"
"2019/02/27 1:28:27 PM AST","College/University","Poland","5","3","C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer","more than 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I read book(s).;Other lectures or tutorials (workplace, conference).","Parallel Programming with MPI;Using MPI","MPICH;Open MPI;Cray MPI","I could not have any choice (the one provided by a vendor).","I read book(s) (except the MPI standard).;I read online documents (such as man pages).","Algorithm design","","Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_MULTIPLE","No appropriate lecture / book / info.","Always","Yes, but I have no special reason for doing that.","No","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Multi-threading support","","There are no unnecessary features","API should be clearly versioned.","3"
"2019/02/27 1:38:58 PM AST","Governmental institute","United States","4","4","C/C++","more than 10 years","more than 10 years","Numerical application and/or library","Research and development software tool(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).;I read articles found on Internet.","Using MPI","Open MPI","I am familiar with it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).","Algorithm design","Dynamic process creation;MPI with OpenMP (or multithread)","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","No appropriate lecture / book / info.;I do not like the API.","Sometimes","No, MPI calls are scattered in my programs.","OpenMP;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","","","I prefer to have new API which is simpler and/or easier-to-use.","4"
"2019/02/27 2:10:09 PM AST","College/University","France","5","5","C/C++;Java;Python","more than 10 years","more than 10 years","System software development (OS, runtime library, communication library, etc.);Numerical application and/or library","Research and development of application(s);Research and development software tool(s);Parallelization of sequential program(s)","I have not read it, but I plan to.","I read articles found on Internet.","I have never read any MPI books","MPICH;Open MPI","I am familiar with it.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Communicator operations (split, duplicate, and so on);Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD;I do not know or I do not care.","No appropriate lecture / book / info.","Always","No, MPI calls are scattered in my programs.","OpenMP;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","MPI is providing all the communication semantics required by my application","Process topologies;Dynamic process creation","Yes, compatibility is very important for me.","5"
"2019/02/27 2:15:28 PM AST","College/University","Portugal","4","3","C/C++;Java;Python","more than 10 years","between 2 and 5 years","Parallel language (incl. domain specific language);Tool development (performance tuning, debugging, etc.)","Research and development of application(s);Research and development on system software (OS and/or runtime library);Parallelization of sequential program(s)","I read only the chapters of interest for my work.","I had lecture(s) at school.;I read articles found on Internet.","Parallel Programming with MPI","Open MPI","I am familiar with it.","I read the MPI Standard document (web/book).","Debugging","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes","I have never called MPI_INIT_THREAD;I do not know or I do not care.","","Sometimes","Yes, to minimize the changes of communication API.","No","I do not know how to find bottlenecks.","A framework or library using MPI.","Latency","Latency hiding (including asynchronous completion)","One-sided communication","Yes, compatibility is very important for me.","3"
"2019/02/27 2:23:50 PM AST","Governmental institute","France","6","3","C/C++;Python","more than 10 years","between 2 and 5 years","Numerical application and/or library","Researcher","I have not read it, but I plan to.","I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","MPICH;Open MPI;Intel MPI","I am familiar with it.","I read book(s) (except the MPI standard).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Debugging","Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;Dynamic process creation","MPI_THREAD_SINGLE","Too complicated and hard to understand.;I have nobody to ask.","Mostly","Yes, to minimize the changes of communication API.","No","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","MPI provides all semantics I need","","Process topologies","Yes, compatibility is very important for me.","3"
"2019/02/27 2:50:22 PM AST","Private research institute","belgium","5","4","C/C++;Python","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s)","No, and I will not read it.","I read articles found on Internet.","I have never read any MPI books","MPICH;Open MPI;MVAPICH;Intel MPI;IBM MPI (BG/Q, PE, Spectrum)","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I know almost all MPI routines.","Performance tuning","Dynamic process creation","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","","","Mostly","Yes, to minimize the changes of communication API.","OpenMP","","A framework or library using MPI.","","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","Process topologies;Dynamic process creation","Yes, compatibility is very important for me.","3"
"2019/02/27 2:51:30 PM AST","Governmental institute","United States","5","4","C/C++","between 5 and 10 years","less than 2 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I had lecture(s) at school.","","Intel MPI","I like to use it.","I read online documents (such as man pages).","Domain decomposition","Point-to-point communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;Persistent communication","Communicator operations (split, duplicate, and so on)","I do not know or I do not care.","No appropriate lecture / book / info.;Too complicated and hard to understand.;incomplete specifications","I rely on the default ‘Errors abort’ error handling","Yes, but I have no special reason for doing that.","No","I do not have (know) tools to find performance bottlenecks.","I am not investigating any alternatives.","","","","I do not know or I do not care.","3"
"2019/02/27 2:54:19 PM AST","College/University","France","6","5","C/C++;Python","more than 10 years","between 5 and 10 years","System software development (OS, runtime library, communication library, etc.);Numerical application and/or library","Parallelization of sequential program(s)","I read most of it.","I read the MPI standard document.;I had lecture(s) at school.","MPI: The Complete Reference","MPICH;Open MPI;MVAPICH;Intel MPI","I am familiar with it.","I read the MPI Standard document (web/book).","Algorithm design","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;Persistent communications;MPI with OpenMP (or multithread)","MPI_THREAD_SERIALIZED;MPI_THREAD_MULTIPLE","I have no obstacles.","Always","Yes, to minimize the changes of communication API.","OpenMP;Pthread","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","MPI is providing all the communication semantics required by my application","One-sided communication;Process topologies","API should be clearly versioned.","3"
"2019/02/27 2:55:00 PM AST","College/University","Russia","2","2","C/C++;Fortran 90 or newer;Python","more than 10 years","less than 2 years","System software development (OS, runtime library, communication library, etc.);Parallel language (incl. domain specific language);Big data","Research and development of application(s);Research and development on system software (OS and/or runtime library);Research and development software tool(s);Parallelization of sequential program(s)","","I read the MPI standard document.","I have never read any MPI books","I do not know","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).","Algorithm design","Point-to-point communications","Collective communications;Dynamic process creation","MPI_THREAD_SINGLE;MPI_THREAD_SERIALIZED","I have no obstacles.","","Yes, to minimize the changes of communication API.","OpenCL","I do not have (know) tools to find performance bottlenecks.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Bandwidth","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","Process topologies","I prefer to have new API which is simpler and/or easier-to-use.","3"
"2019/02/27 3:00:33 PM AST","College/University","France","4","4","Java;Python","more than 10 years","more than 10 years","System software development (OS, runtime library, communication library, etc.);Big data;Tool development (performance tuning, debugging, etc.)","Research and development of application(s);Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Parallel Programming in C with MPI and OpenMP;MPI: The Complete Reference","MPICH;Open MPI","I am familiar with it.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation","Point-to-point communications;Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","I do not know or I do not care.","Today I use it only occasionally","Mostly","Yes, but I have no special reason for doing that.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Resilience (fault tolerance);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","There are no unnecessary features","I prefer to have new API which is simpler and/or easier-to-use.","2"
"2019/02/27 3:10:13 PM AST","Private research institute","United States","5","2","C/C++","between 5 and 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s);Research and development software tool(s)","No, and I will not read it.","Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","Open MPI;IBM MPI (BG/Q, PE, Spectrum)","I am familiar with it.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation","Point-to-point communications;Collective communications;MPI with OpenMP (or multithread)","MPI_THREAD_SERIALIZED","I do not like the API.","Never","Yes, to minimize the changes of communication API.","OpenMP;CUDA","I think there is room but I do not know how to tune it.","A framework or library using MPI.","","MPI is providing all the communication semantics required by my application","There are no unnecessary features","I prefer to have new API which is simpler and/or easier-to-use.","1"
"2019/02/27 3:52:26 PM AST","College/University","France","5","3","C/C++;Java","more than 10 years","between 2 and 5 years","System software development (OS, runtime library, communication library, etc.);Parallel language (incl. domain specific language);Big data","Research and development of application(s)","I have not read it, but I plan to.","I read book(s).;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Using MPI","MPICH;Open MPI;mpi4py","I was said to use it.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Implementation issue workaround","PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;Dynamic process creation;MPI with OpenMP (or multithread)","I do not know or I do not care.","No appropriate lecture / book / info.","Sometimes","Yes, to minimize the changes of communication API.","OpenMP","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A framework or library using MPI.","MPI provides all semantics I need","Resilience (fault tolerance)","There are no unnecessary features","API should be clearly versioned.","3"
"2019/02/27 5:08:19 PM AST","College/University","Russia","5","4","C/C++;Java;Python","between 5 and 10 years","between 2 and 5 years","System software development (OS, runtime library, communication library, etc.);Parallel language (incl. domain specific language);Numerical application and/or library;AI (Deep Learning);Image processing;Tool development (performance tuning, debugging, etc.)","Research and development of application(s);Research and development on system software (OS and/or runtime library)","I read only the chapters of interest for my work.","I read the MPI standard document.;I had lecture(s) at school.;I read articles found on Internet.","","MPICH;Open MPI;Intel MPI;MS MPI","I have no special reason.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","One-sided communications;Dynamic process creation;Persistent communication","Point-to-point communications;Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","I have no obstacles.","Always","Yes, to minimize the changes of communication API.","OpenMP;Pthread;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.;NCCL","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","There are no unnecessary features","API should be clearly versioned.","4"
"2019/02/27 5:16:44 PM AST","Other","France","5","3","C/C++;Python","between 5 and 10 years","between 5 and 10 years","Numerical application and/or library;Big data;Visualization","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","I have not read it, but I plan to.","I had lecture(s) at school.;I read articles found on Internet.","Using MPI","Open MPI;Intel MPI","I like to use it.","I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Algorithm design","PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_FUNNELED;MPI_THREAD_SERIALIZED;MPI_THREAD_MULTIPLE","Too many routines.;Too complicated and hard to understand.;I do not like the API.","Never","Yes, to minimize the changes of communication API.","OpenMP","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","Task-based runtime systems","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Latency hiding (including asynchronous completion);Endpoints (multi-thread, sessions);Resilience (fault tolerance);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","Process topologies","I prefer to have new API which is simpler and/or easier-to-use.","4"
"2019/02/27 5:17:18 PM AST","Other","France","6","6","C/C++;C# (through c bindings) ","more than 10 years","more than 10 years","Parallel language (incl. domain specific language);Numerical application and/or library;Big data;Workflow and/or In-situ;Visualization;Tool development (performance tuning, debugging, etc.)","Research and development of application(s);Research and development on system software (OS and/or runtime library);Research and development software tool(s);Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","I read only the chapters of interest for my work.","I read the MPI standard document.;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","I have never read any MPI books","MPICH;Open MPI;Intel MPI;MS MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).;I know almost all MPI routines.","Performance tuning","PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;Persistent communications;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_SERIALIZED;MPI_THREAD_MULTIPLE","I have no obstacles.;I do not like the API.","Always","Yes, to minimize the changes of communication API.","OpenMP;Pthread;CUDA;Tbb","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.;A Domain Specific Language (DSL).;Task runtimes such as starpu","Latency","Resilience (fault tolerance);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.);Possibility to dynamically change the communicators topology upon machine failure or addition","There are no unnecessary features","I prefer to have new API for better performance.","3"
"2019/02/27 8:07:31 PM AST","Governmental institute","Korea, South","6","5","Fortran (older one than Fortran 90)","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s)","I read all.","I read book(s).","Parallel Programming with MPI;Parallel Programming in C with MPI and OpenMP","Intel MPI","I have no special reason.","I read online documents (such as man pages).","Performance tuning","Dynamic process creation","Point-to-point communications","I have never called MPI_INIT_THREAD","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","No, my program is too small to do that.","OpenMP","No, my MPI programs are well-tuned.","A framework or library using MPI.","Latency","Latency hiding (including asynchronous completion)","Dynamic process creation;Error handlers","Yes, compatibility is very important for me.","4"
"2019/02/27 8:41:17 PM AST","Governmental institute","Korea, South","5","3","C/C++;Python","more than 10 years","less than 2 years","Parallel language (incl. domain specific language);AI (Deep Learning);Image processing","Research and development of application(s);Parallelization of sequential program(s)","I read only the chapters of interest for my work.","I read articles found on Internet.","I have never read any MPI books","Open MPI","I have no special reason.","I search the Internet (Google / Stack Overflow).","Performance tuning","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","Too many routines.;Too complicated and hard to understand.","Never","No, MPI calls are scattered in my programs.","OpenMP;CUDA","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A framework or library using MPI.","Latency","Latency hiding (including asynchronous completion);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","There are no unnecessary features","Yes, compatibility is very important for me.","4"
"2019/02/27 8:45:24 PM AST","Governmental institute","Japan","5","4","C/C++;Fortran 90 or newer;Python","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I read book(s).;Other lectures or tutorials (workplace, conference).","Using MPI;MPI: The Complete Reference","Open MPI;Fujistu MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).;I read online documents (such as man pages).","","","Point-to-point communications;Collective communications;MPI with OpenMP (or multithread)","MPI_THREAD_SERIALIZED","I have no obstacles.","Never","No, MPI calls are scattered in my programs.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.","","","There are no unnecessary features","Yes, compatibility is very important for me.","3"
"2019/02/27 8:46:52 PM AST","Governmental institute","Korea, South","3","3","","between 5 and 10 years","less than 2 years","System software development (OS, runtime library, communication library, etc.);Tool development (performance tuning, debugging, etc.)","Research and development of application(s)","","I read book(s).;I read articles found on Internet.","Beginning MPI (An Introduction in C)","Open MPI;Intel MPI","I was said to use it.","I read book(s) (except the MPI standard).","Finding appropriate MPI routines","Dynamic process creation","MPI with OpenMP (or multithread)","MPI_THREAD_MULTIPLE","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","No","I do not know how to find bottlenecks.","I am not investigating any alternatives.","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","Dynamic process creation","I do not know or I do not care.","4"
"2019/02/27 8:57:30 PM AST","College/University","Korea, South","6","4","C/C++;Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I read book(s).","Parallel Programming with MPI","Open MPI;Intel MPI","I like to use it.","I read the MPI Standard document (web/book).","Implementation issue workaround","Dynamic process creation;Persistent communication","Point-to-point communications;Collective communications;MPI datatypes;One-sided communications","I have never called MPI_INIT_THREAD","I have no obstacles.","","No, MPI calls are scattered in my programs.","No","No, my MPI programs are well-tuned.","I am not investigating any alternatives.","Bandwidth","MPI is providing all the communication semantics required by my application","There are no unnecessary features","Yes, compatibility is very important for me.","2"
"2019/02/27 9:07:13 PM AST","Governmental institute","Korea, South","4","2","C/C++;Python","more than 10 years","less than 2 years","Numerical application and/or library","Data Scientist","I read only the chapters of interest for my work.","I read articles found on Internet.","I have never read any MPI books","Open MPI;Intel MPI","I was said to use it.","","Algorithm design","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);One-sided communications;Dynamic process creation;Persistent communication;PMPI interface","MPI with OpenMP (or multithread)","I do not know or I do not care.","No appropriate lecture / book / info.;Too complicated and hard to understand.;I have nobody to ask.","Never","No, my program is too small to do that.","No","I think there is room but I do not know how to tune it.","I am not investigating any alternatives.","Multi-threading support","Another API which is easier and/or simpler to use","","I do not know or I do not care.","1"
"2019/02/27 9:08:13 PM AST","Governmental institute","Korea, South","5","4","C/C++;Java","between 5 and 10 years","less than 2 years","System software development (OS, runtime library, communication library, etc.);Parallel language (incl. domain specific language)","Research and development on system software (OS and/or runtime library)","I read only the chapters of interest for my work.","I read book(s).;Other lectures or tutorials (workplace, conference).","MPI 병렬 프로그래밍","Open MPI;MVAPICH","I have no special reason.","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Performance tuning","Communicator operations (split, duplicate, and so on);Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes","I do not know or I do not care.","I have nobody to ask.","I rely on the default ‘Errors abort’ error handling","No, my program is too small to do that.","OpenMP","I do not know if there is room for performance tuning.","I am not investigating any alternatives.","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Another API which is easier and/or simpler to use","There are no unnecessary features","Yes, compatibility is very important for me.","5"
"2019/02/27 9:15:22 PM AST","Governmental institute","Korea, South","4","4","Fortran 90 or newer","between 5 and 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s)","I have not read it, but I plan to.","Other lectures or tutorials (workplace, conference).","MPI 병렬 프로그래밍","Intel MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).","Finding appropriate MPI routines","PMPI interface","Communicator operations (split, duplicate, and so on)","MPI_THREAD_SERIALIZED","No appropriate lecture / book / info.","Always","Yes, to minimize the changes of communication API.","No","I think there is room but I do not know how to tune it.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","There are no unnecessary features","Yes, compatibility is very important for me.","5"
"2019/02/27 9:19:00 PM AST","College/University","Korea, South","6","5","Fortran 90 or newer","more than 10 years","between 5 and 10 years","Numerical application and/or library;Big data","Research and development of application(s)","I have not read it, but I plan to.","I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","Parallel Programming with MPI;Using MPI","Open MPI;MVAPICH;Intel MPI","I like to use it.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Domain decomposition","Dynamic process creation;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","No appropriate lecture / book / info.","Always","Yes, but I have no special reason for doing that.","OpenMP","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","I am not investigating any alternatives.","Multi-threading support","Endpoints (multi-thread, sessions)","There are no unnecessary features","Yes, compatibility is very important for me.","5"
"2019/02/27 9:26:14 PM AST","Private research institute","France","3","3","C/C++;Python","more than 10 years","more than 10 years","System software development (OS, runtime library, communication library, etc.)","Research and development of application(s)","I have not read it, but I plan to.","I have not learned MPI.","","I do not know","I have no special reason.","I search the Internet (Google / Stack Overflow).","Performance tuning","Collective communications","Point-to-point communications;Collective communications","I do not know or I do not care.","I do not like the API.","Never","Yes, but I have no special reason for doing that.","Pthread","I have no chance to investigate.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Another API which is easier and/or simpler to use","One-sided communication","API should be clearly versioned.","5"
"2019/02/27 9:26:22 PM AST","Governmental institute","Korea, South","4","2","C/C++;Python","more than 10 years","more than 10 years","System software development (OS, runtime library, communication library, etc.);Tool development (performance tuning, debugging, etc.)","Research and development of application(s);Research and development on system software (OS and/or runtime library)","I have not read it, but I plan to.","I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","I have never read any MPI books","MPICH;MVAPICH","I have no special reason.","I search the Internet (Google / Stack Overflow).","Debugging","Communicator operations (split, duplicate, and so on);One-sided communications;Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes","I do not know or I do not care.","I do not like the API.","I rely on the default ‘Errors abort’ error handling","No, MPI calls are scattered in my programs.","No","No, my MPI programs are well-tuned.","I am not investigating any alternatives.","","","","","3"
"2019/02/27 9:38:32 PM AST","College/University","Korea, South","5","5","Fortran (older one than Fortran 90);Fortran 90 or newer","between 5 and 10 years","between 5 and 10 years","cfd","Research and development of application(s)","I read only the chapters of interest for my work.","I read book(s).;I read articles found on Internet.","","MVAPICH","I have no special reason.","I search the Internet (Google / Stack Overflow).","Debugging","","Point-to-point communications;Collective communications","I do not know or I do not care.","I have no obstacles.","Mostly","Yes, to minimize the changes of communication API.","OpenMP;CUDA","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","I am not investigating any alternatives.","Bandwidth","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","There are no unnecessary features","I do not know or I do not care.","3"
"2019/02/27 9:48:53 PM AST","College/University","Korea, South","6","5","C/C++;Python","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","MPI: The Complete Reference","MPICH;Open MPI;MVAPICH;Intel MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED","No appropriate lecture / book / info.;I have nobody to ask.","Mostly","Yes, to minimize the changes of communication API.","OpenMP","No, my MPI programs are well-tuned.","I am not investigating any alternatives.","Multi-threading support","Endpoints (multi-thread, sessions);Another API which is easier and/or simpler to use","Error handlers","I prefer to have new API for better performance.","5"
"2019/02/27 9:49:08 PM AST","Governmental institute","Korea, South","5","5","C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer;Python","more than 10 years","more than 10 years","Parallel language (incl. domain specific language);Numerical application and/or library","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Parallel Programming in C with MPI and OpenMP","Open MPI;MVAPICH;Intel MPI","I am familiar with it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).","Performance tuning","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED","No appropriate lecture / book / info.;finding examples for the new and advanced functions","Sometimes","Yes, but I have no special reason for doing that.","OpenMP","Application performance varies according to the combination of MPI functions, so it is highly required to select apropriate ones.","I am not investigating any alternatives.","Latency","Latency hiding (including asynchronous completion);Another API which is easier and/or simpler to use","Dynamic process creation","I prefer to have new API which is simpler and/or easier-to-use.","4"
"2019/02/27 10:08:41 PM AST","College/University","Korea, South","5","4","C/C++;Java;MATLAB","more than 10 years","between 5 and 10 years","Numerical application and/or library;Image processing","Research and development of application(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I read articles found on Internet.","I have never read any MPI books","Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes","I do not know or I do not care.","I have nobody to ask.","Sometimes","Yes, but I have no special reason for doing that.","No","I do not know how to find bottlenecks.","A framework or library using MPI.","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","MPI is providing all the communication semantics required by my application","Process topologies;Dynamic process creation","I prefer to have new API for better performance.","4"
"2019/02/27 10:13:21 PM AST","Governmental institute","Korea, South","6","4","C/C++;Python","more than 10 years","between 5 and 10 years","Tool development (performance tuning, debugging, etc.)","Research and development of application(s)","I read only the chapters of interest for my work.","I read articles found on Internet.","I have never read any MPI books","Open MPI","I could not have any choice (the one provided by a vendor).","I search the Internet (Google / Stack Overflow).","Finding appropriate MPI routines","MPI with OpenMP (or multithread)","Point-to-point communications","I do not know or I do not care.","","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","No","I do not have (know) tools to find performance bottlenecks.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Another API which is easier and/or simpler to use","There are no unnecessary features","Yes, compatibility is very important for me.","3"
"2019/02/27 10:23:08 PM AST","Governmental institute","Korea, South","3","2","C/C++","more than 10 years","less than 2 years","Numerical application and/or library","Research and development of application(s)","I have not read it, but I plan to.","Other lectures or tutorials (workplace, conference).","Using MPI","Open MPI","I like to use it.","I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Finding appropriate MPI routines","Dynamic process creation","MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","No appropriate lecture / book / info.","I rely on the default ‘Errors abort’ error handling","No, my program is too small to do that.","No","I do not know if there is room for performance tuning.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","There are no unnecessary features","I do not know or I do not care.","3"
"2019/02/27 10:26:02 PM AST","Governmental institute","Korea, South","5","4","C/C++;Fortran 90 or newer;Python","more than 10 years","more than 10 years","Big data;Atmospheric circulation modeling","Research and development of application(s)","I read only the chapters of interest for my work.","I read book(s).;I read articles found on Internet.","Parallel Programming with MPI;Using MPI","MPICH;Intel MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).;I search the Internet (Google / Stack Overflow).","Performance tuning","Persistent communication","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes","MPI_THREAD_SINGLE","No appropriate lecture / book / info.;I have nobody to ask.","Mostly","Yes, to minimize the changes of communication API.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","There are no unnecessary features","I prefer to have new API for better performance.","3"
"2019/02/27 10:39:41 PM AST","Governmental institute","United States","6","5","C/C++;UPC","more than 10 years","more than 10 years","System software development (OS, runtime library, communication library, etc.);Parallel language (incl. domain specific language)","Research and development on system software (OS and/or runtime library);Developing alternative programming models to MPI","I read most of it.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).","I have never read any MPI books","MPICH;Open MPI;MVAPICH;Intel MPI;Cray MPI;IBM MPI (BG/Q, PE, Spectrum)","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I know almost all MPI routines.","Implementation issue workaround","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);One-sided communications","MPI_THREAD_SINGLE;MPI_THREAD_SERIALIZED;MPI_THREAD_MULTIPLE","I have no obstacles.;Too many routines.;I do not like the API.","Always","Yes, to minimize the changes of communication API.","Pthread;UPC, UPC++","Yes, I know there is room for tuning but I do not have enough resources to do that.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).;Low-level communication layer provided by vendor (Verbs, DCMF, ...).","Better passive-target MPI RMA performance. Better MPI_THREAD_MULTIPLE performance.","Latency hiding (including asynchronous completion);Endpoints (multi-thread, sessions);Expose de-aggregated (eg Request-based) REMOTE completion for individual MPI_PUT operations. Allow Accumulate/Fetch-op to concurrently perform different computational operations on a single location (eg fetch-add racing with swap or compare-swap)","Process topologies;Dynamic process creation;I/O","Yes, compatibility is very important for me.","1"
"2019/02/27 10:56:01 PM AST","College/University","Korea, South","5","5","Fortran 90 or newer","between 5 and 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s)","No, and I will not read it.","Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","Open MPI;Intel MPI;MS MPI","I have no special reason.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","One-sided communications;Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications","I have never called MPI_INIT_THREAD;I do not know or I do not care.","No appropriate lecture / book / info.;Too complicated and hard to understand.","Never","No, MPI calls are scattered in my programs.","No","I do not have (know) tools to find performance bottlenecks.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","There are no unnecessary features","Yes, compatibility is very important for me.","4"
"2019/02/27 10:57:45 PM AST","Other","India","4","2","Python","more than 10 years","between 2 and 5 years","Image processing;Big data","Research and development of application(s);Research and development software tool(s)","No, and I will not read it.","I have not learned MPI.","","Open MPI","I could not have any choice (the one provided by a vendor).","I ask colleagues.","Finding appropriate MPI routines","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);One-sided communications;Dynamic process creation;PMPI interface","MPI with OpenMP (or multithread)","MPI_THREAD_MULTIPLE","Too complicated and hard to understand.","Never","No, my program is too small to do that.","","I do not know if there is room for performance tuning.","","","","","","4"
"2019/02/27 11:01:56 PM AST","College/University","Korea, South","2","1","Java;Python","less than 2 years","less than 2 years","Big data","Research and development of application(s)","","I read the MPI standard document.;I read articles found on Internet.","Beginning MPI (An Introduction in C)","MPICH","I like to use it.","I read the MPI Standard document (web/book).;I search the Internet (Google / Stack Overflow).","Domain decomposition","Communicator operations (split, duplicate, and so on);MPI datatypes;Dynamic process creation;Persistent communication","Communicator operations (split, duplicate, and so on);MPI datatypes;Dynamic process creation;Persistent communications","MPI_THREAD_SINGLE","Too many routines.","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","No","No, my MPI programs are well-tuned.","A framework or library using MPI.;A Domain Specific Language (DSL).;Low-level communication layer provided by vendor (Verbs, DCMF, ...).","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Resilience (fault tolerance);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.);Another API which is easier and/or simpler to use;MPI is providing all the communication semantics required by my application","Collective operations;Process topologies","Yes, compatibility is very important for me.","2"
"2019/02/27 11:18:47 PM AST","College/University","Korea, South","4","3","C/C++","between 2 and 5 years","less than 2 years","Image processing","Parallelization of sequential program(s)","I read only the chapters of interest for my work.","I read book(s).","MPI 병렬프로그래밍","Open MPI","I was said to use it.","I read book(s) (except the MPI standard).","Finding appropriate MPI routines","Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes","I have never called MPI_INIT_THREAD","No appropriate lecture / book / info.;Too complicated and hard to understand.","Sometimes","No, my program is too small to do that.","No","I have no chance to investigate.","A framework or library using MPI.","Latency","Endpoints (multi-thread, sessions)","There are no unnecessary features","Yes, compatibility is very important for me.","5"
"2019/02/28 12:17:38 AM AST","Governmental institute","Korea, South","5","5","C/C++;Fortran 90 or newer","more than 10 years","between 5 and 10 years","Parallel language (incl. domain specific language)","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","I read book(s).;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Using MPI","MPICH;Open MPI;MVAPICH;Intel MPI","I am familiar with it.","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).;I read online documents (such as man pages).","Performance tuning","Persistent communication","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE","","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","OpenMP;OpenACC;CUDA","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","Dynamic process creation","Yes, compatibility is very important for me.","3"
"2019/02/28 1:16:44 AM AST","Governmental institute","India","5","3","C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer;Python","between 5 and 10 years","between 2 and 5 years","System software development (OS, runtime library, communication library, etc.);Parallel language (incl. domain specific language);Numerical application and/or library","Research and development on system software (OS and/or runtime library);Research and development software tool(s);Parallelization of sequential program(s);Debugging MPI programs","I read most of it.","I read the MPI standard document.;I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","Beginning MPI (An Introduction in C);Parallel Programming in C with MPI and OpenMP","Open MPI;MVAPICH;Intel MPI","I am familiar with it.","I read the MPI Standard document (web/book).;I know almost all MPI routines.","Performance tuning","","Communicator operations (split, duplicate, and so on);MPI datatypes;Persistent communications;MPI with OpenMP (or multithread)","MPI_THREAD_SERIALIZED","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","Yes, but I have no special reason for doing that.","OpenMP;Pthread;OpenACC;CUDA","I do not know if there is room for performance tuning.","A Domain Specific Language (DSL).","","","","Yes, compatibility is very important for me.","5"
"2019/02/28 1:49:39 AM AST","College/University","Japan","5","3","Fortran (older one than Fortran 90);Fortran 90 or newer","more than 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I read the MPI standard document.","documents by computer venders","MPICH;Open MPI;Intel MPI;Fujistu MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).","Performance tuning","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on)","I have never called MPI_INIT_THREAD","Too complicated and hard to understand.","","Yes, to minimize the changes of communication API.","No","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A framework or library using MPI.","Latency","Another API which is easier and/or simpler to use;MPI is providing all the communication semantics required by my application","Dynamic process creation","Yes, compatibility is very important for me.","3"
"2019/02/28 2:15:43 AM AST","Governmental institute","India","5","3","C/C++","more than 10 years","between 2 and 5 years","System software development (OS, runtime library, communication library, etc.)","Research and development on system software (OS and/or runtime library);Research and development software tool(s);Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).","","MPICH;MVAPICH;Intel MPI","I am familiar with it.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","","Point-to-point communications;Collective communications","","Limited lectures/tutorials are available online ","","","OpenMP;Pthread","I do not have (know) tools to find performance bottlenecks.","","","","","I do not know or I do not care.","3"
"2019/02/28 3:51:07 AM AST","Governmental institute","Germany","5","5","C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer","more than 10 years","between 5 and 10 years","System software development (OS, runtime library, communication library, etc.);Parallel language (incl. domain specific language);Numerical application and/or library;AI (Deep Learning);Tool development (performance tuning, debugging, etc.)","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","","I read the MPI standard document.;I read book(s).;Other lectures or tutorials (workplace, conference).","Parallel Programming in C with MPI and OpenMP;MPI: The Complete Reference","MPICH;Open MPI;Intel MPI","I am familiar with it.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","Too many routines.","Sometimes","","OpenMP;Pthread;CUDA","","A framework or library using MPI.;A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).;Low-level communication layer provided by vendor (Verbs, DCMF, ...).","","","","",""
"2019/02/28 3:52:13 AM AST","Governmental institute","Japan","5","5","C/C++;Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library;Workflow and/or In-situ","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","","Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","MPICH;Open MPI;MVAPICH;Intel MPI;Fujistu MPI","I like to use it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","Persistent communication","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_SERIALIZED","I have no obstacles.","Sometimes","No, MPI calls are scattered in my programs.","OpenMP;OpenACC","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Another API which is easier and/or simpler to use","Dynamic process creation","Yes, compatibility is very important for me.","2"
"2019/02/28 4:02:06 AM AST","College/University","France","5","5","Fortran 90 or newer;Python","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s)","","Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Using MPI","MPICH;Open MPI;Intel MPI;IBM MPI (BG/Q, PE, Spectrum);BULLMPI","I could not have any choice (the one provided by a vendor).","I read book(s) (except the MPI standard).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).;I know almost all MPI routines.","Debugging","Dynamic process creation;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);Persistent communications;MPI with OpenMP (or multithread)","MPI_THREAD_MULTIPLE","I have no obstacles.","Never","Yes, to minimize the changes of communication API.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Latency","Latency hiding (including asynchronous completion)","Dynamic process creation","Yes, compatibility is very important for me.","5"
"2019/02/28 4:08:39 AM AST","Governmental institute","Russia","3","2","C/C++;Python","between 5 and 10 years","between 2 and 5 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).","Bogachev K.Yu. The basics of parallel programming. - M.: Binom, 2003","Open MPI","I like to use it.","I read the MPI Standard document (web/book).","Performance tuning","Communicator operations (split, duplicate, and so on);Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI with OpenMP (or multithread);MPI I/O","I have never called MPI_INIT_THREAD","Need time and appropriate book, which contains philosophy, ideas and solutions of rather complex tasks","Mostly","Sometimes, to simplify and unify (in non MPI mode) communications","OpenMP","I think there is room but I do not know how to tune it.","I am not investigating any alternatives.","MPI provides all semantics I need","Another API which is easier and/or simpler to use;MPI is providing all the communication semantics required by my application;Exceptions support in C++","Datatypes","I prefer to have new API for better performance.","4"
"2019/02/28 4:19:44 AM AST","Governmental institute","France","5","4","C/C++;Perl","more than 10 years","more than 10 years","System software development (OS, runtime library, communication library, etc.)","Research and development on system software (OS and/or runtime library);Research and development software tool(s)","No, and I will not read it.","I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","MPICH;Open MPI;BullMPI","I am familiar with it.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Performance tuning","Persistent communication","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);PMPI interface","MPI_THREAD_MULTIPLE","Too many routines.","Sometimes","No, MPI calls are scattered in my programs.","Pthread","I do not know if there is room for performance tuning.","A framework or library using MPI.","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","Datatypes;Dynamic process creation","I do not know or I do not care.","4"
"2019/02/28 4:42:54 AM AST","Other","France","3","4","C/C++","between 5 and 10 years","between 5 and 10 years","Parallel language (incl. domain specific language)","Debugging MPI programs","I read only the chapters of interest for my work.","I had lecture(s) at school.","I have never read any MPI books","MPICH;Open MPI;Intel MPI;Cray MPI","I have no special reason.","I read the MPI Standard document (web/book).","Performance tuning","Dynamic process creation","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE","Too complicated and hard to understand.","Never","No, my program is too small to do that.","OpenMP","I do not know if there is room for performance tuning.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","MPI is providing all the communication semantics required by my application","Dynamic process creation","Yes, compatibility is very important for me.","3"
"2019/02/28 4:43:18 AM AST","College/University","France","6","4","Fortran 90 or newer;Python","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s);Research and development software tool(s);Parallelization of sequential program(s)","","I read the MPI standard document.;I read articles found on Internet.","","MPICH;Open MPI;Intel MPI;IBM MPI (BG/Q, PE, Spectrum)","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Domain decomposition","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","Too many routines.;Too complicated and hard to understand.;I do not like the API.","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","OpenMP","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A framework or library using MPI.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","Process topologies;Dynamic process creation","I prefer to have new API which is simpler and/or easier-to-use.","2"
"2019/02/28 4:47:58 AM AST","Governmental institute","France","3","2","C/C++;Fortran 90 or newer;Python","less than 2 years","less than 2 years","Numerical application and/or library","Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","I have not read it, but I plan to.","I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","Open MPI;HPE MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Debugging","Communicator operations (split, duplicate, and so on);Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI with OpenMP (or multithread)","I do not know or I do not care.","","Sometimes","","OpenACC;CUDA","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","I am not investigating any alternatives.","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Resilience (fault tolerance)","Process topologies","I prefer to have new API for better performance.","4"
"2019/02/28 4:48:01 AM AST","College/University","France","4","2","C/C++;Python","between 5 and 10 years","less than 2 years","System software development (OS, runtime library, communication library, etc.);Tool development (performance tuning, debugging, etc.)","Research and development on system software (OS and/or runtime library);Research and development software tool(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I had lecture(s) at school.","I have never read any MPI books","Open MPI;Intel MPI;MPC MPI","I was said to use it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Domain decomposition","Dynamic process creation;Persistent communication","Point-to-point communications;Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_SERIALIZED","Too many runtime ""optimisation"" (implem choice) flags","I rely on the default ‘Errors abort’ error handling","No, MPI calls are scattered in my programs.","OpenMP;Pthread","I do not know how to find bottlenecks.","A Domain Specific Language (DSL).","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Latency hiding (including asynchronous completion);Resilience (fault tolerance);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.);Another API which is easier and/or simpler to use","One-sided communication;Communicator and group management","I prefer to have new API which is simpler and/or easier-to-use.","3"
"2019/02/28 4:48:37 AM AST","College/University","France","1","1","C/C++;Python","between 2 and 5 years","less than 2 years","Workflow and/or In-situ","Research and development of application(s)","I have not read it, but I plan to.","I have not learned MPI.","","Open MPI","I could not have any choice (the one provided by a vendor).","I search the Internet (Google / Stack Overflow).","Finding appropriate MPI routines","Point-to-point communications;MPI datatypes;One-sided communications;Dynamic process creation;Persistent communication;PMPI interface","","MPI_THREAD_MULTIPLE","Too complicated and hard to understand.;I do not like the API.","Sometimes","","OpenMP","I think there is room but I do not know how to tune it.","A framework or library using MPI.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Latency hiding (including asynchronous completion);Resilience (fault tolerance)","Communicator and group management;Collective operations","Yes, compatibility is very important for me.","2"
"2019/02/28 4:53:09 AM AST","Governmental institute","France","5","5","C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer","between 5 and 10 years","between 2 and 5 years","System software development (OS, runtime library, communication library, etc.);Numerical application and/or library","Research and development on system software (OS and/or runtime library);Development of a  multi-thread MPI library","I read only the chapters of interest for my work.","I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","I have never read any MPI books","MPICH;Open MPI;Intel MPI;madmpi","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Algorithm design","","Point-to-point communications;MPI datatypes;MPI with OpenMP (or multithread);communications progression","MPI_THREAD_SERIALIZED","I have no obstacles.","Mostly","No, MPI calls are scattered in my programs.","Pthread;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","Dynamic process creation","Yes, compatibility is very important for me.","3"
"2019/02/28 4:56:26 AM AST","Governmental institute","France","5","5","C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer;Python","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I read book(s).;Other lectures or tutorials (workplace, conference).","Using MPI;MPI: The Complete Reference","MPICH;Open MPI","I was said to use it.","I read the MPI Standard document (web/book).","Finding appropriate MPI routines","PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes","MPI_THREAD_SINGLE","Too many routines.","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","No","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","injure that messages progresses while my code is computing (not only within MPI calls)","Latency hiding (including asynchronous completion);Resilience (fault tolerance)","One-sided communication","I prefer to have new API for better performance.","2"
"2019/02/28 5:03:56 AM AST","Other","France","4","4","C/C++;Fortran (older one than Fortran 90)","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s)","No, and I will not read it.","I read book(s).","Using MPI","MPICH;Open MPI;Intel MPI;HPE MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).","Debugging","Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_MULTIPLE","Too many routines.","Always","No, MPI calls are scattered in my programs.","OpenMP;Pthread","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","Low-level communication layer provided by vendor (Verbs, DCMF, ...).","asynchronous comm that are ACTUALLY asynchronous (that is to say, progress even when we're outside MPI)","","One-sided communication;Dynamic process creation","I prefer to have new API which is simpler and/or easier-to-use.","4"
"2019/02/28 5:10:10 AM AST","Governmental institute","France","5","4","C/C++;Python","more than 10 years","between 5 and 10 years","Numerical application and/or library","Scientist Researcher in Geophysics","I read only the chapters of interest for my work.","I read the MPI standard document.;I read articles found on Internet.","I have never read any MPI books","Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Performance tuning","Dynamic process creation;PMPI interface","Point-to-point communications;Collective communications;MPI with OpenMP (or multithread)","MPI_THREAD_FUNNELED","I have no obstacles.","Sometimes","No, MPI calls are scattered in my programs.","OpenMP;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Latency","Latency hiding (including asynchronous completion)","One-sided communication;Datatypes","I prefer to have new API for better performance.","4"
"2019/02/28 5:14:08 AM AST","Governmental institute","France","5","4","C/C++","between 5 and 10 years","between 5 and 10 years","Parallel language (incl. domain specific language)","Research and development of application(s)","I read only the chapters of interest for my work.","I had lecture(s) at school.","I have never read any MPI books","Open MPI;Intel MPI","I have no special reason.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes","MPI_THREAD_MULTIPLE","I have no obstacles.;I don't use it so often / Often I don't use it directly","I rely on the default ‘Errors abort’ error handling","Yes, I have few MPI function call into my program(s), and we use an other library which does most of the MPI function calls","OpenMP;Pthread","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","Communicator and group management;Dynamic process creation","I prefer to have new API for better performance.","1"
"2019/02/28 5:15:49 AM AST","Governmental institute","France","6","5","C/C++","more than 10 years","more than 10 years","System software development (OS, runtime library, communication library, etc.)","Research and development on system software (OS and/or runtime library)","I read most of it.","I read the MPI standard document.;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","I have never read any MPI books","MPICH;Open MPI;MVAPICH;Intel MPI;MPC MPI;MadMPI","I like to use it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I know almost all MPI routines.","Performance tuning","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;Dynamic process creation;Persistent communication;MPI with OpenMP (or multithread);PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_MULTIPLE","Too many routines.","Sometimes","No, MPI calls are scattered in my programs.","OpenMP;Pthread","I do not know if there is room for performance tuning.","A framework or library using MPI.","Multi-threading support","Endpoints (multi-thread, sessions);Another API which is easier and/or simpler to use","Dynamic process creation","Yes, compatibility is very important for me.","3"
"2019/02/28 5:22:43 AM AST","Governmental institute","France","5","2","C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer;Python","between 5 and 10 years","between 5 and 10 years","Parallel language (incl. domain specific language);Visualization","Research and development of application(s)","No, and I will not read it.","I read articles found on Internet.","","MPICH;Open MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","No appropriate lecture / book / info.","Sometimes","Yes, to minimize the changes of communication API.","No","I think there is room but I do not know how to tune it.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","Process topologies;Dynamic process creation","Yes, compatibility is very important for me.","2"
"2019/02/28 5:29:17 AM AST","Governmental institute","France","5","5","C/C++;Fortran 90 or newer;Python","between 2 and 5 years","between 2 and 5 years","Numerical application and/or library","Research and development of application(s);Performance tuning of MPI program(s)","No, and I will not read it.","I had lecture(s) at school.","I have never read any MPI books","Open MPI;Intel MPI","I was said to use it.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Performance tuning","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;Dynamic process creation;Persistent communication;MPI with OpenMP (or multithread)","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);Persistent communications;MPI with OpenMP (or multithread)","MPI_THREAD_MULTIPLE","I have no obstacles.","Sometimes","No, MPI calls are scattered in my programs.","OpenMP;Pthread","I think there is room but I do not know how to tune it.","A framework or library using MPI.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Latency hiding (including asynchronous completion)","Dynamic process creation","I prefer to have new API for better performance.","3"
"2019/02/28 5:29:45 AM AST","Private research institute","France","5","2","C/C++;Java;Python","more than 10 years","between 2 and 5 years","System software development (OS, runtime library, communication library, etc.);Numerical application and/or library","Research and development of application(s);Research and development on system software (OS and/or runtime library);Parallelization of sequential program(s);Performance tuning of MPI program(s)","I have not read it, but I plan to.","I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","","Open MPI;IBM MPI (BG/Q, PE, Spectrum)","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Implementation issue workaround","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes","MPI_THREAD_SERIALIZED","Too complicated and hard to understand.","Always","Yes, to minimize the changes of communication API.","OpenMP;Pthread","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.","RPC like API","RPC like API","","API should be clearly versioned.","4"
"2019/02/28 5:35:45 AM AST","Governmental institute","France","4","3","C/C++","more than 10 years","less than 2 years","Storage systems","Research and development software tool(s)","No, and I will not read it.","I read articles found on Internet.","","MPICH","I was said to use it.","I read online documents (such as man pages).","Other","One-sided communications;Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on)","I have never called MPI_INIT_THREAD","","Never","No, my program is too small to do that.","No","I have no chance to investigate.","","","","Datatypes;Process topologies;Dynamic process creation","I do not know or I do not care.","3"
"2019/02/28 5:39:44 AM AST","College/University","France","5","4","Fortran 90 or newer;Python","more than 10 years","between 5 and 10 years","Computational fluid dynamics","Research and development of application(s)","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","MPICH;Open MPI;Intel MPI","I have no special reason.","I read online documents (such as man pages).","Performance tuning","Dynamic process creation;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_FUNNELED;MPI_THREAD_MULTIPLE","","Mostly","No, MPI calls are scattered in my programs.","OpenMP","I think there is room but I do not know how to tune it.","","","","There are no unnecessary features","API should be clearly versioned.","5"
"2019/02/28 5:44:59 AM AST","Governmental institute","Germany","5","5","C/C++","more than 10 years","more than 10 years","System software development (OS, runtime library, communication library, etc.);Parallel language (incl. domain specific language)","Research and development on system software (OS and/or runtime library);Research and development software tool(s)","I read most of it.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).","","MPICH;Open MPI;Intel MPI;IBM MPI (BG/Q, PE, Spectrum)","I like to use it.","I read the MPI Standard document (web/book).;I search the Internet (Google / Stack Overflow).","Performance tuning","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on)","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED","I have no obstacles.","Mostly","Yes, to minimize the changes of communication API.","OpenMP","I think there is room but I do not know how to tune it.","A framework or library using MPI.;Low-level communication layer provided by vendor (Verbs, DCMF, ...).","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Resilience (fault tolerance)","Datatypes;Process topologies","Yes, compatibility is very important for me.","1"
"2019/02/28 5:47:42 AM AST","Governmental institute","France","5","3","C/C++","between 5 and 10 years","less than 2 years","Numerical application and/or library","Research and development of application(s)","I have not read it, but I plan to.","I read the MPI standard document.;I had lecture(s) at school.;I read articles found on Internet.;I read MPI softwares written by experienced users","I have never read any MPI books","MPICH;Open MPI;MVAPICH","I have no special reason.","I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Domain decomposition","One-sided communications;Dynamic process creation;Persistent communication;PMPI interface","One-sided communications;Dynamic process creation;Persistent communications;PMPI interface","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED","Efficient debugging knowledges","Always","No, MPI calls are scattered in my programs.","Pthread","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Latency hiding (including asynchronous completion);Endpoints (multi-thread, sessions)","Dynamic process creation","API should be clearly versioned.","3"
"2019/02/28 5:48:04 AM AST","Software vendor","India","4","4","C/C++;Fortran (older one than Fortran 90)","between 2 and 5 years","between 2 and 5 years","System software development (OS, runtime library, communication library, etc.)","Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Beginning MPI (An Introduction in C);Using MPI","MPICH;Open MPI;MVAPICH;Intel MPI","I like to use it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).","Algorithm design","Persistent communication;PMPI interface","Point-to-point communications;Collective communications","MPI_THREAD_SINGLE","Too many routines.;Too complicated and hard to understand.","I rely on the default ‘Errors abort’ error handling","No, MPI calls are scattered in my programs.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","","Latency","Resilience (fault tolerance)","Dynamic process creation","Yes, compatibility is very important for me.","3"
"2019/02/28 5:52:26 AM AST","College/University","Russia","3","1","Java","between 2 and 5 years","less than 2 years","Tool development (performance tuning, debugging, etc.)","Research and development of application(s);Research and development software tool(s)","I read only the chapters of interest for my work.","I read articles found on Internet.","I have never read any MPI books","Open MPI;Intel MPI","I like to use it.","I ask colleagues.","Other","Point-to-point communications;MPI datatypes;One-sided communications;Dynamic process creation;Persistent communication","MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","I have no obstacles.","Sometimes","No, my program is too small to do that.","No","I do not know if there is room for performance tuning.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","There are no unnecessary features","I do not know or I do not care.","3"
"2019/02/28 6:07:40 AM AST","Governmental institute","France","5","4","C/C++;Python","more than 10 years","between 5 and 10 years","System software development (OS, runtime library, communication library, etc.)","Research and development on system software (OS and/or runtime library)","I read only the chapters of interest for my work.","I read articles found on Internet.","","Open MPI;MPC MPI","I am familiar with it.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","MPI datatypes;Persistent communication;PMPI interface","","MPI_THREAD_MULTIPLE","I have no obstacles.","Sometimes","Yes, to minimize the changes of communication API.","OpenMP;Pthread;OpenCL","Yes, I know there is room for tuning but I do not have enough resources to do that.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Energy consumption","MPI is providing all the communication semantics required by my application","There are no unnecessary features","Yes, compatibility is very important for me.","1"
"2019/02/28 6:27:30 AM AST","Governmental institute","France","4","3","C/C++","between 2 and 5 years","less than 2 years","System software development (OS, runtime library, communication library, etc.)","Research and development on system software (OS and/or runtime library)","I read only the chapters of interest for my work.","I read articles found on Internet.","I have never read any MPI books","Open MPI;Intel MPI;MPC MPI;madMPI","I have no special reason.","I read online documents (such as man pages).","Debugging","Communicator operations (split, duplicate, and so on);Dynamic process creation","Point-to-point communications;Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_FUNNELED;MPI_THREAD_MULTIPLE","I have no obstacles.","Never","No, MPI calls are scattered in my programs.","OpenMP;Pthread","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Latency hiding (including asynchronous completion)","One-sided communication;Dynamic process creation","I prefer to have new API which is simpler and/or easier-to-use.","5"
"2019/02/28 6:27:44 AM AST","Governmental institute","France","5","5","C/C++","between 5 and 10 years","between 2 and 5 years","Numerical application and/or library;Tool development (performance tuning, debugging, etc.)","Research and development of application(s);Research and development software tool(s)","I read only the chapters of interest for my work.","I had lecture(s) at school.","I have never read any MPI books","MPICH;Open MPI;Intel MPI;MPC MPI","I have no special reason.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).","Debugging","Dynamic process creation","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_MULTIPLE","","Never","No, MPI calls are scattered in my programs.","OpenMP;Pthread;OpenCL","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","Process topologies;Dynamic process creation","I prefer to have new API for better performance.","5"
"2019/02/28 6:30:33 AM AST","Governmental institute","France","4","3","Fortran 90 or newer","more than 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s)","I have not read it, but I plan to.","I read articles found on Internet.","I have never read any MPI books","MPICH;Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Performance tuning","Communicator operations (split, duplicate, and so on);Persistent communication","Point-to-point communications;Collective communications;MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","Too complicated and hard to understand.","Sometimes","No, MPI calls are scattered in my programs.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","There are no unnecessary features","Yes, compatibility is very important for me.","3"
"2019/02/28 7:09:29 AM AST","Software vendor","France","4","5","C/C++","between 2 and 5 years","between 2 and 5 years","System software development (OS, runtime library, communication library, etc.);Numerical application and/or library","Research and development of application(s)","I read most of it.","I read the MPI standard document.;I had lecture(s) at school.;I read articles found on Internet.","MPI: The Complete Reference","MPICH;Open MPI;MPC MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).","Performance tuning","Persistent communication","Point-to-point communications;Collective communications;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_FUNNELED;MPI_THREAD_SERIALIZED","I have no obstacles.","Always","Yes, to minimize the changes of communication API.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.;A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Latency hiding (including asynchronous completion)","Communicator and group management","API should be clearly versioned.","4"
"2019/02/28 7:31:05 AM AST","College/University","Russia","3","3","C/C++;Julia","between 5 and 10 years","between 2 and 5 years","Numerical application and/or library","Research and development of application(s)","","I had lecture(s) at school.","I have never read any MPI books","Open MPI","I have no special reason.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications","I do not know or I do not care.","I have nobody to ask.","Always","Yes, to minimize the changes of communication API.","No","I do not know how to find bottlenecks.","A framework or library using MPI.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","There are no unnecessary features","I do not know or I do not care.","1"
"2019/02/28 7:50:07 AM AST","Governmental institute","Tunisia","5","4","C/C++;Python","more than 10 years","between 5 and 10 years","Numerical application and/or library;AI (Deep Learning);Big data","Research and development of application(s)","I read only the chapters of interest for my work.","I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","MPICH","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Performance tuning","Dynamic process creation;Persistent communication","Point-to-point communications;Collective communications;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","OpenMP","No, my MPI programs are well-tuned.","I am not investigating any alternatives.","Multi-threading support","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.);Another API which is easier and/or simpler to use","There are no unnecessary features","I prefer to have new API for better performance.","3"
"2019/02/28 8:14:38 AM AST","Governmental institute","India","3","2","Fortran (older one than Fortran 90)","more than 10 years","less than 2 years","Parallel language (incl. domain specific language)","Research and development of application(s)","","I read articles found on Internet.","","Intel MPI","I have no special reason.","I ask colleagues.","Performance tuning","MPI datatypes","Point-to-point communications","MPI_THREAD_SINGLE","I have no obstacles.","Sometimes","No, MPI calls are scattered in my programs.","No","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A framework or library using MPI.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","Dynamic process creation;Error handlers","Yes, compatibility is very important for me.","4"
"2019/02/28 8:42:56 AM AST","Governmental institute","Korea, South","4","1","C/C++;Python;MATLAB script","more than 10 years","less than 2 years","Numerical application and/or library;Visualization","Research and development of application(s)","I have not read it, but I plan to.","I have not learned MPI.","I have never read any MPI books","I do not know","I like to use it.","I read the MPI Standard document (web/book).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Debugging","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);Dynamic process creation;Persistent communication;PMPI interface","MPI with OpenMP (or multithread)","I do not know or I do not care.","Too complicated and hard to understand.","Sometimes","Yes, but I have no special reason for doing that.","No","I do not know if there is room for performance tuning.","I am not investigating any alternatives.","Multi-threading support","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","There are no unnecessary features","I prefer to have new API for better performance.","3"
"2019/02/28 9:34:51 AM AST","Other","France","5","4","C/C++;Python","between 5 and 10 years","between 2 and 5 years","Numerical application and/or library;AI (Deep Learning);Big data","Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","","I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","","MPICH;Open MPI","I am familiar with it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Performance tuning","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","","No appropriate lecture / book / info.;I have nobody to ask.","Mostly","No, my program is too small to do that.","OpenMP;OpenCL;CUDA","I think there is room but I do not know how to tune it.","A framework or library using MPI.","Latency","Another API which is easier and/or simpler to use","","I prefer to have new API for better performance.","4"
"2019/02/28 10:24:15 AM AST","College/University","France","2","2","C/C++","less than 2 years","less than 2 years","Visualization","Research and development of application(s)","No, and I will not read it.","I had lecture(s) at school.;I read articles found on Internet.","","","I have no special reason.","I search the Internet (Google / Stack Overflow).","Debugging","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;Dynamic process creation;Persistent communication;MPI with OpenMP (or multithread);PMPI interface","","I do not know or I do not care.","Too complicated and hard to understand.","Always","No, MPI calls are scattered in my programs.","No","I do not know if there is room for performance tuning.","I am not investigating any alternatives.","","","","",""
"2019/02/28 11:02:22 AM AST","Private research institute","France","5","5","C/C++;Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","I read most of it.","I read the MPI standard document.;I had lecture(s) at school.;I read articles found on Internet.","MPI: The Complete Reference","MPICH;Open MPI;MVAPICH;Intel MPI;Cray MPI;IBM MPI (BG/Q, PE, Spectrum);HPE MPI","I could not have any choice (the one provided by a vendor).","I search the Internet (Google / Stack Overflow).;I know almost all MPI routines.","Algorithm design","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;Persistent communication;MPI with OpenMP (or multithread)","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED;MPI_THREAD_SERIALIZED;MPI_THREAD_MULTIPLE","I have no obstacles.","Sometimes","Yes, but I have no special reason for doing that.","OpenMP;Pthread;OpenACC;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Multi-threading support","MPI is providing all the communication semantics required by my application","Dynamic process creation","Yes, compatibility is very important for me.","3"
"2019/02/28 11:31:21 AM AST","College/University","France","6","4","C/C++","more than 10 years","more than 10 years","System software development (OS, runtime library, communication library, etc.);Parallel language (incl. domain specific language)","Research and development software tool(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).","Using MPI","Open MPI;Intel MPI","I am familiar with it.","I read online documents (such as man pages).","Performance tuning","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_MULTIPLE","I have no obstacles.","Mostly","No, MPI calls are scattered in my programs.","OpenMP","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).;A Domain Specific Language (DSL).","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","There are no unnecessary features","I prefer to have new API for better performance.","5"
"2019/02/28 11:55:17 AM AST","College/University","France","4","3","C/C++;Python","between 5 and 10 years","between 2 and 5 years","Numerical application and/or library","Research and development of application(s)","No, and I will not read it.","I had lecture(s) at school.;I read articles found on Internet.","I have never read any MPI books","MPICH;Open MPI;Intel MPI","I was said to use it.","I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation;PMPI interface","MPI datatypes;Persistent communications;MPI with OpenMP (or multithread)","MPI_THREAD_MULTIPLE","I don't need to master it","Mostly","No, MPI calls are scattered in my programs.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.;runtime","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Another API which is easier and/or simpler to use","Communicator and group management","Yes, compatibility is very important for me.","4"
"2019/02/28 12:21:37 PM AST","Governmental institute","Germany","6","2","C/C++","more than 10 years","less than 2 years","Tool development (performance tuning, debugging, etc.)","Research and development software tool(s);Performance tuning of MPI program(s);Debugging MPI programs","I read only the chapters of interest for my work.","I read the MPI standard document.;I read articles found on Internet.","I have never read any MPI books","MPICH;Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Other","Persistent communication","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread);PMPI interface","MPI_THREAD_MULTIPLE","I have no obstacles.;Too many routines.","I rely on the default ‘Errors abort’ error handling","No, my program is too small to do that.","No","My programs are usually micro-benchmarks which evaluate performance of MPI.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","MPI is providing all the communication semantics required by my application","There are no unnecessary features","API should be clearly versioned.","5"
"2019/02/28 1:25:35 PM AST","Governmental institute","France","6","5","C/C++;Python","more than 10 years","between 5 and 10 years","System software development (OS, runtime library, communication library, etc.);Parallel language (incl. domain specific language)","Research and development of application(s);Research and development on system software (OS and/or runtime library);Parallelization of sequential program(s)","I read only the chapters of interest for my work.","I had lecture(s) at school.;I read articles found on Internet.","I have never read any MPI books","Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Performance tuning","PMPI interface","Point-to-point communications;Collective communications;Persistent communications;MPI with OpenMP (or multithread)","MPI_THREAD_FUNNELED;MPI_THREAD_SERIALIZED;MPI_THREAD_MULTIPLE","I have no obstacles.","Never","It clearly depends of targeted software, but I tend to write my own abstration layer","OpenMP","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A framework or library using MPI.","Message injection rate","Latency hiding (including asynchronous completion);A better interaction with OpenMP tasks","One-sided communication;Datatypes;Dynamic process creation;Error handlers","API should be clearly versioned.","4"
"2019/02/28 1:54:01 PM AST","College/University","France","6","4","C/C++;Python","more than 10 years","more than 10 years","System software development (OS, runtime library, communication library, etc.);Tool development (performance tuning, debugging, etc.)","Research and development on system software (OS and/or runtime library);Research and development software tool(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I had lecture(s) at school.","Using MPI;MPI: The Complete Reference","MPICH;Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I ask colleagues.","Implementation issue workaround","Dynamic process creation","Point-to-point communications;MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED;MPI_THREAD_SERIALIZED;MPI_THREAD_MULTIPLE","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","OpenMP;Pthread;OpenCL;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.;A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).;A Domain Specific Language (DSL).;Low-level communication layer provided by vendor (Verbs, DCMF, ...).","Multi-threading support","Latency hiding (including asynchronous completion);Endpoints (multi-thread, sessions);Resilience (fault tolerance)","One-sided communication;Process topologies;Dynamic process creation","Yes, compatibility is very important for me.","3"
"2019/02/28 2:35:45 PM AST","Private research institute","France","5","5","C/C++;Fortran 90 or newer;Python","between 5 and 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s);Parallelization of sequential program(s)","I read most of it.","I read the MPI standard document.;I had lecture(s) at school.","I have never read any MPI books","MPICH;Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I search the Internet (Google / Stack Overflow).","Implementation issue workaround","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;Dynamic process creation;Persistent communication;MPI with OpenMP (or multithread)","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_SERIALIZED","I have no obstacles.","Sometimes","Yes, but I have no special reason for doing that.","OpenMP;Pthread;StarPU","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","runtime system, StarPU, newmadeleine","Multi-threading support","Latency hiding (including asynchronous completion)","Dynamic process creation","API should be clearly versioned.","3"
"2019/02/28 5:12:58 PM AST","Governmental institute","Russia","4","3","Fortran (older one than Fortran 90);Fortran 90 or newer;Python","more than 10 years","between 2 and 5 years","Parallel language (incl. domain specific language);Numerical application and/or library","Research and development of application(s);Research and development software tool(s)","I have not read it, but I plan to.","I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Parallel Programming with MPI;Antonov A.S. Parallel Programming with MPI","MPICH;Open MPI;Intel MPI;Cray MPI;SGI MPI","I could not have any choice (the one provided by a vendor).","I read book(s) (except the MPI standard).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD;I do not know or I do not care.","No good and free debuging tools","Sometimes","No, my program is too small to do that.","No","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.;A Domain Specific Language (DSL).","Multi-threading support","Another API which is easier and/or simpler to use","There are no unnecessary features","Yes, compatibility is very important for me.","3"
"2019/02/28 6:36:51 PM AST","Governmental institute","Canada","5","5","C/C++","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s)","I read most of it.","I read the MPI standard document.;I read book(s).;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Using MPI;MPI: The Complete Reference","MPICH;Open MPI","I like to use it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Domain decomposition","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;Dynamic process creation","MPI_THREAD_SINGLE","I have no obstacles.","Never","Yes, to minimize the changes of communication API.","No","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","Error handlers;Tag matching is not needed most of the time. I would exchange it in return for more performance.","I prefer to have new API for better performance.","4"
"2019/02/28 8:12:19 PM AST","College/University","Korea, South","5","4","C/C++;Python","between 5 and 10 years","between 2 and 5 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I read book(s).","Parallel Programming with MPI;MPI: The Complete Reference","MVAPICH","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).","Performance tuning","Dynamic process creation;PMPI interface","Collective communications;MPI datatypes","I have never called MPI_INIT_THREAD","Too complicated and hard to understand.","I rely on the default ‘Errors abort’ error handling","No, MPI calls are scattered in my programs.","No","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","There are no unnecessary features","Yes, compatibility is very important for me.","5"
"2019/02/28 9:29:22 PM AST","Private research institute","Japan","5","6","C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer","more than 10 years","more than 10 years","System software development (OS, runtime library, communication library, etc.);Numerical application and/or library;Tool development (performance tuning, debugging, etc.)","Parallelization of sequential program(s);Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","I read book(s).;I had lecture(s) at school.","Using MPI;MPI: The Complete Reference","Open MPI;Intel MPI;Fujistu MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).;I read online documents (such as man pages).;I ask colleagues.","Algorithm design","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread);PMPI interface","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","No, MPI calls are scattered in my programs.","OpenMP","No, my MPI programs are well-tuned.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Endpoints (multi-thread, sessions);Resilience (fault tolerance);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","There are no unnecessary features","API should be clearly versioned.","4"
"2019/03/01 12:40:23 AM AST","College/University","Japan","3","1","Python;R","between 2 and 5 years","less than 2 years","Bioinformatics","Research for genome sequence","No, and I will not read it.","I read articles found on Internet.","I have never read any MPI books","I do not know","I have no special reason.","I search the Internet (Google / Stack Overflow).","Algorithm design","Point-to-point communications;Collective communications","Point-to-point communications;Collective communications","I have never called MPI_INIT_THREAD","Too complicated and hard to understand.;I have nobody to ask.","Mostly","No, my program is too small to do that.","No","I do not know if there is room for performance tuning.","A framework or library using MPI.;A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Message injection rate","Latency hiding (including asynchronous completion);Endpoints (multi-thread, sessions);Resilience (fault tolerance)","One-sided communication;Datatypes;Error handlers","I do not know or I do not care.","3"
"2019/03/01 12:43:17 AM AST","Governmental institute","Korea, South","5","2","Java;Python","more than 10 years","less than 2 years","AI (Deep Learning);Big data","Research and development of application(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).","I have never read any MPI books","Open MPI;MVAPICH;Intel MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).","Debugging","MPI with OpenMP (or multithread);PMPI interface","Collective communications;Dynamic process creation","I do not know or I do not care.","Too complicated and hard to understand.","Sometimes","Yes, to minimize the changes of communication API.","CUDA","I think there is room but I do not know how to tune it.","A framework or library using MPI.;Low-level communication layer provided by vendor (Verbs, DCMF, ...).","Latency","Latency hiding (including asynchronous completion)","Communicator and group management;Process topologies","I prefer to have new API which is simpler and/or easier-to-use.","4"
"2019/03/01 6:06:11 AM AST","Governmental institute","France","6","5","C/C++;Fortran 90 or newer;Python","more than 10 years","more than 10 years","System software development (OS, runtime library, communication library, etc.);Parallel language (incl. domain specific language);Numerical application and/or library;Tool development (performance tuning, debugging, etc.)","Research and development on system software (OS and/or runtime library)","I read only the chapters of interest for my work.","I read the MPI standard document.;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","MPICH;Open MPI","I like to use it.","I read online documents (such as man pages).","Debugging","PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED;MPI_THREAD_SERIALIZED;MPI_THREAD_MULTIPLE","few examples/tutorials available for advanced features such as one sided routines","Mostly","Yes, to minimize the changes of communication API.","OpenMP;Pthread;CUDA","No, my MPI programs are well-tuned.","A framework or library using MPI.;Low-level communication layer provided by vendor (Verbs, DCMF, ...).","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Endpoints (multi-thread, sessions);Resilience (fault tolerance);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","One-sided communication","I think the MPI standard should evolve more quickly, and drop backward compatibility when necessary","3"
"2019/03/01 7:23:05 AM AST","College/University","France","5","3","C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer","between 5 and 10 years","between 2 and 5 years","Numerical application and/or library;Workflow and/or In-situ","Research and development of application(s)","No, and I will not read it.","I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","Open MPI","I was said to use it.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","Point-to-point communications;One-sided communications;Dynamic process creation;Persistent communication;PMPI interface","MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED;MPI_THREAD_MULTIPLE","","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","OpenMP","I do not know if there is room for performance tuning.","A Domain Specific Language (DSL).","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Resilience (fault tolerance)","","API should be clearly versioned.","4"
"2019/03/01 7:25:00 AM AST","College/University","France","6","4","C/C++;Python","more than 10 years","between 2 and 5 years","Parallel language (incl. domain specific language);Numerical application and/or library","Research and development of application(s);Research and development software tool(s);Parallelization of sequential program(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I read articles found on Internet.","","MPICH;Open MPI","I have no special reason.","I read the MPI Standard document (web/book).;I search the Internet (Google / Stack Overflow).","Algorithm design","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","Time","Sometimes","Yes, to minimize the changes of communication API.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","","","","","API should be clearly versioned.","3"
"2019/03/01 7:59:40 AM AST","College/University","France","5","4","Fortran 90 or newer","more than 10 years","more than 10 years","Parallel language (incl. domain specific language);Numerical application and/or library","Research and development of application(s)","I have not read it, but I plan to.","I read book(s).;I had lecture(s) at school.","","MPICH;Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read book(s) (except the MPI standard).;I search the Internet (Google / Stack Overflow).","Performance tuning","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED","No appropriate lecture / book / info.","Sometimes","No, MPI calls are scattered in my programs.","OpenMP","I think there is room but I do not know how to tune it.","I am not investigating any alternatives.","MPI provides all semantics I need","Resilience (fault tolerance)","Process topologies;Dynamic process creation","Yes, compatibility is very important for me.","2"
"2019/03/01 8:09:27 AM AST","College/University","France","4","3","C/C++;Fortran 90 or newer;Python","between 2 and 5 years","between 2 and 5 years","Numerical application and/or library","Research and development of application(s);Parallelization of sequential program(s)","I read only the chapters of interest for my work.","I read book(s).;I read articles found on Internet.","Using MPI;MPI: The Complete Reference","Open MPI","I was said to use it.","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Algorithm design","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on)","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","No appropriate lecture / book / info.;I have nobody to ask.","Mostly","It's a mix of both, I try to keep the communications part as a separate layer whenever I can. ","OpenMP","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","I am not investigating any alternatives.","Mainly bandwidth and passing large arrays ~2GB+ memory usage and ofcourse the associated latency for large messages.","Another API which is easier and/or simpler to use;MPI is providing all the communication semantics required by my application","Process topologies;Dynamic process creation","I prefer to have new API which is simpler and/or easier-to-use.","3"
"2019/03/01 8:51:07 AM AST","College/University","France","5","2","Fortran (older one than Fortran 90);Fortran 90 or newer","between 5 and 10 years","less than 2 years","Numerical application and/or library;Tool development (performance tuning, debugging, etc.)","Research and development of application(s)","I have not read it, but I plan to.","Other lectures or tutorials (workplace, conference).","","Open MPI","I was said to use it.","I ask colleagues.;I search the Internet (Google / Stack Overflow).","Algorithm design","MPI with OpenMP (or multithread)","MPI with OpenMP (or multithread)","I do not know or I do not care.","No appropriate lecture / book / info.;Too complicated and hard to understand.;I have nobody to ask.","Mostly","No, MPI calls are scattered in my programs.","No","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","I am not investigating any alternatives.","Multi-threading support","","","Yes, compatibility is very important for me.","3"
"2019/03/01 1:46:22 PM AST","College/University","France","4","4","C/C++","between 2 and 5 years","less than 2 years","Numerical application and/or library","Research and development on system software (OS and/or runtime library)","I read only the chapters of interest for my work.","I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","Parallel Programming with MPI","Open MPI","I was said to use it.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","","Point-to-point communications;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED","No detailed and clear enough documents about internal implementation","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","OpenMP","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A framework or library using MPI.","Multi-threading support","Resilience (fault tolerance)","There are no unnecessary features","API should be clearly versioned.","3"
"2019/03/01 5:32:55 PM AST","College/University","France","5","4","Fortran 90 or newer","more than 10 years","between 5 and 10 years","Physics","Research in physics","I read only the chapters of interest for my work.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","I have never read any MPI books","MPICH;Intel MPI;IBM MPI (BG/Q, PE, Spectrum)","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","I do not know or I do not care.","Difficulty to debug","Always","No, MPI calls are scattered in my programs.","OpenMP","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","I am not investigating any alternatives.","Multi-threading support","Endpoints (multi-thread, sessions)","","Yes, compatibility is very important for me.","3"
"2019/03/02 5:06:01 AM AST","College/University","Russia","3","3","C/C++","between 2 and 5 years","less than 2 years","Parallel language (incl. domain specific language)","Research and development of application(s);Parallelization of sequential program(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).","I have never read any MPI books","Open MPI;Intel MPI","I like to use it.","I read the MPI Standard document (web/book).","Finding appropriate MPI routines","Persistent communication","Point-to-point communications","I do not know or I do not care.","I have no obstacles.","Sometimes","No, my program is too small to do that.","No","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","Datatypes;Communicator and group management","I prefer to have new API for better performance.","4"
"2019/03/03 11:55:36 AM AST","College/University","France","4","5","C/C++","between 2 and 5 years","between 2 and 5 years","Numerical application and/or library","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s)","I read most of it.","I read the MPI standard document.;I had lecture(s) at school.;I read articles found on Internet.","MPI: The Complete Reference","Open MPI","I have no special reason.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).","Debugging","Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_SERIALIZED","I have no obstacles.","Mostly","Yes, but I have no special reason for doing that.","Pthread;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Latency hiding (including asynchronous completion);Resilience (fault tolerance)","There are no unnecessary features","I do not know or I do not care.","3"
"2019/03/03 1:19:45 PM AST","College/University","Poland","4","5","C/C++;Fortran 90 or newer;Python","more than 10 years","more than 10 years","Numerical application and/or library;Visualization","Research and development of application(s)","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).;I learned from other working applications","I have never read any MPI books","MPICH;Open MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Domain decomposition","Communicator operations (split, duplicate, and so on);Dynamic process creation;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","I have no obstacles.","Sometimes","No, MPI calls are scattered in my programs.","OpenMP;Pthread","I do not have (know) tools to find performance bottlenecks.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Latency hiding (including asynchronous completion)","Dynamic process creation","Yes, compatibility is very important for me.","3"
"2019/03/03 7:24:56 PM AST","College/University","France","4","2","R","between 5 and 10 years","less than 2 years","Parallel language (incl. domain specific language);Big data;statistics","Research and development of application(s)","No, and I will not read it.","","","","","","","","","","","","","","","","","","","",""
"2019/03/03 8:55:03 PM AST","College/University","Korea, South","5","5","Fortran (older one than Fortran 90);Fortran 90 or newer","more than 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).","","Open MPI;Intel MPI","I like to use it.","I read the MPI Standard document (web/book).","Algorithm design","Communicator operations (split, duplicate, and so on)","Point-to-point communications","MPI_THREAD_SINGLE","I have no obstacles.","Sometimes","Yes, but I have no special reason for doing that.","OpenMP","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A framework or library using MPI.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Endpoints (multi-thread, sessions)","One-sided communication","Yes, compatibility is very important for me.","3"
"2019/03/04 4:00:27 AM AST","Other","France","4","5","C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s);Research and development software tool(s);Performance tuning of MPI program(s);Debugging MPI programs","I read only the chapters of interest for my work.","I read the MPI standard document.;I read articles found on Internet.","MPI: The Complete Reference","MPICH;Open MPI;Intel MPI;IBM MPI (BG/Q, PE, Spectrum)","I have no special reason.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).","Performance tuning","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_FUNNELED","Understanding performance, making immediate communications asynchronous, ...","Never","No, MPI calls are scattered in my programs.","OpenMP;Pthread;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","rather than ibcast: isend same msg efficiently to several destinations, reception with irecv/recv. Or better (panel broadcast in a dense linear algebra factorizations): a way to pipeline communication and computation in an asynchronous broadcast tree. For example P0->(P1,P2) ; P1->(P3,P4), P2->(P5,P6), etc... while P3-P6 receive panel 1 (say), P1-P2  work with and forward panel 2, and P0 computes and sends panel 3, without synchronization and re-use of same buffer space for all panels","Latency hiding (including asynchronous completion)","","Yes, compatibility is very important for me.","1"
"2019/03/04 5:07:24 AM AST","College/University","France","5","5","C/C++","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s);Research and development software tool(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).;I read articles found on Internet.","Parallel Programming with MPI;Using MPI;MPI: The Complete Reference","MPICH;Open MPI;MVAPICH;Intel MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).","Debugging","PMPI interface","Point-to-point communications;MPI datatypes;Persistent communications;MPI with OpenMP (or multithread)","MPI_THREAD_FUNNELED;MPI_THREAD_MULTIPLE","Too many routines.","Always","Yes, to minimize the changes of communication API.","OpenMP;Pthread;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","Low-level communication layer provided by vendor (Verbs, DCMF, ...).","Multi-threading support","Latency hiding (including asynchronous completion)","One-sided communication;Process topologies","I prefer to have new API for better performance.","4"
"2019/03/04 5:13:23 AM AST","Governmental institute","France","6","4","C/C++","more than 10 years","more than 10 years","Numerical application and/or library","Research and development software tool(s)","","I read the MPI standard document.;I read book(s).","MPI: The Complete Reference","MPICH;Open MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Debugging","Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED;MPI_THREAD_SERIALIZED;MPI_THREAD_MULTIPLE","I have no obstacles.","Mostly","Yes, to minimize the changes of communication API.","","I think there is room but I do not know how to tune it.","A framework or library using MPI.","Latency","MPI is providing all the communication semantics required by my application","There are no unnecessary features","Yes, compatibility is very important for me.","1"
"2019/03/04 5:31:14 AM AST","College/University","France","5","4","Fortran 90 or newer","more than 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s)","","I read articles found on Internet.","I have never read any MPI books","Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I ask colleagues.","Algorithm design","Dynamic process creation;Persistent communication","Point-to-point communications;MPI with OpenMP (or multithread)","MPI_THREAD_MULTIPLE","Too many routines.","Sometimes","No, MPI calls are scattered in my programs.","No","No, my MPI programs are well-tuned.","I am not investigating any alternatives.","Bandwidth","MPI is providing all the communication semantics required by my application","There are no unnecessary features","Yes, compatibility is very important for me.","4"
"2019/03/04 5:58:44 AM AST","College/University","France","6","5","C/C++;Fortran 90 or newer;Java;Python","between 5 and 10 years","","Parallel language (incl. domain specific language);Numerical application and/or library;Image processing;Tool development (performance tuning, debugging, etc.)","Research and development of application(s);Research and development software tool(s);Parallelization of sequential program(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I had lecture(s) at school.;I read articles found on Internet.","","Intel MPI","I like to use it.","I read the MPI Standard document (web/book).;I ask colleagues.","Performance tuning","Persistent communication;MPI with OpenMP (or multithread)","MPI with OpenMP (or multithread)","","No appropriate lecture / book / info.","Sometimes","Yes, to minimize the changes of communication API.","","I do not have (know) tools to find performance bottlenecks.","A framework or library using MPI.","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","","","Yes, compatibility is very important for me.","3"
"2019/03/04 6:41:33 AM AST","Governmental institute","France","6","5","C/C++","more than 10 years","between 5 and 10 years","System software development (OS, runtime library, communication library, etc.);Numerical application and/or library;Workflow and/or In-situ","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","I read only the chapters of interest for my work.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).","","MPICH;Open MPI;Intel MPI;IBM MPI (BG/Q, PE, Spectrum)","I have no special reason.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).","Other","PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI with OpenMP (or multithread);I use almost exclusively the Boost MPI layer","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED","Too complicated and hard to understand.;I do not like the API.;seems target to Fortran 77 programmers","Mostly","Through Boost MPI","OpenMP;Pthread","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.","MPI provides all semantics I need","better async IO","One-sided communication","API should be clearly versioned.","2"
"2019/03/04 6:50:42 AM AST","Governmental institute","France","4","4","C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer","between 5 and 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s)","","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).","Using MPI;MPI: The Complete Reference","MPICH;Open MPI;Intel MPI;BULL MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Performance tuning","Persistent communication","Point-to-point communications;Collective communications;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","Too many routines.","Sometimes","No, MPI calls are scattered in my programs.","OpenMP;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).;A Domain Specific Language (DSL).","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Latency hiding (including asynchronous completion);Resilience (fault tolerance);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","Communicator and group management;Dynamic process creation","Yes, compatibility is very important for me.","3"
"2019/03/04 6:53:59 AM AST","Private research institute","France","4","4","C/C++","between 5 and 10 years","between 2 and 5 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).","","Open MPI;Intel MPI","I am familiar with it.","I read online documents (such as man pages).","Domain decomposition","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","I have no obstacles.","Sometimes","Yes, to minimize the changes of communication API.","OpenMP;OpenACC;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","MPI is providing all the communication semantics required by my application","Datatypes","I prefer to have new API which is simpler and/or easier-to-use.","3"
"2019/03/04 7:31:45 AM AST","Governmental institute","France","5","5","Fortran (older one than Fortran 90);Fortran 90 or newer;Python","more than 10 years","less than 2 years","Numerical application and/or library;Visualization;Tool development (performance tuning, debugging, etc.)","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","I read book(s).;Other lectures or tutorials (workplace, conference).","Using MPI;MPI: The Complete Reference","MPICH;Open MPI;Intel MPI;IBM MPI (BG/Q, PE, Spectrum);SGI MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Debugging","Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_FUNNELED","I have no obstacles.","Mostly","Yes, to minimize the changes of communication API.","OpenMP;OpenACC","I have no chance to investigate.","I am not investigating any alternatives.","Multi-threading support","Resilience (fault tolerance)","Dynamic process creation;Error handlers","Yes, compatibility is very important for me.","3"
"2019/03/04 7:32:26 AM AST","College/University","France","6","5","Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s)","No, and I will not read it.","Other lectures or tutorials (workplace, conference).","I have never read any MPI books","MPICH;Open MPI;Intel MPI","I am familiar with it.","I read online documents (such as man pages).;I ask colleagues.","Debugging","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications","I have never called MPI_INIT_THREAD","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","No","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","There are no unnecessary features","API should be clearly versioned.","3"
"2019/03/04 7:43:40 AM AST","College/University","France","4","3","C/C++;Python","between 5 and 10 years","between 2 and 5 years","System software development (OS, runtime library, communication library, etc.);Tool development (performance tuning, debugging, etc.)","Research and development on system software (OS and/or runtime library);Performance tuning of MPI program(s)","No, and I will not read it.","I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","I have never read any MPI books","Open MPI","I have no special reason.","I search the Internet (Google / Stack Overflow).","Debugging","One-sided communications;Dynamic process creation;Persistent communication","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread);PMPI interface","I have never called MPI_INIT_THREAD","I have no obstacles.","Sometimes","No, my program is too small to do that.","OpenMP","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","There are no unnecessary features","API should be clearly versioned.","3"
"2019/03/04 7:53:38 AM AST","Governmental institute","France","4","4","C/C++;Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s);Performance tuning of MPI program(s);Debugging MPI programs","I read only the chapters of interest for my work.","I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","Parallel Programming with MPI","Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","","Point-to-point communications;Collective communications;MPI datatypes;Persistent communications;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE","I have no obstacles.","Sometimes","No, MPI calls are scattered in my programs.","OpenMP;Pthread;CUDA","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A framework or library using MPI.;A Domain Specific Language (DSL).","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","One-sided communication;Dynamic process creation","API should be clearly versioned.","3"
"2019/03/04 7:56:30 AM AST","College/University","France","5","4","C/C++","more than 10 years","between 2 and 5 years","Tool development (performance tuning, debugging, etc.)","Research and development software tool(s);Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","","Open MPI;Intel MPI","I am familiar with it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Algorithm design","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;Dynamic process creation;Persistent communications;PMPI interface","I have never called MPI_INIT_THREAD;I do not know or I do not care.","I have no obstacles.","Sometimes","No, MPI calls are scattered in my programs.","No","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Multi-threading support","","","API should be clearly versioned.","4"
"2019/03/04 8:04:58 AM AST","College/University","France","6","6","C/C++;Python","more than 10 years","more than 10 years","Parallel language (incl. domain specific language);Numerical application and/or library;Visualization","Research and development of application(s);Research and development software tool(s);Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","I read only the chapters of interest for my work.","I read book(s).;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Using MPI;MPI: The Complete Reference","Open MPI","I am familiar with it.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Performance tuning","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread);PMPI interface","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","I have no obstacles.;The issue is usually the support on supercomputers ","Sometimes","Yes, to minimize the changes of communication API.","Pthread","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Multi-threading support","","There are no unnecessary features","I prefer to have new API which is simpler and/or easier-to-use.","3"
"2019/03/04 8:08:01 AM AST","College/University","France","4","5","C/C++;Fortran 90 or newer;Python","between 5 and 10 years","between 5 and 10 years","System software development (OS, runtime library, communication library, etc.);Numerical application and/or library","Research and development of application(s);Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).","I have never read any MPI books","Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).","Debugging","Dynamic process creation;Persistent communication","Point-to-point communications;Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","No, my program is too small to do that.","OpenMP","I do not know if there is room for performance tuning.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Another API which is easier and/or simpler to use","There are no unnecessary features","API should be clearly versioned.","3"
"2019/03/04 8:10:09 AM AST","Governmental institute","France","5","5","C/C++;Fortran 90 or newer;Python","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","I read only the chapters of interest for my work.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).;Stack overflow","","MPICH;Open MPI;MVAPICH;Intel MPI;IBM MPI (BG/Q, PE, Spectrum)","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Algorithm design","Dynamic process creation;Persistent communication","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED","I have no obstacles.","Sometimes","No, MPI calls are scattered in my programs.","OpenMP;OpenACC","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.;A Domain Specific Language (DSL).","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","MPI is providing all the communication semantics required by my application","One-sided communication;Process topologies;Dynamic process creation;Error handlers","Yes, compatibility is very important for me.","4"
"2019/03/04 8:28:39 AM AST","College/University","France","6","5","C/C++","more than 10 years","more than 10 years","System software development (OS, runtime library, communication library, etc.);Parallel language (incl. domain specific language);Tool development (performance tuning, debugging, etc.)","Research and development software tool(s);Parallelization of sequential program(s);Performance tuning of MPI program(s)","I read most of it.","I read the MPI standard document.;I had lecture(s) at school.","I have never read any MPI books","MPICH;Open MPI","I like to use it.","I read online documents (such as man pages).","Implementation issue workaround","Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","I have no obstacles.","Mostly","Yes, to minimize the changes of communication API.","OpenMP;Pthread","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.;A Domain Specific Language (DSL).","dynamicity of nodes","Resilience (fault tolerance)","","API should be clearly versioned.","3"
"2019/03/04 9:42:46 AM AST","College/University","France","5","4","C/C++;Python;Shell","between 5 and 10 years","less than 2 years","System software development (OS, runtime library, communication library, etc.);Workflow and/or In-situ;Tool development (performance tuning, debugging, etc.)","Research and development on system software (OS and/or runtime library);Research and development software tool(s)","No, and I will not read it.","I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","I have never read any MPI books","MPICH;Open MPI","I am familiar with it.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","Persistent communication","","I have never called MPI_INIT_THREAD","I have no obstacles.","Always","Yes, to minimize the changes of communication API.","No","I think there is room but I do not know how to tune it.","I am not investigating any alternatives.","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","There are no unnecessary features","I do not know or I do not care.","3"
"2019/03/04 10:08:19 AM AST","College/University","Korea, South","5","5","Fortran (older one than Fortran 90)","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s)","No, and I will not read it.","I read articles found on Internet.","I have never read any MPI books","Open MPI","I have no special reason.","I search the Internet (Google / Stack Overflow).","Debugging","Communicator operations (split, duplicate, and so on);Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes","I have never called MPI_INIT_THREAD","No appropriate lecture / book / info.;I have nobody to ask.","Mostly","No, MPI calls are scattered in my programs.","OpenMP;Kokkos","I do not know if there is room for performance tuning.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.);Another API which is easier and/or simpler to use","","Yes, compatibility is very important for me.","5"
"2019/03/05 3:10:08 AM AST","Governmental institute","France","5","5","Fortran (older one than Fortran 90)","more than 10 years","more than 10 years","Numerical application and/or library;AI (Deep Learning)","Research and development of application(s)","No, and I will not read it.","I read book(s).","Using MPI;Parallel Programming in C with MPI and OpenMP","Intel MPI","I have no special reason.","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).;I read online documents (such as man pages).;I ask colleagues.","Debugging","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes","I have never called MPI_INIT_THREAD","No appropriate lecture / book / info.","Sometimes","Yes, to minimize the changes of communication API.","No","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","Process topologies;Dynamic process creation","Yes, compatibility is very important for me.","2"
"2019/03/05 7:16:58 AM AST","Governmental institute","France","5","4","Fortran 90 or newer;Python","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I read the MPI standard document.","MPI reference","MPICH;Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Finding appropriate MPI routines","MPI datatypes;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_FUNNELED;MPI_THREAD_MULTIPLE","Too many routines.","Mostly","Yes, to minimize the changes of communication API.","OpenMP;OpenCL;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","A Domain Specific Language (DSL).;Low-level communication layer provided by vendor (Verbs, DCMF, ...).","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Resilience (fault tolerance);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.);Another API which is easier and/or simpler to use","Datatypes","API should be clearly versioned.","4"
"2019/03/05 8:22:17 AM AST","Governmental institute","France","5","3","C/C++;Fortran 90 or newer;Python","more than 10 years","more than 10 years","Numerical application and/or library;Visualization","Numerical simulation for materials (physics)","I read only the chapters of interest for my work.","I read the MPI standard document.;I read articles found on Internet.","I have never read any MPI books","Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I ask colleagues.","Implementation issue workaround","Communicator operations (split, duplicate, and so on);Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI with OpenMP (or multithread)","MPI_THREAD_FUNNELED","I have no obstacles.","Sometimes","Yes, to minimize the changes of communication API.","OpenMP;OpenCL;CUDA","I think there is room but I do not know how to tune it.","A Domain Specific Language (DSL).","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Resilience (fault tolerance)","Dynamic process creation","API should be clearly versioned.","4"
"2019/03/05 9:59:04 AM AST","Governmental institute","France","5","4","Fortran 90 or newer","more than 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s)","No, and I will not read it.","Other lectures or tutorials (workplace, conference).","","MPICH;Open MPI;Intel MPI","I was said to use it.","I ask colleagues.;I search the Internet (Google / Stack Overflow).;I know almost all MPI routines.","Debugging","One-sided communications;Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes","I do not know or I do not care.","Too many routines.;No appropriate lecture / book / info.","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Latency","Resilience (fault tolerance)","","Yes, compatibility is very important for me.","3"
"2019/03/05 2:42:18 PM AST","College/University","United States","4","4","Fortran 90 or newer;Python","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I read book(s).;Other lectures or tutorials (workplace, conference).","Parallel Programming with MPI;Using MPI;MPI: The Complete Reference","MPICH;Open MPI;Intel MPI","I like to use it.","I read book(s) (except the MPI standard).;I read online documents (such as man pages).","Debugging","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread);PMPI interface","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","I have no obstacles.","Sometimes","No, MPI calls are scattered in my programs.","OpenMP;CUDA","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A framework or library using MPI.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","Dynamic process creation","Yes, compatibility is very important for me.","3"
"2019/03/06 9:55:35 AM AST","College/University","France","4","2","Fortran 90 or newer","more than 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s)","No, and I will not read it.","Other lectures or tutorials (workplace, conference).","","Open MPI;Intel MPI","I have no special reason.","I search the Internet (Google / Stack Overflow).","Implementation issue workaround","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications","I do not know or I do not care.","Too complicated and hard to understand.;I do not like the API.","Never","Yes, to minimize the changes of communication API.","No","I do not know if there is room for performance tuning.","A framework or library using MPI.","","","","I do not know or I do not care.","3"
"2019/03/06 3:53:42 PM AST","College/University","United States","5","4","C/C++","more than 10 years","more than 10 years","System software development (OS, runtime library, communication library, etc.)","Research and development of application(s);Parallelization of sequential program(s)","I read only the chapters of interest for my work.","I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","Using MPI;MPI: The Complete Reference","MPICH;Open MPI;MVAPICH","I have no special reason.","I read online documents (such as man pages).","Algorithm design","PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","I have no obstacles.","Sometimes","No, my program is too small to do that.","OpenMP;Pthread;CUDA","No, my MPI programs are well-tuned.","A framework or library using MPI.;write my own library","Latency","Latency hiding (including asynchronous completion);Endpoints (multi-thread, sessions)","Datatypes;Dynamic process creation","Yes, compatibility is very important for me.","5"
"2019/03/06 5:14:00 PM AST","College/University","Korea, South","5","4","Fortran (older one than Fortran 90);Fortran 90 or newer;Python","more than 10 years","between 5 and 10 years","Parallel language (incl. domain specific language);Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I read book(s).","Parallel Programming with MPI;Using MPI","Open MPI;MVAPICH;Intel MPI","I have no special reason.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications","I have never called MPI_INIT_THREAD","Too complicated and hard to understand.;I have nobody to ask.","Never","No, MPI calls are scattered in my programs.","No","I have no chance to investigate.","A framework or library using MPI.;I am not investigating any alternatives.","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Endpoints (multi-thread, sessions)","There are no unnecessary features","Yes, compatibility is very important for me.","3"
"2019/03/07 5:57:58 AM AST","Other","France","5","5","C/C++;Fortran 90 or newer;Python","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s);Research and development software tool(s);Debugging MPI programs","I read most of it.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).","don't remember","MPICH;Open MPI;Intel MPI;IBM MPI (BG/Q, PE, Spectrum)","I like to use it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED","I have no obstacles.","Sometimes","No, MPI calls are scattered in my programs.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","MPI is providing all the communication semantics required by my application","Dynamic process creation","I prefer to have new API for better performance.","2"
"2019/03/07 2:16:32 PM AST","Governmental institute","France","4","2","C/C++;Fortran (older one than Fortran 90);Python","more than 10 years","less than 2 years","Numerical application and/or library;Big data;Visualization","Research and development of application(s);Research and development software tool(s)","No, and I will not read it.","Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","I have never read any MPI books","MPICH;Open MPI;Intel MPI","I was said to use it.","I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Algorithm design","One-sided communications;Dynamic process creation;Persistent communication;PMPI interface","Collective communications","MPI_THREAD_MULTIPLE","Too complicated and hard to understand.","I rely on the default ‘Errors abort’ error handling","No, MPI calls are scattered in my programs.","No","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A framework or library using MPI.;A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).;A Domain Specific Language (DSL).","Latency","MPI is providing all the communication semantics required by my application","There are no unnecessary features","I do not know or I do not care.","3"
"2019/03/08 10:12:13 AM AST","Governmental institute","United States","6","6","C/C++;Java;Python","more than 10 years","between 5 and 10 years","System software development (OS, runtime library, communication library, etc.);Parallel language (incl. domain specific language)","Research and development on system software (OS and/or runtime library)","I read most of it.","I read the MPI standard document.;I read articles found on Internet.","I have never read any MPI books","MPICH;Open MPI;Cray MPI;IBM MPI (BG/Q, PE, Spectrum)","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).","Performance tuning","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_SERIALIZED;MPI_THREAD_MULTIPLE","I have no obstacles.","Always","No, MPI calls are scattered in my programs.","OpenMP;Pthread;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Multi-threading support","Endpoints (multi-thread, sessions);Resilience (fault tolerance);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","Dynamic process creation","API should be clearly versioned.","3"
"2019/03/08 10:42:44 AM AST","College/University","France","4","4","C/C++","more than 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).","I have never read any MPI books","MPICH;Open MPI;MVAPICH;Intel MPI;IBM MPI (BG/Q, PE, Spectrum)","I could not have any choice (the one provided by a vendor).","I search the Internet (Google / Stack Overflow).","Debugging","Communicator operations (split, duplicate, and so on);Dynamic process creation;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes","MPI_THREAD_MULTIPLE","I have no obstacles.","Never","Yes, but I have no special reason for doing that.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","A Domain Specific Language (DSL).","Bandwidth","Latency hiding (including asynchronous completion);Resilience (fault tolerance)","One-sided communication;Communicator and group management;Dynamic process creation","API should be clearly versioned.","3"
"2019/03/08 12:54:07 PM AST","College/University","United States","6","6","C/C++","more than 10 years","more than 10 years","System software development (OS, runtime library, communication library, etc.);Parallel language (incl. domain specific language);Numerical application and/or library","Research and development on system software (OS and/or runtime library);Research and development software tool(s)","","I read the MPI standard document.;I read book(s).;I had lecture(s) at school.;I read articles found on Internet.","Using MPI;MPI: The Complete Reference","Open MPI;Intel MPI;Cray MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).","Domain decomposition","MPI with OpenMP (or multithread)","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;Dynamic process creation;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED;MPI_THREAD_MULTIPLE","Too many routines.;No appropriate lecture / book / info.","I rely on the default ‘Errors abort’ error handling","No, MPI calls are scattered in my programs.","OpenMP;Pthread;CUDA","No, my MPI programs are well-tuned.","A framework or library using MPI.;A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).;A Domain Specific Language (DSL).","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Resilience (fault tolerance);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","Process topologies","API should be clearly versioned.","4"
"2019/03/09 1:15:37 AM AST","Hardware vendor","United States","5","6","C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer","more than 10 years","more than 10 years","System software development (OS, runtime library, communication library, etc.);Numerical application and/or library","Research and development of application(s);Research and development on system software (OS and/or runtime library);Debugging MPI programs","I read all.","I read the MPI standard document.;I read code.","Parallel Programming with MPI;Using MPI;MPI: The Complete Reference","MPICH;Open MPI;Intel MPI;Cray MPI","I am familiar with it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).;I know almost all MPI routines.","Domain decomposition","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread);PMPI interface","MPI_THREAD_FUNNELED;MPI_THREAD_MULTIPLE","Open-MPI is routinely buggy and prevents me from using MPI 3.0 as specified","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","OpenMP;Pthread","No, my MPI programs are well-tuned.","A framework or library using MPI.;A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).;Low-level communication layer provided by vendor (Verbs, DCMF, ...).","Asynchronous progress","Good integration with modern C++, including coroutines/fibers/async/future as well as object (de)serialization","Dynamic process creation","Yes, compatibility is very important for me.","3"
"2019/03/12 2:16:25 PM AST","Other","France","4","5","C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library;Big data;Workflow and/or In-situ","Research and development of application(s);Parallelization of sequential program(s)","I read only the chapters of interest for my work.","I read book(s).;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Using MPI;MPI: The Complete Reference","MPICH;Open MPI;Intel MPI;IBM MPI (BG/Q, PE, Spectrum);BullX-MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).","Algorithm design","Persistent communication","Point-to-point communications;Collective communications;MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","Too many routines.","Mostly","Yes, to minimize the changes of communication API.","OpenMP;Pthread;Cilk++","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.","Multi-threading support","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","Communicator and group management","API should be clearly versioned.","3"
"2019/03/14 7:27:21 AM AST","College/University","Russia","4","4","C/C++;Python","more than 10 years","between 5 and 10 years","Numerical application and/or library;Big data","Research and development of application(s)","I read only the chapters of interest for my work.","I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","Parallel Programming with MPI","MPICH;Open MPI;MVAPICH;Intel MPI","I am familiar with it.","I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Debugging","","Point-to-point communications;Collective communications;MPI with OpenMP (or multithread)","I do not know or I do not care.","I do not like the API.","Sometimes","Yes, to minimize the changes of communication API.","Pthread;CUDA","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A framework or library using MPI.","Message injection rate","Latency hiding (including asynchronous completion)","One-sided communication","Yes, compatibility is very important for me.","4"
"2019/03/14 12:53:31 PM AST","Governmental institute","Germany","6","6","C/C++;Fortran 90 or newer;Python","more than 10 years","more than 10 years","Research applications","Research and development of application(s);Research and development software tool(s);Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","I read all.","I read the MPI standard document.;I read book(s).;Other lectures or tutorials (workplace, conference).","Using MPI;MPI: The Complete Reference","MPICH;Open MPI;MVAPICH;Intel MPI;Cray MPI;IBM MPI (BG/Q, PE, Spectrum);NEC MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I ask colleagues.;I search the Internet (Google / Stack Overflow).;I know almost all MPI routines.","Implementation issue workaround","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;Persistent communications;MPI with OpenMP (or multithread);PMPI interface","MPI_THREAD_MULTIPLE","implementation issues","Always","Yes, to minimize the changes of communication API.","OpenMP;OpenACC;CUDA","Several communication patterns for adapting to implementation of MPI on a specific machine","I am not investigating any alternatives.","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","MPI is providing all the communication semantics required by my application","There are no unnecessary features","I do not know or I do not care.","3"
"2019/03/15 10:56:53 AM AST","Software vendor","France","4","5","C/C++;Python","between 5 and 10 years","","Numerical application and/or library","Research and development of application(s);Debugging MPI programs","I read only the chapters of interest for my work.","I read articles found on Internet.","I have never read any MPI books","Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Performance tuning","Persistent communication;MPI with OpenMP (or multithread);PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on)","I do not know or I do not care.","Too many routines.","Sometimes","No, my program is too small to do that.","No","I think there is room but I do not know how to tune it.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Another API which is easier and/or simpler to use","One-sided communication","I prefer to have new API for better performance.","3"
"2019/03/17 12:11:28 PM AST","College/University","Russia","4","5","C/C++","more than 10 years","more than 10 years","Tool development (performance tuning, debugging, etc.)","Debugging MPI programs","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).;I had lecture(s) at school.","MPI: The Complete Reference;books in Russian","MPICH;Open MPI;Intel MPI;MS MPI","I was said to use it.","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).;I read online documents (such as man pages).","Debugging","Persistent communication","Point-to-point communications;Collective communications;MPI datatypes;PMPI interface","I have never called MPI_INIT_THREAD","Too complicated and hard to understand.","Sometimes","No, my program is too small to do that.","OpenMP","My program - is MPI tool.So I do not need MPI performance tuning.","I am not investigating any alternatives.","Bandwidth","Resilience (fault tolerance)","Process topologies;Dynamic process creation","Yes, compatibility is very important for me.","2"
"2019/03/17 12:16:58 PM AST","Governmental institute","Canada","4","3","Fortran 90 or newer;Python","more than 10 years","less than 2 years","Numerical application and/or library","Research and development of application(s);Research and development software tool(s)","I read only the chapters of interest for my work.","I read articles found on Internet.","MPI: The Complete Reference","Open MPI;Cray MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).","Finding appropriate MPI routines","Point-to-point communications;Collective communications;MPI datatypes","Point-to-point communications;MPI datatypes","I do not know or I do not care.","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","Yes, but I have no special reason for doing that.","No","I do not know if there is room for performance tuning.","I am not investigating any alternatives.","MPI provides all semantics I need","","There are no unnecessary features","I prefer to have new API which is simpler and/or easier-to-use.","3"
"2019/03/17 10:46:26 PM AST","Governmental institute","Japan","6","5","Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s)","","I read the MPI standard document.","Some guidebooks written in Japanese","MPICH;Open MPI;Fujistu MPI;NEC MPI","I have no special reason.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).","Debugging","Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","Too many routines.","Mostly","Yes, to minimize the changes of communication API.","OpenMP;OpenACC","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Latency hiding (including asynchronous completion);Resilience (fault tolerance)","Process topologies;Dynamic process creation","Yes, compatibility is very important for me.","2"
"2019/03/17 10:56:24 PM AST","College/University","Japan","6","6","C/C++","more than 10 years","more than 10 years","System software development (OS, runtime library, communication library, etc.)","Research and development on system software (OS and/or runtime library)","I read all.","I read the MPI standard document.","Using MPI;MPI: The Complete Reference","MPICH;Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).","Debugging","","Point-to-point communications;Collective communications;MPI with OpenMP (or multithread);PMPI interface","MPI_THREAD_FUNNELED","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.","Bandwidth","Resilience (fault tolerance)","There are no unnecessary features","Yes, compatibility is very important for me.","3"
"2019/03/17 11:02:46 PM AST","College/University","Japan","3","3","C/C++;Fortran 90 or newer","more than 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I read book(s).","Using MPI","MPICH;Open MPI;MVAPICH;Intel MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation","Collective communications;Communicator operations (split, duplicate, and so on)","MPI_THREAD_MULTIPLE","Too many routines.","I rely on the default ‘Errors abort’ error handling","Yes, but I have no special reason for doing that.","OpenMP;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.;A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Bandwidth","MPI is providing all the communication semantics required by my application","There are no unnecessary features","I prefer to have new API which is simpler and/or easier-to-use.","3"
"2019/03/17 11:29:54 PM AST","Hardware vendor","Japan","5","4","C/C++;Fortran 90 or newer;Python","more than 10 years","more than 10 years","Parallel language (incl. domain specific language)","Research and development on system software (OS and/or runtime library)","I read only the chapters of interest for my work.","I read book(s).;I read articles found on Internet.","Using MPI-2","MPICH;Open MPI;MVAPICH;Fujistu MPI","I could not have any choice (the one provided by a vendor).","I search the Internet (Google / Stack Overflow).","Finding appropriate MPI routines","Dynamic process creation;Persistent communication","Point-to-point communications;Collective communications;MPI datatypes;One-sided communications","MPI_THREAD_SINGLE;I have never called MPI_INIT_THREAD","Too complicated and hard to understand.;I do not like the API.","Sometimes","No, my program is too small to do that.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Latency","I hope simply short latency.  It is not hiding.","One-sided communication","I prefer to have new API which is simpler and/or easier-to-use.","4"
"2019/03/18 12:34:34 AM AST","College/University","Japan","4","2","C/C++;Python","between 2 and 5 years","less than 2 years","Parallel language (incl. domain specific language);AI (Deep Learning);Image processing","Research and development of application(s)","I read only the chapters of interest for my work.","I had lecture(s) at school.","","Open MPI","I am familiar with it.","I read the MPI Standard document (web/book).","Performance tuning","One-sided communications;Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","No appropriate lecture / book / info.","Sometimes","Yes, to minimize the changes of communication API.","OpenMP;Pthread;CUDA","I think there is room but I do not know how to tune it.","A framework or library using MPI.","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","I am not sure about this","I am not sure","Yes, compatibility is very important for me.","5"
"2019/03/18 12:38:21 AM AST","College/University","Japan","5","3","C/C++;Lisp, Ocaml, Perl","more than 10 years","between 2 and 5 years","Parallel language (incl. domain specific language)","Research and development on system software (OS and/or runtime library)","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","スパコンプログラミング入門: 並列処理とMPIの学習, ISBN-13: 978-4130624534","Intel MPI;Cray MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Debugging","Communicator operations (split, duplicate, and so on);Persistent communication;PMPI interface","One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_MULTIPLE","No appropriate lecture / book / info.","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","OpenMP;Pthread","Yes, I know there is room for tuning but I do not have enough resources to do that.","Low-level communication layer provided by vendor (Verbs, DCMF, ...).","Multi-threading support","Endpoints (multi-thread, sessions)","There are no unnecessary features","I prefer to have new API which is simpler and/or easier-to-use.","4"
"2019/03/18 2:02:49 AM AST","College/University","Japan","4","3","C/C++","between 5 and 10 years","between 2 and 5 years","System software development (OS, runtime library, communication library, etc.)","Research and development on system software (OS and/or runtime library)","I have not read it, but I plan to.","I had lecture(s) at school.","I have never read any MPI books","MVAPICH","I was said to use it.","I search the Internet (Google / Stack Overflow).","Debugging","Persistent communication","Collective communications","I do not know or I do not care.","No appropriate lecture / book / info.","Never","No, my program is too small to do that.","OpenMP","I do not know if there is room for performance tuning.","I am not investigating any alternatives.","Bandwidth","Latency hiding (including asynchronous completion)","There are no unnecessary features","I do not know or I do not care.","3"
"2019/03/18 3:55:48 AM AST","College/University","Japan","5","4","C/C++;Python","more than 10 years","between 2 and 5 years","System software development (OS, runtime library, communication library, etc.);Parallel language (incl. domain specific language)","Research and development on system software (OS and/or runtime library)","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).;Other lectures or tutorials (workplace, conference).","Parallel Programming with MPI","Open MPI;MVAPICH;Intel MPI;Fujistu MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","","Point-to-point communications;Collective communications;One-sided communications;MPI with OpenMP (or multithread);PMPI interface","MPI_THREAD_SERIALIZED;MPI_THREAD_MULTIPLE","Too complicated and hard to understand.","Mostly","Yes, to minimize the changes of communication API.","OpenMP;Pthread;OpenACC","Yes, I know there is room for tuning but I do not have enough resources to do that.","Low-level communication layer provided by vendor (Verbs, DCMF, ...).","Multi-threading support","Latency hiding (including asynchronous completion);Endpoints (multi-thread, sessions);Another API which is easier and/or simpler to use","Datatypes","API should be clearly versioned.","4"
"2019/03/18 5:36:49 AM AST","Private research institute","Japan","6","5","C/C++;Python;JavaScript, MATLAB","more than 10 years","more than 10 years","Numerical application and/or library;Image processing;Tool development (performance tuning, debugging, etc.)","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","MPICH;Open MPI;MS MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Performance tuning","Dynamic process creation;Persistent communication;PMPI interface","Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Bandwidth","MPI is providing all the communication semantics required by my application","One-sided communication;Dynamic process creation","Yes, compatibility is very important for me.","3"
"2019/03/18 5:44:17 AM AST","College/University","Germany","5","5","C/C++","more than 10 years","between 5 and 10 years","System software development (OS, runtime library, communication library, etc.);Tool development (performance tuning, debugging, etc.)","Research and development on system software (OS and/or runtime library)","I read only the chapters of interest for my work.","I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","I have never read any MPI books","Open MPI;Intel MPI;Cray MPI","I am familiar with it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I ask colleagues.","Debugging","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;Persistent communications;MPI with OpenMP (or multithread)","MPI_THREAD_MULTIPLE","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","OpenMP;Pthread;OpenACC","No, my MPI programs are well-tuned.","Low-level communication layer provided by vendor (Verbs, DCMF, ...).;GASPI","Multi-threading support","RMA operation ordering","Process topologies;Dynamic process creation","API should be clearly versioned.","4"
"2019/03/18 5:58:47 AM AST","Governmental institute","Japan","5","5","C/C++","more than 10 years","more than 10 years","System software development (OS, runtime library, communication library, etc.)","Research and development on system software (OS and/or runtime library)","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).","Parallel Programming with MPI;Using MPI;Parallel Programming in C with MPI and OpenMP","MPICH;Open MPI;MVAPICH;Fujistu MPI","I am familiar with it.","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","MPI with OpenMP (or multithread)","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;PMPI interface","I have never called MPI_INIT_THREAD","Too many routines.","Mostly","No, MPI calls are scattered in my programs.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","Datatypes;Communicator and group management;Collective operations","I prefer to have new API which is simpler and/or easier-to-use.","3"
"2019/03/18 6:43:15 AM AST","Governmental institute","Germany","5","5","C/C++;Python","","","Tool development (performance tuning, debugging, etc.)","Research and development software tool(s);Performance tuning of MPI program(s)","I read most of it.","Other lectures or tutorials (workplace, conference).","Parallel Programming with MPI;Using MPI","MPICH;Open MPI;Intel MPI","I am familiar with it.","I read the MPI Standard document (web/book).","Performance tuning","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread);PMPI interface","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","","Error handlers","","2"
"2019/03/18 10:29:05 AM AST","Governmental institute","United States","5","4","C/C++","more than 10 years","between 2 and 5 years","System software development (OS, runtime library, communication library, etc.)","Research and development on system software (OS and/or runtime library);Research and development software tool(s)","I read only the chapters of interest for my work.","I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Using MPI;MPI: The Complete Reference","Open MPI;Cray MPI;IBM MPI (BG/Q, PE, Spectrum)","I am familiar with it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI with OpenMP (or multithread);PMPI interface","MPI_THREAD_MULTIPLE","I have no obstacles.","Mostly","No, my program is too small to do that.","No","I do not know if there is room for performance tuning.","I am not investigating any alternatives.","","Resilience (fault tolerance)","","I do not know or I do not care.","3"
"2019/03/18 11:59:57 AM AST","Hardware vendor","United States","6","5","C/C++;Julia","more than 10 years","between 5 and 10 years","System software development (OS, runtime library, communication library, etc.);Parallel language (incl. domain specific language)","Research and development on system software (OS and/or runtime library);Performance tuning of MPI program(s);Debugging MPI programs","I read only the chapters of interest for my work.","I read the MPI standard document.;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Using MPI;MPI: The Complete Reference","MPICH;Cray MPI","I am familiar with it.","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).;I search the Internet (Google / Stack Overflow).","Algorithm design","","Point-to-point communications;MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_MULTIPLE","I have no obstacles.","Always","Yes, to minimize the changes of communication API.","OpenMP;CUDA","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","I am not investigating any alternatives.","Message injection rate","Resilience (fault tolerance)","There are no unnecessary features","I prefer to have new API for better performance.","5"
"2019/03/18 8:44:00 PM AST","Governmental institute","Japan","4","5","C/C++","more than 10 years","more than 10 years","AI (Deep Learning);AI (non deep learning)","Research and development of application(s);Parallelization of sequential program(s)","I read only the chapters of interest for my work.","I read the MPI standard document.","I have never read any MPI books","MPICH;Open MPI;MVAPICH;Intel MPI;Cray MPI","I am familiar with it.","I read the MPI Standard document (web/book).;I search the Internet (Google / Stack Overflow).","Debugging","Communicator operations (split, duplicate, and so on);Dynamic process creation","Point-to-point communications;Collective communications","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED","Too complicated and hard to understand.","Mostly","Yes, to minimize the changes of communication API.","Pthread;TensorFlow","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.;A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Latency hiding (including asynchronous completion);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","Dynamic process creation","API should be clearly versioned.","1"
"2019/03/18 10:10:58 PM AST","College/University","China","5","4","C/C++","between 5 and 10 years","between 5 and 10 years","Parallel language (incl. domain specific language);AI (Deep Learning)","Research and development of application(s);Parallelization of sequential program(s)","I read only the chapters of interest for my work.","I read book(s).;I had lecture(s) at school.;I read articles found on Internet.","Parallel Programming in C with MPI and OpenMP","Open MPI;Intel MPI;Tianhe MPI","I have no special reason.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Finding appropriate MPI routines","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","Too many routines.;No appropriate lecture / book / info.","Sometimes","Yes, to minimize the changes of communication API.","OpenMP;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.","Bandwidth","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","There are no unnecessary features","Yes, compatibility is very important for me.","4"
"2019/03/19 3:41:04 AM AST","College/University","Japan","5","5","Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","I had lecture(s) at school.","Using MPI","Intel MPI;Fujistu MPI;NEC MPI;SGI MPI","I like to use it.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Performance tuning","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on)","I do not know or I do not care.","Too many routines.;Implementations based on the MPI specification depend on vendors.","Sometimes","Yes, to minimize the changes of communication API.","OpenMP","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Latency hiding (including asynchronous completion);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","Datatypes;Dynamic process creation;Error handlers","Yes, compatibility is very important for me.","5"
"2019/03/19 10:23:03 AM AST","College/University","Japan","6","4","C/C++;Python","more than 10 years","more than 10 years","System software development (OS, runtime library, communication library, etc.);Parallel language (incl. domain specific language)","Research and development of application(s);Research and development on system software (OS and/or runtime library)","I have not read it, but I plan to.","I read book(s).","Using MPI;MPI: The Complete Reference","MPICH;Open MPI","I have no special reason.","I read online documents (such as man pages).","Domain decomposition","Persistent communication","Point-to-point communications;Collective communications;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","OpenMP","I do not know if there is room for performance tuning.","A framework or library using MPI.;A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Message injection rate","","","I do not know or I do not care.","4"
"2019/03/20 4:30:44 AM AST","College/University","Japan","6","3","C/C++;Python","between 5 and 10 years","between 2 and 5 years","Numerical application and/or library","Research and development of application(s);Research and development software tool(s)","","I read the MPI standard document.;I had lecture(s) at school.;I read articles found on Internet.","","Open MPI;Intel MPI","I have no special reason.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).","Debugging","One-sided communications;PMPI interface","Collective communications;MPI datatypes","I have never called MPI_INIT_THREAD","Too many routines.;No appropriate lecture / book / info.","Sometimes","No, MPI calls are scattered in my programs.","OpenMP","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","I am not investigating any alternatives.","Bandwidth","","Process topologies","API should be clearly versioned.","4"
"2019/03/20 10:27:27 AM AST","College/University","Pakistan","3","3","C/C++;Python","less than 2 years","less than 2 years","Numerical application and/or library","Research student","I read most of it.","I read articles found on Internet.","","MPICH;Open MPI","I could not have any choice (the one provided by a vendor).","I search the Internet (Google / Stack Overflow).","Implementation issue workaround","Communicator operations (split, duplicate, and so on);Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_MULTIPLE;I have never called MPI_INIT_THREAD;I do not know or I do not care.","No appropriate lecture / book / info.;I have nobody to ask.","I rely on the default ‘Errors abort’ error handling","Yes, but I have no special reason for doing that.","No","No, my MPI programs are well-tuned.","","","Endpoints (multi-thread, sessions)","","Yes, compatibility is very important for me.","3"
"2019/03/20 10:29:14 AM AST","College/University","Saudi Arabia","5","4","C/C++;Java;Python","more than 10 years","between 2 and 5 years","Parallel language (incl. domain specific language)","Research and development of application(s);Research and development software tool(s)","I read only the chapters of interest for my work.","I read book(s).;I read articles found on Internet.","Parallel Programming in C with MPI and OpenMP","MS MPI","I have no special reason.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).","Domain decomposition","One-sided communications;PMPI interface","Point-to-point communications;Collective communications;MPI with OpenMP (or multithread)","I do not know or I do not care.","Too many routines.;No appropriate lecture / book / info.","I rely on the default ‘Errors abort’ error handling","","OpenMP","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","","","MPI is providing all the communication semantics required by my application","There are no unnecessary features","Yes, compatibility is very important for me.","3"
"2019/03/20 10:32:47 AM AST","Private research institute","México","5","2","C/C++;Fortran 90 or newer","between 5 and 10 years","between 2 and 5 years","Numerical application and/or library","Research and development of application(s)","I have not read it, but I plan to.","I read the MPI standard document.;I had lecture(s) at school.","I have never read any MPI books","MPICH","I have no special reason.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","I do not know or I do not care.","Too complicated and hard to understand.","Always","No, my program is too small to do that.","CUDA","I do not know if there is room for performance tuning.","I am not investigating any alternatives.","Bandwidth","MPI is providing all the communication semantics required by my application","There are no unnecessary features","I prefer to have new API which is simpler and/or easier-to-use.","4"
"2019/03/20 11:20:14 AM AST","Governmental institute","Argentina","3","1","Python;bash?","between 2 and 5 years","less than 2 years","Parallel language (incl. domain specific language)","HPC Administrator","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","I have never read any MPI books","MPICH;Open MPI","I have no special reason.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Performance tuning","MPI datatypes","Collective communications;Persistent communications","MPI_THREAD_MULTIPLE","Too complicated and hard to understand.;I have nobody to ask.","Mostly","No, MPI calls are scattered in my programs.","No","I do not know if there is room for performance tuning.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","There are no unnecessary features","Yes, compatibility is very important for me.","5"
"2019/03/20 5:53:05 PM AST","College/University","Peru","2","1","C/C++;Fortran (older one than Fortran 90);C#","less than 2 years","less than 2 years","Parallel language (incl. domain specific language);Numerical application and/or library","Research and development of application(s)","No, and I will not read it.","I have not learned MPI.","","","I have no special reason.","I search the Internet (Google / Stack Overflow).","Other","MPI with OpenMP (or multithread)","MPI with OpenMP (or multithread)","I do not know or I do not care.","Too complicated and hard to understand.","Mostly","No, my program is too small to do that.","No","No, my MPI programs are well-tuned.","I am not investigating any alternatives.","","","There are no unnecessary features","Yes, compatibility is very important for me.","5"
"2019/03/21 11:21:56 AM AST","Governmental institute","United States","5","4","C/C++","more than 10 years","between 5 and 10 years","System software development (OS, runtime library, communication library, etc.)","Research and development on system software (OS and/or runtime library)","I read only the chapters of interest for my work.","I read book(s).;Other lectures or tutorials (workplace, conference).","Using MPI","MPICH;Open MPI;MVAPICH;Intel MPI;Cray MPI","I am familiar with it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Algorithm design","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on)","MPI_THREAD_FUNNELED","Too many routines.","Never","No, my program is too small to do that.","OpenMP","I do not know if there is room for performance tuning.","I am not investigating any alternatives.","Message injection rate","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.);Another API which is easier and/or simpler to use","One-sided communication;Datatypes;Process topologies;Dynamic process creation;Error handlers","I prefer to have new API which is simpler and/or easier-to-use.","5"
"2019/03/25 3:54:23 AM AST","College/University","Japan","5","4","C/C++","more than 10 years","more than 10 years","System software development (OS, runtime library, communication library, etc.);Parallel language (incl. domain specific language)","Research and development on system software (OS and/or runtime library);Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).","Parallel Programming with MPI;Using MPI;Parallel Programming in C with MPI and OpenMP;Using Advanced MPI, Using MPI-2","MPICH;Open MPI;MVAPICH;Intel MPI","I like to use it.","I read the MPI Standard document (web/book).;I search the Internet (Google / Stack Overflow).","Implementation issue workaround","Persistent communication","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_MULTIPLE","No appropriate lecture / book / info.","Always","Yes, to minimize the changes of communication API.","OpenMP;Pthread","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.;A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Multi-threading support","Endpoints (multi-thread, sessions);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.);Another API which is easier and/or simpler to use","Communicator and group management;Process topologies","API should be clearly versioned.","3"
"2019/03/26 1:21:26 PM AST","College/University","Austria","5","5","C/C++;Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s)","I read most of it.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","MPI standard document","MPICH;Open MPI;Intel MPI","I like to use it.","I read the MPI Standard document (web/book).","Algorithm design","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;Persistent communications;MPI with OpenMP (or multithread);Cartesian topologies","MPI_THREAD_FUNNELED;MPI_THREAD_SERIALIZED;MPI_THREAD_MULTIPLE","I have no obstacles.;Too many routines.","I rely on the default ‘Errors abort’ error handling","No, MPI calls are scattered in my programs.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Latency hiding (including asynchronous completion);Resilience (fault tolerance);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","One-sided communication;Dynamic process creation","Yes, compatibility is very important for me.","4"
"2019/03/27 10:22:43 AM AST","Other","Spain","5","4","Fortran 90 or newer;Python","between 5 and 10 years","between 5 and 10 years","Parallel language (incl. domain specific language);Numerical application and/or library;Workflow and/or In-situ","Research and development of application(s);Research and development software tool(s)","No, and I will not read it.","I read book(s).;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","Open MPI;Intel MPI;IBM MPI (BG/Q, PE, Spectrum)","I have no special reason.","I read book(s) (except the MPI standard).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Domain decomposition","Collective communications;MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_MULTIPLE","Too complicated and hard to understand.","Always","Yes, to minimize the changes of communication API.","OpenMP","No, my MPI programs are well-tuned.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","There are no unnecessary features","I prefer to have new API for better performance.","4"
"2019/03/27 9:15:36 PM AST","Governmental institute","United States","4","6","C/C++;Fortran 90 or newer;Python","more than 10 years","more than 10 years","Parallel language (incl. domain specific language)","Research and development on system software (OS and/or runtime library)","","I read book(s).","Using MPI;MPI: The Complete Reference","Open MPI;Cray MPI;NEC MPI","I am familiar with it.","I read the MPI Standard document (web/book).","Domain decomposition","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_MULTIPLE","I have no obstacles.","Mostly","Yes, to minimize the changes of communication API.","OpenMP;Pthread","Yes, I know there is room for tuning but I do not have enough resources to do that.","A Domain Specific Language (DSL).","Multi-threading support","Endpoints (multi-thread, sessions)","","Yes, compatibility is very important for me.","2"
"2019/03/28 8:56:13 AM AST","College/University","Japan","4","1","Fortran (older one than Fortran 90);Fortran 90 or newer","more than 10 years","less than 2 years","Fluid Mechanics","Research and development of application(s)","I have not read it, but I plan to.","I have not learned MPI.","","MPICH;Intel MPI","I could not have any choice (the one provided by a vendor).","I ask colleagues.","Finding appropriate MPI routines","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;Dynamic process creation;Persistent communication;MPI with OpenMP (or multithread);PMPI interface","I don't know so well.","I do not know or I do not care.","Too many routines.;Too complicated and hard to understand.","","I don't know.","No","I do not know how to find bottlenecks.","I am not investigating any alternatives.","I don't know.","I don't know.","I don't know.","I do not know or I do not care.","3"
"2019/03/28 10:19:38 AM AST","College/University","Germany","4","6","C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer","more than 10 years","more than 10 years","Teaching of MPI and OpenMP","Teaching of MPI and OpenMP","I read most of it.","Other lectures or tutorials (workplace, conference).;Member of the MPI Forum since MPI-2.0","Using MPI","MPICH;Open MPI;Intel MPI;Cray MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).","","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications","I have never called MPI_INIT_THREAD","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","No, my program is too small to do that.","OpenMP;(""MPI + MPI-3 shared memory"" instead of ""MPI+OpenMP"")","","A framework or library using MPI.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","Dynamic process creation;Error handlers","Yes, compatibility is very important for me.","2"
"2019/04/01 5:38:37 AM AST","College/University","Germany","5","5","C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer;Python","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","I read most of it.","I read the MPI standard document.;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","MPICH;Open MPI;Intel MPI;Cray MPI;NEC MPI","","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).;I know almost all MPI routines.","Implementation issue workaround","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED;MPI_THREAD_SERIALIZED;MPI_THREAD_MULTIPLE","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","No, MPI calls are scattered in my programs.","OpenMP;Pthread","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","MPI provides all semantics I need","","","Yes, compatibility is very important for me.","4"
"2019/04/01 8:31:01 AM AST","College/University","Germany","4","2","C/C++;Python","more than 10 years","between 2 and 5 years","Numerical application and/or library;Image processing;Visualization;Tool development (performance tuning, debugging, etc.)","Research and development of application(s);Research and development software tool(s);Parallelization of sequential program(s)","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","MPICH;Open MPI","I have no special reason.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","PMPI interface","Collective communications;Communicator operations (split, duplicate, and so on)","I do not know or I do not care.","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","No, MPI calls are scattered in my programs.","No","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.","Bandwidth","Latency hiding (including asynchronous completion)","There are no unnecessary features","API should be clearly versioned.","4"
"2019/04/01 8:32:14 AM AST","College/University","Spain","5","4","C/C++;Fortran 90 or newer;Python","between 5 and 10 years","less than 2 years","Numerical application and/or library","Research and development of application(s);Research and development software tool(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","MPICH;Open MPI","I have no special reason.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Domain decomposition","Persistent communication;PMPI interface","Point-to-point communications;Collective communications;One-sided communications","I have never called MPI_INIT_THREAD","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","OpenMP;CUDA","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","I am not investigating any alternatives.","Latency","Latency hiding (including asynchronous completion)","Dynamic process creation","I prefer to have new API for better performance.","4"
"2019/04/01 8:35:08 AM AST","College/University","Germany","4","4","Fortran 90 or newer","between 5 and 10 years","between 2 and 5 years","Numerical application and/or library;Visualization","Research and development of application(s)","","Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","I have never read any MPI books","MPICH;Open MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on)","I have never called MPI_INIT_THREAD","Too many routines.","Mostly","No, MPI calls are scattered in my programs.","No","I do not know if there is room for performance tuning.","I am not investigating any alternatives.","MPI provides all semantics I need","Resilience (fault tolerance);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","","Yes, compatibility is very important for me.","4"
"2019/04/01 8:36:38 AM AST","College/University","Egypt","6","5","C/C++;Fortran 90 or newer","more than 10 years","between 5 and 10 years","System software development (OS, runtime library, communication library, etc.);Parallel language (incl. domain specific language);Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I had lecture(s) at school.","Parallel Programming with MPI","MPICH;MS MPI","I am familiar with it.","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Implementation issue workaround","MPI with OpenMP (or multithread);PMPI interface","Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;Dynamic process creation","I do not know or I do not care.","Too complicated and hard to understand.","I rely on the default ‘Errors abort’ error handling","No, MPI calls are scattered in my programs.","No","I do not know if there is room for performance tuning.","I am not investigating any alternatives.","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Another API which is easier and/or simpler to use","There are no unnecessary features","Yes, compatibility is very important for me.","4"
"2019/04/01 8:37:35 AM AST","Software vendor","Germany","4","2","Fortran 90 or newer","more than 10 years","less than 2 years","Parallel language (incl. domain specific language)","Research and development software tool(s)","No, and I will not read it.","Other lectures or tutorials (workplace, conference).","I have never read any MPI books","Intel MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Debugging","Collective communications;Communicator operations (split, duplicate, and so on);MPI with OpenMP (or multithread)","Collective communications;One-sided communications;MPI with OpenMP (or multithread)","I do not know or I do not care.","Too complicated and hard to understand.;MPI details are low priority in current tasks, done by colleagues","I rely on the default ‘Errors abort’ error handling","Partly","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Latency hiding (including asynchronous completion);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","Don't know","I do not know or I do not care.","4"
"2019/04/01 8:40:51 AM AST","Governmental institute","Italy","6","6","Fortran 90 or newer","more than 10 years","more than 10 years","Scientific simulations","Research scientist","I read only the chapters of interest for my work.","I read book(s).;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Using MPI;MPI: The Complete Reference","MPICH;Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read book(s) (except the MPI standard).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Other","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI with OpenMP (or multithread)","I do not know or I do not care.","mastering parallel Input/Output","Sometimes","No, MPI calls are scattered in my programs.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Multi-threading support","Another API which is easier and/or simpler to use","There are no unnecessary features","Yes, compatibility is very important for me.","2"
"2019/04/01 8:41:21 AM AST","College/University","Germany","4","1","Python;Perl","more than 10 years","less than 2 years","Tool development (performance tuning, debugging, etc.)","System administration","No, and I will not read it.","I have not learned MPI.","","Open MPI;Intel MPI","I have no special reason.","I don't write MPI programs","Other","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;Dynamic process creation;Persistent communication","None","I do not know or I do not care.","No immediate need to do so","","I do not call MPI routines","No","I do not know if there is room for performance tuning.","I am not investigating any alternatives.","I don't know","I don't know","I don't know","API should be clearly versioned.","3"
"2019/04/01 8:42:58 AM AST","College/University","Germany","5","2","C/C++;Python","more than 10 years","between 2 and 5 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I had lecture(s) at school.","","I do not know","I was said to use it.","I read the MPI Standard document (web/book).;I search the Internet (Google / Stack Overflow).","Domain decomposition","Dynamic process creation;Persistent communication;PMPI interface","Collective communications;MPI with OpenMP (or multithread)","MPI_THREAD_FUNNELED","no pressing need to master it","Always","No, my program is too small to do that.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","do not know","I prefer to have new API which is simpler and/or easier-to-use.","3"
"2019/04/01 8:43:23 AM AST","Governmental institute","Italy","4","3","Fortran 90 or newer;Python","between 5 and 10 years","between 2 and 5 years","Numerical application and/or library;Visualization","Research and development software tool(s)","I have not read it, but I plan to.","Other lectures or tutorials (workplace, conference).","I have never read any MPI books","MPICH;Open MPI","I have no special reason.","I search the Internet (Google / Stack Overflow).","Finding appropriate MPI routines","Dynamic process creation;Persistent communication;PMPI interface","Collective communications","MPI_THREAD_SINGLE","I have no obstacles.;No appropriate lecture / book / info.","Sometimes","not sure","No","I do not know if there is room for performance tuning.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","There are no unnecessary features","Yes, compatibility is very important for me.","3"
"2019/04/01 8:43:46 AM AST","College/University","France","4","5","Fortran 90 or newer","between 2 and 5 years","between 2 and 5 years","Numerical application and/or library","Research and development of application(s)","I have not read it, but I plan to.","Other lectures or tutorials (workplace, conference).","","Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).","Implementation issue workaround","Dynamic process creation","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","OpenMP","No, my MPI programs are well-tuned.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Multi-threading support","Endpoints (multi-thread, sessions)","Datatypes","I do not know or I do not care.","3"
"2019/04/01 8:44:13 AM AST","Governmental institute","France","5","4","C/C++;Fortran 90 or newer;Python;matlab","between 5 and 10 years","between 2 and 5 years","Numerical application and/or library;Visualization","Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).","I have never read any MPI books","MPICH;Intel MPI","I was said to use it.","I read online documents (such as man pages).;Lecture notes/preexisting source code","Performance tuning","Point-to-point communications;Collective communications;MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","Point-to-point communications;Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","Too many routines.","Sometimes","No, MPI calls are scattered in my programs.","OpenMP","My job is to tune them","I am not investigating any alternatives.","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","MPI is providing all the communication semantics required by my application","One-sided communication;Process topologies;Dynamic process creation","I prefer to have new API which is simpler and/or easier-to-use.","1"
"2019/04/01 8:44:29 AM AST","College/University","Germany","6","3","C/C++;Python","more than 10 years","between 2 and 5 years","Numerical application and/or library","Research and development of application(s);Research and development software tool(s);Parallelization of sequential program(s)","I have not read it, but I plan to.","I read articles found on Internet.","I have never read any MPI books","MPICH;Open MPI;Intel MPI","I am familiar with it.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Domain decomposition","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","I have nobody to ask.","Sometimes","Yes, to minimize the changes of communication API.","OpenMP","I think there is room but I do not know how to tune it.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","MPI is providing all the communication semantics required by my application","Dynamic process creation","API should be clearly versioned.","4"
"2019/04/01 8:48:29 AM AST","Governmental institute","Germany","5","3","C/C++;Python","more than 10 years","between 2 and 5 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).","Beginning MPI (An Introduction in C)","Open MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).","Domain decomposition","Point-to-point communications;Collective communications;MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","Point-to-point communications;Collective communications;One-sided communications","I have never called MPI_INIT_THREAD","I have nobody to ask.","Sometimes","No, my program is too small to do that.","No","I think there is room but I do not know how to tune it.","A framework or library using MPI.;A Domain Specific Language (DSL).","","","Process topologies;Dynamic process creation","I prefer to have new API which is simpler and/or easier-to-use.","2"
"2019/04/01 8:50:18 AM AST","College/University","Germany","4","3","C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer","between 2 and 5 years","between 2 and 5 years","Numerical application and/or library","Research and development of application(s)","No, and I will not read it.","Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","MPICH;Open MPI;I do not know","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes","I have never called MPI_INIT_THREAD","Too many routines.","Never","Sometimes, to make code more readable","OpenMP","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A framework or library using MPI.","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","MPI is providing all the communication semantics required by my application","One-sided communication;Process topologies;Dynamic process creation;Error handlers","Yes, compatibility is very important for me.","2"
"2019/04/01 8:50:40 AM AST","College/University","United Kingdom","6","3","C/C++","between 5 and 10 years","less than 2 years","Numerical application and/or library","Research and development software tool(s)","No, and I will not read it.","I had lecture(s) at school.;I read articles found on Internet.","I have never read any MPI books","Open MPI","I like to use it.","I read online documents (such as man pages).","Domain decomposition","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;Dynamic process creation;Persistent communication;MPI with OpenMP (or multithread);PMPI interface","","MPI_THREAD_MULTIPLE","No appropriate lecture / book / info.;Too complicated and hard to understand.;I have nobody to ask.","Never","No, MPI calls are scattered in my programs.","OpenACC","I do not have (know) tools to find performance bottlenecks.","I am not investigating any alternatives.","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","","","I prefer to have new API which is simpler and/or easier-to-use.","4"
"2019/04/01 8:51:08 AM AST","Governmental institute","Italy","5","4","C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer;Python","more than 10 years","more than 10 years","Numerical application and/or library;AI (Deep Learning)","Research and development of application(s);Research and development software tool(s)","I read most of it.","I read the MPI standard document.;I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","MPI: The Complete Reference","MPICH;Open MPI;MVAPICH;Intel MPI","I am familiar with it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Performance tuning","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","I do not know or I do not care.","Too many routines.","Sometimes","No, MPI calls are scattered in my programs.","OpenMP;OpenCL;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.","Bandwidth","Latency hiding (including asynchronous completion);Endpoints (multi-thread, sessions);Resilience (fault tolerance);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.);Another API which is easier and/or simpler to use","There are no unnecessary features","Yes, compatibility is very important for me.","5"
"2019/04/01 8:51:11 AM AST","College/University","Germany","4","3","C/C++;Fortran 90 or newer;Python;Matlab","between 5 and 10 years","less than 2 years","Numerical application and/or library","Parallelization of sequential program(s);Performance tuning of MPI program(s);Support and training of researchers","I have not read it, but I plan to.","Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","I have never read any MPI books","Open MPI;Intel MPI","I am familiar with it.","I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications","I have never called MPI_INIT_THREAD;I do not know or I do not care.","I have no obstacles.","Sometimes","No, MPI calls are scattered in my programs.","No","I do not know how to find bottlenecks.","A framework or library using MPI.;Matlab Distributed Computing Functionality","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","One-sided communication;Communicator and group management;Dynamic process creation","API should be clearly versioned.","4"
"2019/04/01 8:51:24 AM AST","Private research institute","Germany","5","1","C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer;Python","between 5 and 10 years","less than 2 years","Numerical application and/or library","Research and development software tool(s)","I read only the chapters of interest for my work.","I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Parallel Programming with MPI;Using MPI","Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","Too complicated and hard to understand.;I have nobody to ask.","Mostly","No, MPI calls are scattered in my programs.","No","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","","","","Yes, compatibility is very important for me.","2"
"2019/04/01 8:51:35 AM AST","College/University","Germany","5","3","C/C++","between 5 and 10 years","between 2 and 5 years","Simulation","Research and development of application(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).","","Open MPI;Intel MPI;ParaStation MPI","I have no special reason.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).","Performance tuning","","Point-to-point communications;Collective communications;MPI datatypes","I do not know or I do not care.","I do not like the API.","Mostly","No, MPI calls are scattered in my programs.","No","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","MPI is providing all the communication semantics required by my application","One-sided communication;Process topologies","API should be clearly versioned.","3"
"2019/04/01 8:52:45 AM AST","College/University","Germany","5","3","C/C++","more than 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","MPICH;Open MPI;Intel MPI;Fujistu MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED;MPI_THREAD_SERIALIZED;MPI_THREAD_MULTIPLE","Too many routines.","Mostly","Yes, to minimize the changes of communication API.","OpenMP;Pthread","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.","Bandwidth","Resilience (fault tolerance)","One-sided communication","API should be clearly versioned.","4"
"2019/04/01 8:53:32 AM AST","College/University","Germany","3","2","C/C++","between 5 and 10 years","less than 2 years","Numerical application and/or library","Research and development of application(s);Research and development software tool(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).;Other lectures or tutorials (workplace, conference).","Hager, Wellstein: Introduction to high Performance Computing","MPICH;Open MPI;Intel MPI","I have no special reason.","I read the MPI Standard document (web/book).;I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications","I have never called MPI_INIT_THREAD","I do not like the API.","Never","No, MPI calls are scattered in my programs.","No","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","","","","I prefer to have new API which is simpler and/or easier-to-use.","3"
"2019/04/01 8:53:45 AM AST","College/University","United Kingdom","5","5","Fortran 90 or newer;Python;bash","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s);Research and development software tool(s);Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","No, and I will not read it.","Other lectures or tutorials (workplace, conference).;I read articles found on Internet.;Learnt by studying other peoples' code","","MPICH;Open MPI;MVAPICH;Intel MPI;Cray MPI;HPE MPI","I have no special reason.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;Dynamic process creation;MPI with OpenMP (or multithread);PMPI interface","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","I have no obstacles.","Mostly","Yes, to minimize the changes of communication API.","OpenMP;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.;A Domain Specific Language (DSL).","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Endpoints (multi-thread, sessions);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","One-sided communication","I prefer to have new API for better performance.","3"
"2019/04/01 8:54:42 AM AST","College/University","Sweden","5","5","Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).","I have never read any MPI books","Open MPI;Intel MPI","I like to use it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I know almost all MPI routines.","Performance tuning","Persistent communication","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes","MPI_THREAD_FUNNELED;I have never called MPI_INIT_THREAD","I have no obstacles.","Never","No, MPI calls are scattered in my programs.","OpenMP","I work on MPI performance, but one can always do better.","","Latency","MPI is providing all the communication semantics required by my application","","Yes, compatibility is very important for me.","2"
"2019/04/01 8:55:16 AM AST","Private research institute","Germany","5","3","Fortran 90 or newer","more than 10 years","less than 2 years","Parallel language (incl. domain specific language);Numerical application and/or library","Research and development of application(s);Parallelization of sequential program(s);Debugging MPI programs","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).","I have never read any MPI books","Open MPI","I am familiar with it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes","I do not know or I do not care.","Too complicated and hard to understand.;I have nobody to ask.","I rely on the default ‘Errors abort’ error handling","No, MPI calls are scattered in my programs.","No","I have no chance to investigate.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","MPI is providing all the communication semantics required by my application","There are no unnecessary features","Yes, compatibility is very important for me.","3"
"2019/04/01 8:56:36 AM AST","College/University","Germany","5","4","C/C++","more than 10 years","more than 10 years","Numerical application and/or library;Tool development (performance tuning, debugging, etc.)","Research and development of application(s);Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","I read book(s).;I read articles found on Internet.","","MPICH;Open MPI;Intel MPI;IBM MPI (BG/Q, PE, Spectrum)","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Performance tuning","Dynamic process creation;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_FUNNELED","","Sometimes","Yes, to minimize the changes of communication API.","OpenMP;Pthread;CUDA","I think there is room but I do not know how to tune it.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","improve on one sided communication (GASPI, shmem style)","truely(!) one sided comm, see one before","One-sided communication","I prefer to have new API which is simpler and/or easier-to-use.","5"
"2019/04/01 8:56:37 AM AST","College/University","Croatia","5","3","Fortran (older one than Fortran 90);Fortran 90 or newer;Python","more than 10 years","between 5 and 10 years","Parallel language (incl. domain specific language);Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).","Parallel Programming with MPI;MPI: The Complete Reference","MPICH;Open MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).","Debugging","","Point-to-point communications;Collective communications;MPI datatypes;Dynamic process creation;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE","No appropriate lecture / book / info.","Mostly","No, MPI calls are scattered in my programs.","No","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","I am not investigating any alternatives.","Multi-threading support","Latency hiding (including asynchronous completion)","There are no unnecessary features","Yes, compatibility is very important for me.","3"
"2019/04/01 8:56:52 AM AST","Governmental institute","United Kingdom","4","4","C/C++;Fortran 90 or newer;Python","between 5 and 10 years","between 5 and 10 years","Numerical application and/or library;Plasma Physics","Research and development software tool(s);Performance tuning of MPI program(s)","No, and I will not read it.","I had lecture(s) at school.;I read articles found on Internet.","I have never read any MPI books","MPICH;Open MPI;Cray MPI;IBM MPI (BG/Q, PE, Spectrum)","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I ask colleagues.","Algorithm design","PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);Persistent communications;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","I have no obstacles.","Sometimes","Yes, to simplify the code for other developers, who are often not software specialists","OpenMP","Yes, we are doing this.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","There are no unnecessary features","Both ""I prefer to have new API for better performance"" and ""API should be clearly versioned""","3"
"2019/04/01 8:57:25 AM AST","Other","Germany","4","2","C/C++;Python","more than 10 years","less than 2 years","Numerical application and/or library;Workflow and/or In-situ;Visualization","Research and development software tool(s);Debugging MPI programs","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","Open MPI;Intel MPI;IBM MPI (BG/Q, PE, Spectrum);HPE MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).","Domain decomposition","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes","I do not know or I do not care.","I have no obstacles.","Mostly","No, my program is too small to do that.","OpenMP","I have no chance to investigate.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","There are no unnecessary features","I do not know or I do not care.","4"
"2019/04/01 8:58:10 AM AST","Governmental institute","France","3","3","Fortran (older one than Fortran 90);Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I had lecture(s) at school.","I have never read any MPI books","Open MPI;Intel MPI","I am familiar with it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","","Point-to-point communications;Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_MULTIPLE","I have no obstacles.","Never","No, MPI calls are scattered in my programs.","OpenMP;OpenACC","No, my MPI programs are well-tuned.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","One-sided communication;Process topologies;Dynamic process creation;Error handlers","API should be clearly versioned.","3"
"2019/04/01 8:58:17 AM AST","College/University","Serbia","5","4","C/C++","more than 10 years","","Parallel language (incl. domain specific language);Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Parallel Programming in C with MPI and OpenMP","MPICH;Open MPI","I was said to use it.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","Dynamic process creation","Point-to-point communications;Collective communications;MPI datatypes;Persistent communications;MPI with OpenMP (or multithread)","MPI_THREAD_FUNNELED","Too many routines.;Too complicated and hard to understand.","Sometimes","No, my program is too small to do that.","OpenMP;OpenACC;CUDA","I think there is room but I do not know how to tune it.","I am not investigating any alternatives.","Bandwidth","Another API which is easier and/or simpler to use","Datatypes;Process topologies","I prefer to have new API which is simpler and/or easier-to-use.","4"
"2019/04/01 8:58:50 AM AST","College/University","Sweden","5","3","C/C++","more than 10 years","more than 10 years","System software development (OS, runtime library, communication library, etc.)","Research and development on system software (OS and/or runtime library)","I read only the chapters of interest for my work.","I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","Using MPI","MPICH;Open MPI;MVAPICH;Intel MPI;Cray MPI","I am familiar with it.","I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Performance tuning","Persistent communication","Point-to-point communications;Collective communications;One-sided communications;MPI with OpenMP (or multithread);PMPI interface","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","I have no obstacles.","Mostly","No, MPI calls are scattered in my programs.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","Low-level communication layer provided by vendor (Verbs, DCMF, ...).","Latency","Resilience (fault tolerance);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","There are no unnecessary features","API should be clearly versioned.","5"
"2019/04/01 8:58:57 AM AST","College/University","Germany","5","5","C/C++","between 5 and 10 years","between 2 and 5 years","System software development (OS, runtime library, communication library, etc.);administration, workflow management / counseling","Comp. Scientist at HPC site","I read most of it.","I read book(s).;Other lectures or tutorials (workplace, conference).","Parallel Programming with MPI","Open MPI;MVAPICH;Intel MPI","I am familiar with it.","I read the MPI Standard document (web/book).;I search the Internet (Google / Stack Overflow).","Algorithm design","Persistent communication","Point-to-point communications;Collective communications;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","not constantly writing MPI related code, hard getting back on track","Sometimes","Yes, to minimize the changes of communication API.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","","","Process topologies;Dynamic process creation","I do not know or I do not care.","2"
"2019/04/01 8:59:03 AM AST","College/University","Poland","3","5","C/C++;Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s);Performance tuning of MPI program(s);Debugging MPI programs;Research support","I read most of it.","I read the MPI standard document.;I read book(s).;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Using MPI;MPI: The Complete Reference;Advanced MPI (Hoefler et al.)","MPICH;Open MPI;Intel MPI;Cray MPI;NEC MPI","I am familiar with it.","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","","Point-to-point communications;Collective communications;One-sided communications","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","I have no obstacles.","Mostly","No, my program is too small to do that.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Another API which is easier and/or simpler to use","Dynamic process creation","I do not know or I do not care.","4"
"2019/04/01 9:00:05 AM AST","Governmental institute","Germany","4","3","Fortran (older one than Fortran 90);Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I read articles found on Internet.","I have never read any MPI books","MPICH;Open MPI;Intel MPI","I have no special reason.","I search the Internet (Google / Stack Overflow).","Algorithm design","Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes","I have never called MPI_INIT_THREAD","Problems with memory consumption","Sometimes","Yes, to minimize the changes of communication API.","OpenMP","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","Dynamic process creation","Yes, compatibility is very important for me.","2"
"2019/04/01 9:00:34 AM AST","College/University","Germany","3","1","C/C++;Python","between 5 and 10 years","less than 2 years","Numerical application and/or library","Research and development software tool(s);Parallelization of sequential program(s)","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","Open MPI","I was said to use it.","I ask colleagues.;I search the Internet (Google / Stack Overflow).","Implementation issue workaround","Point-to-point communications;One-sided communications;Dynamic process creation;Persistent communication;PMPI interface","Communicator operations (split, duplicate, and so on);MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD;I do not know or I do not care.","I have no obstacles.","Never","No, MPI calls are scattered in my programs.","No","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","","MPI is providing all the communication semantics required by my application","One-sided communication;Communicator and group management;Process topologies;Dynamic process creation;Error handlers","I do not know or I do not care.","5"
"2019/04/01 9:00:36 AM AST","College/University","Germany","4","3","Fortran 90 or newer","between 5 and 10 years","between 2 and 5 years","Numerical application and/or library","Research and development of application(s)","No, and I will not read it.","Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","Open MPI","I could not have any choice (the one provided by a vendor).","I ask colleagues.;I search the Internet (Google / Stack Overflow).","Performance tuning","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","I do not know or I do not care.","I have no obstacles.","Always","Yes, to minimize the changes of communication API.","No","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","","","","I do not know or I do not care.",""
"2019/04/01 9:02:34 AM AST","College/University","Germany","4","3","C/C++;Python","between 2 and 5 years","less than 2 years","Numerical application and/or library","Research and development of application(s)","","I read articles found on Internet.","I have never read any MPI books","Open MPI","I was said to use it.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","Dynamic process creation;Persistent communication","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes","I have never called MPI_INIT_THREAD","I have nobody to ask.;I do not like the API.","I rely on the default ‘Errors abort’ error handling","No, MPI calls are scattered in my programs.","No","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","MPI provides all semantics I need","Endpoints (multi-thread, sessions)","Dynamic process creation","Yes, compatibility is very important for me.","2"
"2019/04/01 9:02:51 AM AST","College/University","Germany","5","3","Fortran 90 or newer","between 5 and 10 years","less than 2 years","Numerical application and/or library","Research and development software tool(s)","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).","I have never read any MPI books","Open MPI;Intel MPI","I have no special reason.","I read the MPI Standard document (web/book).;I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation;Persistent communication;PMPI interface","","","No appropriate lecture / book / info.","","No, my program is too small to do that.","No","I think there is room but I do not know how to tune it.","I am not investigating any alternatives.","","","","",""
"2019/04/01 9:03:40 AM AST","College/University","Germany","4","3","Fortran (older one than Fortran 90);Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).;I have not learned MPI.;learning by doing","I have never read any MPI books","MPICH;Open MPI;Intel MPI","I was said to use it.","I read the MPI Standard document (web/book).","Debugging","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;One-sided communications","I do not know or I do not care.","i am supervising a group of developers","Always","No, MPI calls are scattered in my programs.","No","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","I don't understand the question, we are fighting with latency and bandwidth","MPI is providing all the communication semantics required by my application","I am not sure because I don't have the full overview","Yes, compatibility is very important for me.","3"
"2019/04/01 9:04:11 AM AST","Governmental institute","Switzerland","5","3","C/C++;Fortran 90 or newer;Python","more than 10 years","more than 10 years","Numerical application and/or library","Parallelization of sequential program(s)","I read all.","I read the MPI standard document.;I read book(s).;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","MPICH;Open MPI;Intel MPI","I am familiar with it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Performance tuning","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_FUNNELED","","I rely on the default ‘Errors abort’ error handling","No, MPI calls are scattered in my programs.","OpenMP","I think the MPI implementation could be tuned, but I had no time to experiment with that so far.","I am not investigating any alternatives.","Latency","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","Process topologies;Dynamic process creation","I prefer to have new API for better performance.","5"
"2019/04/01 9:04:44 AM AST","College/University","Sweden","3","4","C/C++;Fortran (older one than Fortran 90);Python","more than 10 years","more than 10 years","System software development (OS, runtime library, communication library, etc.);Parallel language (incl. domain specific language);Numerical application and/or library;Tool development (performance tuning, debugging, etc.)","Performance tuning of MPI program(s);Debugging MPI programs;Advanced user/application support and training","I read most of it.","I read the MPI standard document.;I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.;By reading existing code","Using MPI;MPI: The Complete Reference","MPICH;Open MPI;MVAPICH;Intel MPI","I am familiar with it.","I read the MPI Standard document (web/book).;I search the Internet (Google / Stack Overflow).","Algorithm design","Persistent communication","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread);PMPI interface","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED;MPI_THREAD_SERIALIZED","Too many routines.;The practical details of using a certain MPI in a certain way on a certain system makes a lot of other wise simple things hard (debuggers, pinning, start up sanity, terminal IO, file IO, ..)","Sometimes","I either work on some one else large code base or my own simple tests/examples/proxies. My code is usually single file. ","OpenMP;Pthread","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.;A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Multi-threading support","Endpoints (multi-thread, sessions);Resilience (fault tolerance)","One-sided communication;Dynamic process creation","Hard question to answer either or on. It should be clearly versioned, mainly backward compatible unless impossible by important future performance and/or interop reasons. Clear enough? ;-)","3"
"2019/04/01 9:05:17 AM AST","Software vendor","Germany","3","5","C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer;Python;tcl/tk","more than 10 years","between 5 and 10 years","System software development (OS, runtime library, communication library, etc.);Numerical application and/or library;Big data;Workflow and/or In-situ","Research and development of application(s);Research and development on system software (OS and/or runtime library);Research and development software tool(s);Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","I had lecture(s) at school.","Beginning MPI (An Introduction in C);Parallel Programming with MPI;Using MPI;Parallel Programming in C with MPI and OpenMP;MPI: The Complete Reference","MPICH;Open MPI;MVAPICH;Intel MPI;Cray MPI;IBM MPI (BG/Q, PE, Spectrum)","I have no special reason.","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Performance tuning","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","I do not know or I do not care.","Thinking in parallel paradigm","Mostly","Yes, to minimize the changes of communication API.","OpenMP;OpenACC;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.;A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).;A Domain Specific Language (DSL).","Not fully aware of the issue","Not fully aware of the issue","Haven't tried all. So can not comment","I prefer to have new API which is simpler and/or easier-to-use.","3"
"2019/04/01 9:05:32 AM AST","Governmental institute","France","5","5","C/C++;Fortran 90 or newer;Python","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s)","","I read the MPI standard document.;I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Parallel Programming with MPI;Using MPI;Parallel Programming in C with MPI and OpenMP;MPI: The Complete Reference","MPICH;Open MPI;Intel MPI;Cray MPI;IBM MPI (BG/Q, PE, Spectrum)","I am familiar with it.","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","","","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE;I have never called MPI_INIT_THREAD","I have no obstacles.;Too many routines.","Mostly","No, MPI calls are scattered in my programs.","OpenMP","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","I am not investigating any alternatives.","Multi-threading support","Another API which is easier and/or simpler to use;MPI is providing all the communication semantics required by my application","There are no unnecessary features","API should be clearly versioned.","1"
"2019/04/01 9:06:02 AM AST","College/University","Germany","5","5","C/C++;Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library","Parallelization of sequential program(s);Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","I read book(s).;I read articles found on Internet.","Using MPI","Open MPI;Intel MPI;HPE MPI","I could not have any choice (the one provided by a vendor).","I know almost all MPI routines.","Algorithm design","PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_MULTIPLE","I have no obstacles.","Sometimes","Yes, to minimize the changes of communication API.","OpenMP;Pthread","No, my MPI programs are well-tuned.","I am not investigating any alternatives.","MPI provides all semantics I need","Resilience (fault tolerance)","Dynamic process creation","I prefer to have new API for better performance.","3"
"2019/04/01 9:06:35 AM AST","Software vendor","United States","6","5","C/C++","more than 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s);Performance tuning of MPI program(s);Debugging MPI programs","I read most of it.","I read book(s).;I read articles found on Internet.;Biggest learning tool was making toy programs and seeing performance.","Parallel Programming with MPI;Using MPI;MPI: The Complete Reference","Open MPI;Intel MPI;Cray MPI;IBM MPI (BG/Q, PE, Spectrum);MS MPI","I have no special reason.","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Algorithm design","Dynamic process creation","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;Persistent communications;MPI with OpenMP (or multithread)","MPI_THREAD_SERIALIZED","I have no obstacles.","Always","Yes, to minimize the changes of communication API.","OpenMP;TBB","Work on tuning is underway.","I am not investigating any alternatives.","Multi-threading support","Endpoints (multi-thread, sessions)","Dynamic process creation","API should be clearly versioned.","4"
"2019/04/01 9:07:09 AM AST","Private research institute","United Kingdom","4","3","C/C++","between 5 and 10 years","between 2 and 5 years","Numerical application and/or library","Research and development on system software (OS and/or runtime library)","","I read book(s).;I had lecture(s) at school.;I read articles found on Internet.","Using MPI","MPICH;Open MPI;Intel MPI","I was said to use it.","I read book(s) (except the MPI standard).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Domain decomposition","Communicator operations (split, duplicate, and so on);Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","I do not know or I do not care.","No appropriate lecture / book / info.","I rely on the default ‘Errors abort’ error handling","No, my program is too small to do that.","OpenMP","I think there is room but I do not know how to tune it.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","There are no unnecessary features","I prefer to have new API for better performance.","3"
"2019/04/01 9:07:54 AM AST","College/University","Germany","3","3","C/C++;Python","more than 10 years","between 2 and 5 years","","Research and development of application(s);Parallelization of sequential program(s)","I read only the chapters of interest for my work.","I read book(s).;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Domain decomposition","Dynamic process creation","Point-to-point communications;Collective communications;PMPI interface","","","I rely on the default ‘Errors abort’ error handling","No, MPI calls are scattered in my programs.","OpenMP","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","","Multi-threading support","MPI is providing all the communication semantics required by my application","There are no unnecessary features","API should be clearly versioned.","4"
"2019/04/01 9:08:51 AM AST","College/University","Germany","5","","C/C++;Python","between 5 and 10 years","between 5 and 10 years","System software development (OS, runtime library, communication library, etc.);Parallel language (incl. domain specific language);Numerical application and/or library;AI (Deep Learning);Big data;Visualization;Tool development (performance tuning, debugging, etc.)","Research and development of application(s);Research and development on system software (OS and/or runtime library);Research and development software tool(s);Parallelization of sequential program(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).;Other lectures or tutorials (workplace, conference).","Parallel Programming with MPI;MPI: The Complete Reference","MPICH;Open MPI;MVAPICH;Intel MPI;NEC MPI","I have no special reason.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Other","PMPI interface","Dynamic process creation","I do not know or I do not care.","Too many routines.","Sometimes","Yes, to minimize the changes of communication API.","OpenMP;CUDA","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","I am not investigating any alternatives.","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Endpoints (multi-thread, sessions)","There are no unnecessary features","Yes, compatibility is very important for me.","5"
"2019/04/01 9:08:53 AM AST","College/University","United Kingdom","6","2","C/C++;Java;Python","more than 10 years","more than 10 years","Image processing;Visualization","Research and development of application(s)","No, and I will not read it.","I read book(s).;I read articles found on Internet.","","MPICH;Open MPI;MVAPICH","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","One-sided communications;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes","I do not know or I do not care.","Too complicated and hard to understand.","Sometimes","No, my program is too small to do that.","No","I think there is room but I do not know how to tune it.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","One-sided communication;Dynamic process creation","I prefer to have new API which is simpler and/or easier-to-use.","4"
"2019/04/01 9:09:52 AM AST","Governmental institute","Germany","5","5","C/C++;Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","I read most of it.","I read the MPI standard document.;I read book(s).;I read articles found on Internet.","Using MPI","MPICH;Open MPI;MVAPICH;Intel MPI;Cray MPI;NEC MPI","I was said to use it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).","Implementation issue workaround","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED;MPI_THREAD_SERIALIZED;MPI_THREAD_MULTIPLE","","Always","Yes, to minimize the changes of communication API.","OpenMP","Yes, I know there is room for tuning but re-writing the applications for performance must be balanced with other considerations.","I am not investigating any alternatives.","Latency","","Dynamic process creation","Yes, compatibility is very important for me.","1"
"2019/04/01 9:10:35 AM AST","College/University","Austria","6","5","C/C++;Fortran 90 or newer;Python;C#","more than 10 years","between 2 and 5 years","Numerical application and/or library;Visualization","Research and development of application(s);Parallelization of sequential program(s)","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Using MPI","MPICH;Open MPI;Intel MPI","I was said to use it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","I do not know or I do not care.","I have no obstacles.","Always","Yes, to minimize the changes of communication API.","OpenMP;OpenACC","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A framework or library using MPI.;A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Resilience (fault tolerance);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","There are no unnecessary features","I prefer to have new API for better performance.","5"
"2019/04/01 9:11:02 AM AST","College/University","United States","5","2","C/C++","between 5 and 10 years","less than 2 years","Numerical application and/or library","Research and development of application(s);Parallelization of sequential program(s)","I read only the chapters of interest for my work.","I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","Parallel Programming with MPI","Open MPI","I have no special reason.","I read the MPI Standard document (web/book).;I search the Internet (Google / Stack Overflow).","Debugging","PMPI interface","MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","I do not know or I do not care.","I do not like the API.","Mostly","Yes, to minimize the changes of communication API.","OpenMP","I do not have (know) tools to find performance bottlenecks.","Hpx","Multi-threading support","MPI is providing all the communication semantics required by my application","There are no unnecessary features","I prefer to have new API for better performance.","5"
"2019/04/01 9:12:25 AM AST","College/University","Austria","6","2","C/C++;Ruby","more than 10 years","less than 2 years","System software development (OS, runtime library, communication library, etc.);Numerical application and/or library","Research and development of application(s);Research and development on system software (OS and/or runtime library);Research and development software tool(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).","MPI: The Complete Reference","Open MPI","I have no special reason.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes","MPI_THREAD_MULTIPLE","Too many routines.;I have nobody to ask.","Always","Yes, to minimize the changes of communication API.","No","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.","MPI provides all semantics I need","","Process topologies","I prefer to have new API for better performance.","5"
"2019/04/01 9:12:43 AM AST","College/University","Ukraine","3","2","C/C++;Python;Go","more than 10 years","between 2 and 5 years","Parallel language (incl. domain specific language);Numerical application and/or library","Parallelization of sequential program(s)","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","I have never read any MPI books","MPICH;MVAPICH","I have no special reason.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","One-sided communications;Dynamic process creation;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes","I have never called MPI_INIT_THREAD","I have no obstacles.","Mostly","No, my program is too small to do that.","No","I do not know how to find bottlenecks.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","Communicator and group management","I prefer to have new API for better performance.","4"
"2019/04/01 9:12:52 AM AST","Governmental institute","Germany","5","4","C/C++;Fortran 90 or newer","between 5 and 10 years","between 2 and 5 years","Numerical application and/or library","Parallelization of sequential program(s)","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).","Using MPI","Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).;I read online documents (such as man pages).","Debugging","Dynamic process creation;Persistent communication;PMPI interface","Collective communications;Communicator operations (split, duplicate, and so on)","I have never called MPI_INIT_THREAD","No appropriate lecture / book / info.","I rely on the default ‘Errors abort’ error handling","No, MPI calls are scattered in my programs.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Bandwidth","Resilience (fault tolerance)","There are no unnecessary features","API should be clearly versioned.","4"
"2019/04/01 9:14:25 AM AST","Governmental institute","Germany","4","5","C/C++;Fortran 90 or newer;Python","more than 10 years","between 5 and 10 years","System software development (OS, runtime library, communication library, etc.)","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).;I had lecture(s) at school.","Using MPI;Parallel Programming in C with MPI and OpenMP","MPICH;Open MPI;MVAPICH;Intel MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).","Algorithm design","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);One-sided communications","I have never called MPI_INIT_THREAD","Too many routines.;Too complicated and hard to understand.","I rely on the default ‘Errors abort’ error handling","No, MPI calls are scattered in my programs.","OpenMP","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","I am not investigating any alternatives.","MPI provides all semantics I need","","Dynamic process creation","API should be clearly versioned.","2"
"2019/04/01 9:14:40 AM AST","College/University","Germany","5","5","C/C++;Python","more than 10 years","between 5 and 10 years","Parallel language (incl. domain specific language);Visualization","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","I read articles found on Internet.","","Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","","Point-to-point communications;Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","I have nobody to ask.","Never","No, MPI calls are scattered in my programs.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","","","","","4"
"2019/04/01 9:15:30 AM AST","College/University","Germany","5","3","Fortran 90 or newer","between 5 and 10 years","between 2 and 5 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).","I have never read any MPI books","Open MPI","I was said to use it.","I read the MPI Standard document (web/book).;I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation;Persistent communication;PMPI interface","Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes","I have never called MPI_INIT_THREAD","I have no obstacles.","","Yes, to minimize the changes of communication API.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","MPI is providing all the communication semantics required by my application","There are no unnecessary features","Yes, compatibility is very important for me.","2"
"2019/04/01 9:16:13 AM AST","College/University","United Kingdom","4","2","C/C++;Python","between 5 and 10 years","less than 2 years","Numerical application and/or library;AI (Deep Learning);Big data","Research and development of application(s)","No, and I will not read it.","Other lectures or tutorials (workplace, conference).","I have never read any MPI books","MPICH;Open MPI","I have no special reason.","I search the Internet (Google / Stack Overflow).","Domain decomposition","One-sided communications;Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on)","I have never called MPI_INIT_THREAD;I do not know or I do not care.","Too many routines.;I have nobody to ask.","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","No","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.","I don't know.","Another API which is easier and/or simpler to use","There are no unnecessary features","I prefer to have new API which is simpler and/or easier-to-use.","2"
"2019/04/01 9:16:24 AM AST","Governmental institute","France","4","5","C/C++;Fortran 90 or newer;Python","more than 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s);Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).","I have never read any MPI books","MPICH;Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Performance tuning","PMPI interface","Point-to-point communications;Collective communications;MPI datatypes","","No appropriate lecture / book / info.","Mostly","Yes, to minimize the changes of communication API.","OpenCL","Yes there remains room but the code will became too complex.","","Latency","Latency hiding (including asynchronous completion);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","There are no unnecessary features","I prefer to have new API for better performance.","4"
"2019/04/01 9:17:31 AM AST","Other","Italy","5","6","C/C++;Fortran 90 or newer;Python","between 5 and 10 years","between 2 and 5 years","Numerical application and/or library","Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","I had lecture(s) at school.","","Open MPI;Intel MPI;Cray MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);One-sided communications","I have never called MPI_INIT_THREAD","Too many routines.;No appropriate lecture / book / info.","","Yes, to minimize the changes of communication API.","OpenMP;CUDA","yes, to tune programs is my job","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Resilience (fault tolerance)","There are no unnecessary features","Yes, compatibility is very important for me.","3"
"2019/04/01 9:18:09 AM AST","Governmental institute","Germany","5","5","C/C++;Fortran 90 or newer;Python","more than 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).;Other lectures or tutorials (workplace, conference).","Parallel Programming in C with MPI and OpenMP","Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Algorithm design","PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE","","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","OpenMP;CUDA","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A framework or library using MPI.","Multi-threading support","Latency hiding (including asynchronous completion);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","Dynamic process creation","Yes, compatibility is very important for me.","4"
"2019/04/01 9:18:14 AM AST","Governmental institute","Switzerland","4","4","Python","more than 10 years","between 5 and 10 years","Numerical application and/or library;Image processing","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","No, and I will not read it.","I read book(s).;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Parallel Programming (Rauber, Rünger)","MPICH;Open MPI","I was said to use it.","I search the Internet (Google / Stack Overflow).","Debugging","One-sided communications;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes","I have never called MPI_INIT_THREAD","I have no obstacles.","Never","Yes, to minimize the changes of communication API.","OpenMP","No, my MPI programs are well-tuned.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","One-sided communication;Process topologies;Dynamic process creation;Error handlers","Yes, compatibility is very important for me.","2"
"2019/04/01 9:18:17 AM AST","College/University","Germany","5","4","C/C++;Python","more than 10 years","more than 10 years","Numerical application and/or library;Tool development (performance tuning, debugging, etc.)","Research and development software tool(s);Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","I read articles found on Internet.;courses at various HPC centres","I have never read any MPI books","Open MPI;Cray MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Implementation issue workaround","Persistent communication","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_MULTIPLE","Too many routines.;Too complicated and hard to understand.;I do not like the API.","Sometimes","Yes, to minimize the changes of communication API.","OpenMP;Pthread","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.;A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Multi-threading support","Latency hiding (including asynchronous completion)","Dynamic process creation","API should be clearly versioned.","4"
"2019/04/01 9:19:04 AM AST","Governmental institute","Germany","5","5","C/C++;Fortran (older one than Fortran 90);Python","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Using MPI","MPICH;Intel MPI","I am familiar with it.","I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Debugging","Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications","I have never called MPI_INIT_THREAD","Too many routines.","Sometimes","Yes, to minimize the changes of communication API.","No","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Latency","Resilience (fault tolerance);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","Communicator and group management;Process topologies","API should be clearly versioned.","3"
"2019/04/01 9:19:53 AM AST","College/University","Italy","6","4","Fortran 90 or newer;Python;Julia","more than 10 years","between 2 and 5 years","Numerical application and/or library","Research and development software tool(s)","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).","I have never read any MPI books","Open MPI","I like to use it.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;One-sided communications","I have never called MPI_INIT_THREAD","I have no obstacles.","Sometimes","No, my program is too small to do that.","No","I think there is room but I do not know how to tune it.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","Process topologies;Dynamic process creation","I prefer to have new API which is simpler and/or easier-to-use.","1"
"2019/04/01 9:20:39 AM AST","College/University","Spain","4","4","C/C++;Python","more than 10 years","more than 10 years","System software development (OS, runtime library, communication library, etc.);Numerical application and/or library;AI (Deep Learning);Tool development (performance tuning, debugging, etc.)","Research and development on system software (OS and/or runtime library);Performance tuning of MPI program(s)","I read most of it.","I read the MPI standard document.;I read book(s).;I read articles found on Internet.","Using MPI;Parallel Programming in C with MPI and OpenMP;MPI: The Complete Reference","MPICH;Open MPI;MVAPICH","","I read the MPI Standard document (web/book).;I search the Internet (Google / Stack Overflow).","Domain decomposition","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","I have no obstacles.","Sometimes","No, MPI calls are scattered in my programs.","OpenMP;CUDA","No, my MPI programs are well-tuned.","A framework or library using MPI.;I am not investigating any alternatives.","Multi-threading support","MPI is providing all the communication semantics required by my application","There are no unnecessary features","I prefer to have new API for better performance.","4"
"2019/04/01 9:21:32 AM AST","College/University","Germany","5","5","C/C++;Java","more than 10 years","more than 10 years","Tool development (performance tuning, debugging, etc.)","Research and development software tool(s);Parallelization of sequential program(s);Performance tuning of MPI program(s)","I read most of it.","I read book(s).;Other lectures or tutorials (workplace, conference).","Parallel Programming with MPI;Using MPI","MPICH;Open MPI;Intel MPI","I have no special reason.","I read the MPI Standard document (web/book).","Algorithm design","Persistent communication","Point-to-point communications;MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_MULTIPLE","Performance differences between implementations.","Mostly","No, MPI calls are scattered in my programs.","OpenMP;OpenCL","I have no chance to investigate.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Resilience (fault tolerance)","Dynamic process creation;Error handlers","API should be clearly versioned.","4"
"2019/04/01 9:22:24 AM AST","College/University","Germany","5","3","C/C++;Fortran 90 or newer;Python","more than 10 years","between 5 and 10 years","Numerical application and/or library;Image processing;Visualization","Research and development of application(s)","I read only the chapters of interest for my work.","I read book(s).;I read articles found on Internet.","Parallel Programming with MPI;Using MPI","MPICH;Open MPI;MVAPICH;Intel MPI;Cray MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Performance tuning","PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);Dynamic process creation","MPI_THREAD_MULTIPLE","No appropriate lecture / book / info.","Always","Yes, to minimize the changes of communication API.","OpenMP","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","I am not investigating any alternatives.","Bandwidth","Endpoints (multi-thread, sessions)","Process topologies","Yes, compatibility is very important for me.","3"
"2019/04/01 9:22:26 AM AST","College/University","Germany","5","4","C/C++;Fortran 90 or newer;Python","more than 10 years","between 5 and 10 years","Numerical application and/or library;Big data;Visualization","Research and development of application(s);Research and development software tool(s);Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","I have never read any MPI books","MPICH;Open MPI;MVAPICH;Intel MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).","Algorithm design","Dynamic process creation","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;Persistent communications;MPI with OpenMP (or multithread)","MPI_THREAD_MULTIPLE","I have no obstacles.","Never","No, MPI calls are scattered in my programs.","OpenMP;OpenACC","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.;I am not investigating any alternatives.","MPI provides all semantics I need","Latency hiding (including asynchronous completion)","Process topologies;Dynamic process creation;Error handlers","API should be clearly versioned.","3"
"2019/04/01 9:23:57 AM AST","College/University","Germany","4","3","Fortran 90 or newer;Python","between 2 and 5 years","between 2 and 5 years","Numerical application and/or library","Research and development of application(s);Research and development software tool(s);Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","I read only the chapters of interest for my work.","I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","I have never read any MPI books","Intel MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","I have no obstacles.","Never","No, MPI calls are scattered in my programs.","OpenMP","I think there is room but I do not know how to tune it.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","There are no unnecessary features","API should be clearly versioned.","3"
"2019/04/01 9:25:10 AM AST","College/University","United Kingdom","5","4","C/C++;Python","more than 10 years","more than 10 years","Numerical application and/or library","Research professor","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).","I have never read any MPI books","Open MPI;Intel MPI","I have no special reason.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;One-sided communications","I do not know or I do not care.","Need: I only use it when required for my work.","Always","No, my program is too small to do that.","No","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","MPI is providing all the communication semantics required by my application","There are no unnecessary features","API should be clearly versioned.","3"
"2019/04/01 9:25:41 AM AST","College/University","France","5","5","C/C++;Fortran 90 or newer","more than 10 years","more than 10 years","C.F.D.","Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).;Other lectures or tutorials (workplace, conference).","Using MPI;""Using advanced MPI (978-0-262-52763-7)  ""MPI: A Message Passing Interface Standart"", Version 3.1","MPICH;Open MPI;Intel MPI;IBM MPI (BG/Q, PE, Spectrum)","I like to use it.","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).;I search the Internet (Google / Stack Overflow).","Debugging","Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread);MPI/IO","MPI_THREAD_MULTIPLE","I have no obstacles.","Sometimes","Yes, to minimize the changes of communication API.","OpenMP;coupling applications implemented in various languages (C++, fortran, Python) with MPI","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","may be some control on the MPI overhead in massively parallel applications","Resilience (fault tolerance)","There are no unnecessary features","Yes, compatibility is very important for me.","3"
"2019/04/01 9:26:43 AM AST","College/University","United Kingdom","5","5","Fortran 90 or newer;Python","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","I have never read any MPI books","Open MPI;Intel MPI;Cray MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).","Algorithm design","Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","I know the subset of the standard required to achieve my goals.","I rely on the default ‘Errors abort’ error handling","No, MPI calls are scattered in my programs.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","A Domain Specific Language (DSL).","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","MPI is providing all the communication semantics required by my application","Dynamic process creation","API should be clearly versioned.","2"
"2019/04/01 9:26:58 AM AST","Governmental institute","Germany","4","2","Fortran (older one than Fortran 90);Fortran 90 or newer;Python","more than 10 years","more than 10 years","Numerical application and/or library;Tool development (performance tuning, debugging, etc.)","Research and development of application(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).;MPI course at HLRS","","MPICH;Open MPI;Intel MPI;NEC MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).","Debugging","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","I have no obstacles.","Always","YES, to switch between SEQUENTIAL und MPI","OpenMP","I think there is room but I do not know how to tune it.","I am not investigating any alternatives.","Bandwidth","MPI is providing all the communication semantics required by my application","I use only a small part of the MPI features","API should be clearly versioned.","2"
"2019/04/01 9:27:50 AM AST","College/University","Germany","6","4","C/C++;Python","more than 10 years","between 2 and 5 years","Numerical application and/or library","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s)","","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).","I have never read any MPI books","Open MPI;Intel MPI;MS MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Performance tuning","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes","MPI_THREAD_SINGLE","lack of performance guidelines","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","No","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Latency","Latency hiding (including asynchronous completion)","One-sided communication;Dynamic process creation","compatibility is important, but should be sacrificed if necessary to implement important changes, e.g. to support 64-bit ints for message lengths","3"
"2019/04/01 9:28:06 AM AST","Governmental institute","Germany","5","4","C/C++;Python","more than 10 years","more than 10 years","Numerical application and/or library;Tool development (performance tuning, debugging, etc.)","Research and development of application(s)","I read only the chapters of interest for my work.","I read book(s).;I had lecture(s) at school.","Using MPI","Open MPI;Cray MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).","Algorithm design","Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","I have no obstacles.","Mostly","Yes, to minimize the changes of communication API.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","One-sided communication","Yes, compatibility is very important for me.","3"
"2019/04/01 9:29:25 AM AST","College/University","Finland","5","5","C/C++;Fortran 90 or newer;Python","more than 10 years","more than 10 years","Numerical application and/or library;Tool development (performance tuning, debugging, etc.)","Research and development of application(s);Parallelization of sequential program(s);Debugging MPI programs","I read only the chapters of interest for my work.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).","Using MPI","MPICH;Open MPI;MVAPICH;Intel MPI","I am familiar with it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","Dynamic process creation","Collective communications;MPI datatypes;MPI with OpenMP (or multithread);PMPI interface","I have never called MPI_INIT_THREAD","I have no obstacles.","Sometimes","No, MPI calls are scattered in my programs.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Resilience (fault tolerance);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","There are no unnecessary features","Yes, compatibility is very important for me.","3"
"2019/04/01 9:30:43 AM AST","College/University","Germany","5","5","Fortran 90 or newer;Python","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Parallel Programming with MPI","MPICH;Open MPI;Intel MPI;Cray MPI;NEC MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).","Debugging","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;Persistent communications;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","Partially encapsulated to allow for changes of communication patterns, but otherwise MPI calls scattered throughout the application (only few calls, though).","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","MPI is providing all the communication semantics required by my application","There are no unnecessary features","Yes, compatibility is very important for me.","4"
"2019/04/01 9:31:18 AM AST","College/University","Germany","5","4","C/C++;Fortran (older one than Fortran 90);Python","between 5 and 10 years","less than 2 years","Numerical application and/or library","Research and development software tool(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).","","Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Performance tuning","PMPI interface","Point-to-point communications;Collective communications","","I have no obstacles.","Never","No, MPI calls are scattered in my programs.","No","Yes, I know there is room for tuning but I do not have enough resources to do that.","","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","There are no unnecessary features","I prefer to have new API for better performance.","3"
"2019/04/01 9:32:42 AM AST","Governmental institute","Germany","6","4","Fortran (older one than Fortran 90);Fortran 90 or newer;Perl5 IDL","more than 10 years","more than 10 years","Numerical application and/or library;Big data;Visualization","Research and development of application(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I read articles found on Internet.","","MPICH;Open MPI;Intel MPI;Cray MPI;Sun MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Performance tuning","One-sided communications;Persistent communication;PMPI interface","Collective communications;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","Too many routines.;I do not like the API.","Always","Yes, to minimize the changes of communication API.","OpenMP;Pthread","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Latency","Another API which is easier and/or simpler to use","Communicator and group management","Yes, compatibility is very important for me.","2"
"2019/04/01 9:33:25 AM AST","Governmental institute","France","4","4","Fortran 90 or newer","between 2 and 5 years","between 2 and 5 years","Numerical application and/or library;Tool development (performance tuning, debugging, etc.)","Research and development of application(s);Parallelization of sequential program(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","Using MPI","Open MPI;Intel MPI","I am familiar with it.","I read the MPI Standard document (web/book).","Algorithm design","PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);One-sided communications","I have never called MPI_INIT_THREAD","I have no obstacles.","Sometimes","Yes, to minimize the changes of communication API.","No","I have no chance to investigate.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","Datatypes;Dynamic process creation","Yes, compatibility is very important for me.","1"
"2019/04/01 9:33:44 AM AST","Other","Italy","3","4","C/C++;Fortran 90 or newer","between 5 and 10 years","between 5 and 10 years","Parallel language (incl. domain specific language);Tool development (performance tuning, debugging, etc.)","HPC User Support","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).","I have never read any MPI books","Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","Persistent communication","Point-to-point communications;Collective communications","MPI_THREAD_FUNNELED","I have no obstacles.","Sometimes","No, my program is too small to do that.","No","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Multi-threading support","Resilience (fault tolerance);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","One-sided communication;Dynamic process creation","Yes, compatibility is very important for me.","4"
"2019/04/01 9:33:45 AM AST","College/University","Serbia","6","5","C/C++;Java","more than 10 years","between 2 and 5 years","Parallel language (incl. domain specific language);Numerical application and/or library","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s)","I read most of it.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","MPICH;Open MPI","I like to use it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Performance tuning","PMPI interface","Collective communications;MPI datatypes;One-sided communications","","","Sometimes","No, MPI calls are scattered in my programs.","No","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","","","I prefer to have new API for better performance.","4"
"2019/04/01 9:34:02 AM AST","College/University","Germany","5","2","Fortran 90 or newer","between 2 and 5 years","less than 2 years","Numerical application and/or library","Research and development software tool(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).;Other lectures or tutorials (workplace, conference).","Using MPI","Open MPI;Intel MPI;Cray MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Debugging","PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;Persistent communications;MPI with OpenMP (or multithread)","I do not know or I do not care.","I have nobody to ask.","Sometimes","Yes, to minimize the changes of communication API.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Bandwidth","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","There are no unnecessary features","I do not know or I do not care.","4"
"2019/04/01 9:39:45 AM AST","College/University","Netherlands","5","5","Fortran (older one than Fortran 90);Fortran 90 or newer;Python","more than 10 years","between 2 and 5 years","Numerical application and/or library;Visualization","Research and development of application(s)","I have not read it, but I plan to.","I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","Open MPI;Intel MPI","I am familiar with it.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on)","","Too many routines.","Never","No, MPI calls are scattered in my programs.","OpenMP;OpenACC","I do not have (know) tools to find performance bottlenecks.","I am not investigating any alternatives.","Bandwidth","","","I prefer to have new API for better performance.","5"
"2019/04/01 9:40:01 AM AST","College/University","Austria","5","4","C/C++;Fortran 90 or newer;Python","between 5 and 10 years","between 2 and 5 years","Numerical application and/or library;Image processing;Visualization","Research and development of application(s);Debugging MPI programs","I read only the chapters of interest for my work.","I read the MPI standard document.;I had lecture(s) at school.;I read articles found on Internet.","I have never read any MPI books","MPICH;Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","I do not know or I do not care.","I have no obstacles.","Mostly","Yes, to minimize the changes of communication API.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.;I am not investigating any alternatives.","MPI provides all semantics I need","Another API which is easier and/or simpler to use","","Yes, compatibility is very important for me.","1"
"2019/04/01 9:40:26 AM AST","College/University","Germany","4","3","Fortran 90 or newer;Python","between 2 and 5 years","less than 2 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).","I have never read any MPI books","Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).","Algorithm design","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","I have no obstacles.;but it needs a lot of time to exercise ","Sometimes","No, my program is too small to do that.","No","Yes, but first the algorithm has to work!","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","","I do not know or I do not care.","3"
"2019/04/01 9:40:30 AM AST","Governmental institute","Germany","5","3","C/C++;Python","more than 10 years","less than 2 years","Numerical application and/or library","Research and development software tool(s)","I read only the chapters of interest for my work.","I had lecture(s) at school.","","MPICH;Open MPI;Intel MPI","I was said to use it.","I search the Internet (Google / Stack Overflow).","Performance tuning","Communicator operations (split, duplicate, and so on);Dynamic process creation;Persistent communication","Point-to-point communications;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_SERIALIZED","Too many routines.","Always","Yes, to minimize the changes of communication API.","No","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","There are no unnecessary features","I prefer to have new API which is simpler and/or easier-to-use.","3"
"2019/04/01 9:40:41 AM AST","College/University","Italy","4","2","Python","between 2 and 5 years","less than 2 years","Parallel language (incl. domain specific language)","Research and development of application(s)","I have not read it, but I plan to.","Other lectures or tutorials (workplace, conference).","I have never read any MPI books","Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I ask colleagues.;I search the Internet (Google / Stack Overflow).","Algorithm design","Point-to-point communications;Collective communications;MPI with OpenMP (or multithread)","MPI with OpenMP (or multithread)","I do not know or I do not care.","Too many routines.;Too complicated and hard to understand.","Sometimes","","OpenMP","I do not know if there is room for performance tuning.","","","","","","3"
"2019/04/01 9:42:29 AM AST","Other","France","5","5","C/C++;Fortran 90 or newer;Python","between 5 and 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s);Performance tuning of MPI program(s);Debugging MPI programs","I have not read it, but I plan to.","I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","I have never read any MPI books","MPICH;Open MPI;Intel MPI;Platform","I am familiar with it.","I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Domain decomposition","PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","Too many routines.","Always","Yes, but I have no special reason for doing that.","OpenMP","I think there is room but I do not know how to tune it.","I am not investigating any alternatives.","Multi-threading support","Another API which is easier and/or simpler to use","Process topologies;Dynamic process creation","Yes, compatibility is very important for me.","3"
"2019/04/01 9:43:51 AM AST","College/University","Netherlands","5","5","C/C++","more than 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I read book(s).;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Parallel Programming in C with MPI and OpenMP","MPICH;Open MPI;Intel MPI;IBM MPI (BG/Q, PE, Spectrum)","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Implementation issue workaround","Persistent communication","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread);PMPI interface","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","No appropriate lecture / book / info.;I have nobody to ask.","Mostly","Yes, but I have no special reason for doing that.","Pthread","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Latency hiding (including asynchronous completion);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","Dynamic process creation","API should be clearly versioned.","3"
"2019/04/01 9:47:21 AM AST","College/University","Brazil","3","1","C/C++","between 5 and 10 years","between 2 and 5 years","Numerical application and/or library","Research and development of application(s)","I have not read it, but I plan to.","Other lectures or tutorials (workplace, conference).","I have never read any MPI books","MPICH;Intel MPI","I could not have any choice (the one provided by a vendor).","I search the Internet (Google / Stack Overflow).","Debugging","One-sided communications;PMPI interface","Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","I do not know or I do not care.","I do not like the API.","Mostly","Yes, to minimize the changes of communication API.","OpenMP","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A framework or library using MPI.","Multi-threading support","Another API which is easier and/or simpler to use","There are no unnecessary features","I prefer to have new API which is simpler and/or easier-to-use.","3"
"2019/04/01 9:53:10 AM AST","College/University","Germany","4","4","Fortran 90 or newer;Python","more than 10 years","between 5 and 10 years","Parallel language (incl. domain specific language);Numerical application and/or library;Image processing;Visualization","Research and development software tool(s);Parallelization of sequential program(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).;Other lectures or tutorials (workplace, conference).","MPI: The Complete Reference","Open MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;compiler warnings","Debugging","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes","I have never called MPI_INIT_THREAD;I do not know or I do not care.","confusion between specification of MPI datatypes and standard Fortran types (e.g. the size of MPI Offset kind)","Sometimes","No, but i would like to implement it if i had more time for code improvement","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","There are no unnecessary features","Yes, compatibility is very important for me.","4"
"2019/04/01 9:53:49 AM AST","College/University","Germany","6","4","C/C++;Python;bash, awk, rust","more than 10 years","between 2 and 5 years","Numerical application and/or library","Research and development of application(s);Research and development software tool(s)","I read only the chapters of interest for my work.","I read articles found on Internet.","Using MPI","MPICH;Open MPI;Cray MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Implementation issue workaround","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread);MPI-IO, plan to use shared memory window for hybrid parallelization","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED;MPI_THREAD_MULTIPLE","I have no obstacles.;time","Sometimes","No, MPI calls are scattered in my programs.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Latency for collective ops and bandwidth for point-to-point heavy codes.","Resilience (fault tolerance)","Dynamic process creation","I prefer to have new API for better performance.","4"
"2019/04/01 9:55:51 AM AST","Governmental institute","Germany","5","5","C/C++;Fortran 90 or newer","between 5 and 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s)","I read most of it.","I read the MPI standard document.;I read book(s).;I had lecture(s) at school.;I read articles found on Internet.","Parallel Programming with MPI","MPICH;Open MPI;Intel MPI;Cray MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","Dynamic process creation","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE","","I rely on the default ‘Errors abort’ error handling","No, MPI calls are scattered in my programs.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","Error handlers","Yes, compatibility is very important for me.","3"
"2019/04/01 9:56:56 AM AST","Governmental institute","Germany","4","3","Fortran 90 or newer;Python","more than 10 years","between 2 and 5 years","data analysis from CFD","R&D of CFD","I read only the chapters of interest for my work.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","MPICH;Open MPI;MVAPICH","I have no special reason.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Other","One-sided communications;Dynamic process creation;Persistent communication;PMPI interface","Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes","I do not know or I do not care.","I have no obstacles.;Time limitations","Sometimes","I'm mainly adapting existing code","No","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","","","","Would be nice, but sometimes one has to move forward.","2"
"2019/04/01 9:59:35 AM AST","Governmental institute","Italy","5","5","Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s)","No, and I will not read it.","I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","MPICH;Open MPI;MVAPICH;Intel MPI;Cray MPI;IBM MPI (BG/Q, PE, Spectrum)","I have no special reason.","I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Algorithm design","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes","MPI_THREAD_SINGLE","Too many routines.","Always","Yes, to minimize the changes of communication API.","OpenMP;CUDA","No, my MPI programs are well-tuned.","I am not investigating any alternatives.","MPI provides all semantics I need","Resilience (fault tolerance);MPI is providing all the communication semantics required by my application","Process topologies","API should be clearly versioned.","4"
"2019/04/01 9:59:50 AM AST","College/University","Germany","5","5","C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer","more than 10 years","between 5 and 10 years","Parallel language (incl. domain specific language);Numerical application and/or library;Workflow and/or In-situ;Tool development (performance tuning, debugging, etc.)","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","I read most of it.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Standars","Open MPI;MVAPICH;Intel MPI;Cray MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Domain decomposition","Dynamic process creation;Persistent communication","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications","MPI_THREAD_FUNNELED","I have no obstacles.","Mostly","No, MPI calls are scattered in my programs.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.;A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Latency","Resilience (fault tolerance);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","There are no unnecessary features","Yes, compatibility is very important for me.","4"
"2019/04/01 10:00:05 AM AST","Governmental institute","Italy","4","2","C/C++;Fortran 90 or newer","more than 10 years","less than 2 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).","MPI: The Complete Reference","Open MPI;Intel MPI","I am familiar with it.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation;Persistent communication","Collective communications;Communicator operations (split, duplicate, and so on)","MPI_THREAD_FUNNELED","Not enough time","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","No","I think there is room but I do not know how to tune it.","I rely on the work of master expert developers","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","There are no unnecessary features","API should be clearly versioned.","5"
"2019/04/01 10:03:56 AM AST","Software vendor","Germany","5","3","C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer","more than 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","I read only the chapters of interest for my work.","I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","Using MPI","MPICH;Open MPI;Intel MPI;MS MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","I do not know or I do not care.","No appropriate lecture / book / info.;Too complicated and hard to understand.","Mostly","Yes, to minimize the changes of communication API.","OpenMP","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","I am not investigating any alternatives.","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Latency hiding (including asynchronous completion);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","Dynamic process creation","I prefer to have new API for better performance.","4"
"2019/04/01 10:04:50 AM AST","Software vendor","Germany","6","5","C/C++;Python","more than 10 years","more than 10 years","Numerical application and/or library;Big data;Cloud","Research and development software tool(s)","I read most of it.","I read the MPI standard document.;I read book(s).;Other lectures or tutorials (workplace, conference).","Using MPI;MPI: The Complete Reference","Intel MPI;MS MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).;I read online documents (such as man pages).;I know almost all MPI routines.","Algorithm design","Persistent communication","Point-to-point communications;Collective communications;MPI datatypes;PMPI interface","MPI_THREAD_FUNNELED","I have no obstacles.","Always","Yes, to minimize the changes of communication API.","OpenMP;Pthread","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Resilience (fault tolerance);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.);Another API which is easier and/or simpler to use","There are no unnecessary features","Yes, compatibility is very important for me.","2"
"2019/04/01 10:10:01 AM AST","College/University","Sweden","6","4","C/C++;Fortran 90 or newer;Python","between 5 and 10 years","","System software development (OS, runtime library, communication library, etc.);Numerical application and/or library;Visualization","Research and development on system software (OS and/or runtime library);Research and development software tool(s)","","I read book(s).;Other lectures or tutorials (workplace, conference).","Using MPI;MPI: The Complete Reference","Open MPI;Intel MPI","I am familiar with it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Debugging","Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;One-sided communications","I have never called MPI_INIT_THREAD","Too complicated and hard to understand.;Light-weight simplified interface. Perhaps OO C++ wrapper.","Sometimes","Yes, to minimize the changes of communication API.","No","I think there is room but I do not know how to tune it.","A framework or library using MPI.;A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).;A Domain Specific Language (DSL).","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","Process topologies","I prefer to have new API which is simpler and/or easier-to-use.","3"
"2019/04/01 10:15:28 AM AST","College/University","Germany","6","3","C/C++;Python","more than 10 years","between 2 and 5 years","Numerical application and/or library;Big data","Research and development of application(s);Research and development software tool(s);Parallelization of sequential program(s)","I read only the chapters of interest for my work.","I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","Open MPI;Intel MPI","I have no special reason.","I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Algorithm design","PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_MULTIPLE","I have no obstacles.","Always","No, my program is too small to do that.","OpenMP;Pthread","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Latency hiding (including asynchronous completion)","Communicator and group management","Yes, compatibility is very important for me.","4"
"2019/04/01 10:17:30 AM AST","Governmental institute","Germany","5","3","C/C++;Python","between 5 and 10 years","between 5 and 10 years","Numerical application and/or library;Tool development (performance tuning, debugging, etc.)","Research and development of application(s);Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","colleagues","I have never read any MPI books","Open MPI;Intel MPI","I was said to use it.","I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Debugging","Communicator operations (split, duplicate, and so on);Dynamic process creation;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED","Too complicated and hard to understand.","Mostly","Yes, to minimize the changes of communication API.","OpenMP;Pthread","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","","","There are no unnecessary features","API should be clearly versioned.","4"
"2019/04/01 10:19:05 AM AST","College/University","Germany","6","5","C/C++;Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s);Performance tuning of MPI program(s);Debugging MPI programs","I read all.","I read the MPI standard document.;I read articles found on Internet.","I have never read any MPI books","Open MPI;Cray MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Persistent communication","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","I have no obstacles.","Sometimes","No, MPI calls are scattered in my programs.","OpenMP;Pthread","No, my MPI programs are well-tuned.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","Datatypes;Process topologies;Dynamic process creation","Yes, compatibility is very important for me.","5"
"2019/04/01 10:19:13 AM AST","College/University","Germany","5","2","C/C++;Python","more than 10 years","between 2 and 5 years","Numerical application and/or library","Parallelization of sequential program(s);Academic Research","I read only the chapters of interest for my work.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.;I have not learned MPI.","I have never read any MPI books","Open MPI;Intel MPI","I have no special reason.","I read the MPI Standard document (web/book).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Finding appropriate MPI routines","Dynamic process creation;PMPI interface","Point-to-point communications;Collective communications;MPI with OpenMP (or multithread)","I do not know or I do not care.","","Sometimes","No, MPI calls are scattered in my programs.","OpenMP","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A framework or library using MPI.","MPI provides all semantics I need","","","I prefer to have new API for better performance.","5"
"2019/04/01 10:25:10 AM AST","Governmental institute","Germany","5","4","Fortran 90 or newer;Python","between 5 and 10 years","between 2 and 5 years","Numerical application and/or library;Visualization","Research and development of application(s)","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","I have never read any MPI books","MPICH;Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Debugging","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","Too complicated and hard to understand.","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.","Latency","Another API which is easier and/or simpler to use","Dynamic process creation","I prefer to have new API which is simpler and/or easier-to-use.","4"
"2019/04/01 10:25:34 AM AST","College/University","Italy","5","3","Fortran 90 or newer;Python","more than 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I read the MPI standard document.","Parallel Programming with MPI","MPICH;Open MPI","I have no special reason.","I search the Internet (Google / Stack Overflow).","Algorithm design","PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on)","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","No appropriate lecture / book / info.","Mostly","Yes, to minimize the changes of communication API.","No","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A Domain Specific Language (DSL).","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","MPI is providing all the communication semantics required by my application","There are no unnecessary features","Yes, compatibility is very important for me.","4"
"2019/04/01 10:27:49 AM AST","College/University","Spain","4","2","Fortran 90 or newer;Python","between 2 and 5 years","less than 2 years","Workflow and/or In-situ","Research and development software tool(s)","I read only the chapters of interest for my work.","lecture in High Performance Computing Center (HLRS)","Using MPI","Open MPI","I like to use it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Domain decomposition","PMPI interface","MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE","I have nobody to ask.","Sometimes","Yes, to minimize the changes of communication API.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","There are no unnecessary features","I do not know or I do not care.","3"
"2019/04/01 10:29:30 AM AST","College/University","Germany","5","4","C/C++","between 5 and 10 years","between 2 and 5 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I had lecture(s) at school.","I have never read any MPI books","MPICH;Intel MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Implementation issue workaround","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","Point-to-point communications;Collective communications;MPI datatypes","I do not know or I do not care.","No exception handling -> Inconsisten states","Sometimes","Yes, to minimize the changes of communication API.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Exception handling","Another API which is easier and/or simpler to use;Exception handling","Process topologies;Dynamic process creation","I prefer to have new API which is simpler and/or easier-to-use.","3"
"2019/04/01 10:31:18 AM AST","College/University","Germany","6","3","C/C++;Python","more than 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s);Research and development software tool(s);Parallelization of sequential program(s);Performance tuning of MPI program(s)","No, and I will not read it.","Other lectures or tutorials (workplace, conference).","","Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).","Debugging","Persistent communication","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes","MPI_THREAD_MULTIPLE","Too complicated and hard to understand.;I do not like the API.","Always","Yes, but I have no special reason for doing that.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Another API which is easier and/or simpler to use","","I prefer to have new API which is simpler and/or easier-to-use.","1"
"2019/04/01 10:36:17 AM AST","College/University","United Kingdom","6","6","Fortran (older one than Fortran 90);Fortran 90 or newer;Python","more than 10 years","more than 10 years","claiClimate and Weather simulation (probably numerical application then)","Research and development of application(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).;Other lectures or tutorials (workplace, conference).","Using MPI;MPI: The Complete Reference","MPICH;Open MPI;MVAPICH;Intel MPI;Cray MPI","","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).;I read online documents (such as man pages).","Domain decomposition","Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_FUNNELED","Too many routines.","Sometimes","Yes, to minimize the changes of communication API.","OpenMP","I have no chance to investigate.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","Dynamic process creation","API should be clearly versioned.","3"
"2019/04/01 10:36:57 AM AST","College/University","United Kingdom","5","3","Fortran 90 or newer;Python","more than 10 years","between 5 and 10 years","Scientific research ","Research and development software tool(s);Performance tuning of MPI program(s);Debugging MPI programs","No, and I will not read it.","I read articles found on Internet.","I have never read any MPI books","Open MPI","I am familiar with it.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Domain decomposition","PMPI interface","Collective communications;Persistent communications","I have never called MPI_INIT_THREAD","I have nobody to ask.;Time ","I rely on the default ‘Errors abort’ error handling","No, MPI calls are scattered in my programs.","No","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","There are no unnecessary features","Yes, compatibility is very important for me.","4"
"2019/04/01 10:37:06 AM AST","Governmental institute","United Kingdom","5","3","C/C++;Fortran 90 or newer;Python","between 2 and 5 years","less than 2 years","Numerical application and/or library;Big data;Workflow and/or In-situ","Research and development of application(s);Parallelization of sequential program(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","I have never read any MPI books","MPICH;Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation;Persistent communication;PMPI interface","Collective communications;Communicator operations (split, duplicate, and so on)","I have never called MPI_INIT_THREAD","I have no obstacles.","Mostly","No, MPI calls are scattered in my programs.","No","I have no chance to investigate.","A framework or library using MPI.","Multi-threading support","MPI is providing all the communication semantics required by my application","There are no unnecessary features","API should be clearly versioned.","4"
"2019/04/01 10:38:21 AM AST","College/University","United Kingdom","5","3","C/C++;Fortran 90 or newer;Python","more than 10 years","between 5 and 10 years","Numerical application and/or library;Visualization","Research and development of application(s);Research and development software tool(s);Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","I have never read any MPI books","MPICH;Open MPI","I have no special reason.","I search the Internet (Google / Stack Overflow).","Algorithm design","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);One-sided communications;Dynamic process creation;Persistent communication;PMPI interface","MPI datatypes","I do not know or I do not care.","Too many routines.;Too complicated and hard to understand.;I do not like the API.","Never","No, MPI calls are scattered in my programs.","No","I think there is room but I do not know how to tune it.","I am not investigating any alternatives.","MPI provides all semantics I need","Another API which is easier and/or simpler to use","","API should be clearly versioned.","3"
"2019/04/01 10:39:52 AM AST","College/University","United Kingdom","5","3","C/C++;Python","more than 10 years","between 2 and 5 years","Numerical application and/or library;Big data;Workflow and/or In-situ;Visualization","Research and development software tool(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I read articles found on Internet.","I have never read any MPI books","MPICH;Open MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","PMPI interface","","I do not know or I do not care.","","Mostly","No, my program is too small to do that.","OpenMP;Pthread","Yes, I know there is room for tuning but I do not have enough resources to do that.","","Unsure","","","API should be clearly versioned.","3"
"2019/04/01 10:41:31 AM AST","College/University","United Kingdom","6","5","C/C++","more than 10 years","between 5 and 10 years","Numerical application and/or library;Visualization","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","I read only the chapters of interest for my work.","I read articles found on Internet.","","MPICH;Open MPI;MVAPICH;Intel MPI","I am familiar with it.","I read online documents (such as man pages).","Performance tuning","PMPI interface","Point-to-point communications;Collective communications;MPI datatypes","I have never called MPI_INIT_THREAD","I have no obstacles.","Sometimes","Yes, to minimize the changes of communication API.","OpenMP;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.;A Domain Specific Language (DSL).","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","Dynamic process creation","API should be clearly versioned.","3"
"2019/04/01 10:47:44 AM AST","College/University","United Kingdom","5","5","C/C++","between 5 and 10 years","between 2 and 5 years","Numerical application and/or library","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","I read only the chapters of interest for my work.","I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","I have never read any MPI books","Open MPI;MVAPICH;Intel MPI","I was said to use it.","I read online documents (such as man pages).","Debugging","One-sided communications;Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE","","Sometimes","Yes, to allow users to easily compile without MPI parallelism on certain platforms","OpenMP;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","","Multi-threading support","","Dynamic process creation","I do not know or I do not care.","4"
"2019/04/01 10:47:50 AM AST","College/University","Italy","4","3","C/C++","between 2 and 5 years","between 2 and 5 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).","I have never read any MPI books","Open MPI","I am familiar with it.","I read online documents (such as man pages).","Debugging","Point-to-point communications;Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","Point-to-point communications;Collective communications;MPI datatypes","I have never called MPI_INIT_THREAD","debug","Mostly","No, MPI calls are scattered in my programs.","No","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Latency","Latency hiding (including asynchronous completion)","There are no unnecessary features","I prefer to have new API which is simpler and/or easier-to-use.","3"
"2019/04/01 10:48:03 AM AST","College/University","United Kingdom","5","2","C/C++","between 5 and 10 years","less than 2 years","Numerical application and/or library","Scientist","No, and I will not read it.","I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","I have never read any MPI books","MPICH;Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Finding appropriate MPI routines","Communicator operations (split, duplicate, and so on);Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE","Theoretical problem does not map easily to distributed parallelism","Always","No, my program is too small to do that.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","There are no unnecessary features","API should be clearly versioned.","3"
"2019/04/01 10:48:29 AM AST","College/University","United Kingdom","5","4","Fortran 90 or newer;Python","between 5 and 10 years","between 2 and 5 years","Numerical application and/or library;Workflow and/or In-situ;Tool development (performance tuning, debugging, etc.)","Research and development of application(s);Research and development software tool(s);Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","I read only the chapters of interest for my work.","I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","MPICH;Open MPI;MVAPICH;Intel MPI;Cray MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","I have no obstacles.","Always","Yes, to minimize the changes of communication API.","OpenMP","I am actively working on it.","I am not investigating any alternatives.","Latency","MPI is providing all the communication semantics required by my application","There are no unnecessary features","Yes, compatibility is very important for me.","2"
"2019/04/01 10:49:40 AM AST","College/University","Austria","4","2","Python","more than 10 years","less than 2 years","Numerical application and/or library;Workflow and/or In-situ;Visualization","Research and development of application(s);Research and development software tool(s)","I read only the chapters of interest for my work.","I had lecture(s) at school.;I read articles found on Internet.","","Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Implementation issue workaround","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes","I have never called MPI_INIT_THREAD","","I rely on the default ‘Errors abort’ error handling","No, MPI calls are scattered in my programs.","No","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Bandwidth","","There are no unnecessary features","API should be clearly versioned.","5"
"2019/04/01 10:52:24 AM AST","College/University","Austria","5","5","C/C++;Fortran 90 or newer;Python","more than 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s)","I read most of it.","I read the MPI standard document.;I had lecture(s) at school.","I have never read any MPI books","MPICH;Open MPI;Intel MPI;NEC MPI","I am familiar with it.","I read the MPI Standard document (web/book).","Debugging","Persistent communication","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications","MPI_THREAD_SINGLE","I have no obstacles.","Always","No, MPI calls are scattered in my programs.","No","I have no chance to investigate.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).;Low-level communication layer provided by vendor (Verbs, DCMF, ...).","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Resilience (fault tolerance);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","There are no unnecessary features","API should be clearly versioned.","2"
"2019/04/01 10:59:29 AM AST","College/University","Australia","6","6","C/C++","","","System software development (OS, runtime library, communication library, etc.)","Performance tuning of MPI program(s)","","I read articles found on Internet.","Parallel Programming with MPI","Open MPI","I like to use it.","I read book(s) (except the MPI standard).","Other","Point-to-point communications","Collective communications","MPI_THREAD_MULTIPLE","Too complicated and hard to understand.","","Yes, to minimize the changes of communication API.","OpenCL","I have no chance to investigate.","I am not investigating any alternatives.","Latency","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","There are no unnecessary features","API should be clearly versioned.","4"
"2019/04/01 11:01:29 AM AST","College/University","Denmark, Austria","6","4","C/C++","between 5 and 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s);Performance tuning of MPI program(s);Debugging MPI programs","No, and I will not read it.","Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","I have never read any MPI books","Open MPI;Intel MPI","I am familiar with it.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread);cuda-aware mpi (although I think that is not standard is it?)","MPI_THREAD_FUNNELED","I have no obstacles.","Never","No, MPI calls are scattered in my programs.","OpenMP;CUDA","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","I am not investigating any alternatives.","Latency","MPI is providing all the communication semantics required by my application","One-sided communication;Dynamic process creation","I prefer to have new API which is simpler and/or easier-to-use.","1"
"2019/04/01 11:01:42 AM AST","Governmental institute","United Kingdom","5","4","Fortran 90 or newer","more than 10 years","between 2 and 5 years","Numerical application and/or library","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s)","I read most of it.","I read the MPI standard document.;I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Using Advanced MPI: Modern Features of the Message-Passing Interface ","MPICH;Cray MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Implementation issue workaround","PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_MULTIPLE","","Never","Mixed, some are abstracted some are direct MPI calls","OpenMP","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","OpenSHMEM only","Latency","Latency hiding (including asynchronous completion);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.);One sided with completation signal (see OpenSHMEM)","Dynamic process creation","Yes, compatibility is very important for me.","3"
"2019/04/01 11:05:47 AM AST","Software vendor","Italy","5","4","C/C++","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s)","No, and I will not read it.","I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","Open MPI;Intel MPI","I am familiar with it.","I read the MPI Standard document (web/book).","Debugging","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications","I have never called MPI_INIT_THREAD","I have no obstacles.","Sometimes","Yes, to minimize the changes of communication API.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.;A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).;A Domain Specific Language (DSL).","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","","","I prefer to have new API which is simpler and/or easier-to-use.","3"
"2019/04/01 11:08:53 AM AST","Governmental institute","United Kingdom","5","4","C/C++;Fortran 90 or newer;Python","more than 10 years","between 5 and 10 years","Parallel language (incl. domain specific language);Numerical application and/or library;Tool development (performance tuning, debugging, etc.)","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).;I read articles found on Internet.;Learned by doing mostly - worked on codes at the beginning of my PhD and just picked up the basics from there, with more advanced stuff being self taught","I have never read any MPI books","Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Performance tuning","Dynamic process creation;Persistent communication","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_MULTIPLE","I have nobody to ask.","Always","No, MPI calls are scattered in my programs.","OpenMP;Pthread;CUDA","I have no chance to investigate.","I am not investigating any alternatives.","Multi-threading support","Endpoints (multi-thread, sessions);Resilience (fault tolerance);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","Dynamic process creation","I do not know or I do not care.","4"
"2019/04/01 11:09:16 AM AST","College/University","Greece","6","6","C/C++;Python","more than 10 years","between 5 and 10 years","System software development (OS, runtime library, communication library, etc.);Numerical application and/or library","Research and development on system software (OS and/or runtime library);Research and development software tool(s);Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","I read most of it.","I read the MPI standard document.;I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","Using MPI;MPI: The Complete Reference","MPICH;Open MPI;Cray MPI","I have no special reason.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Performance tuning","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread);PMPI interface","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED;MPI_THREAD_MULTIPLE","I have no obstacles.","Sometimes","No, my program is too small to do that.","OpenMP;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Resilience (fault tolerance);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","Dynamic process creation","Yes, compatibility is very important for me.","3"
"2019/04/01 11:11:06 AM AST","Software vendor","United Kingdom","6","5","C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer;Java","more than 10 years","more than 10 years","Parallel language (incl. domain specific language);Numerical application and/or library","Research and development of application(s);Research and development software tool(s);Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","I read only the chapters of interest for my work.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","I have never read any MPI books","MPICH;Open MPI;MVAPICH;Intel MPI;Cray MPI;HPE MPI","I have no special reason.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Algorithm design","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;Dynamic process creation;Persistent communication;MPI with OpenMP (or multithread);PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED;MPI_THREAD_MULTIPLE","I have no obstacles.","Mostly","No, my program is too small to do that.","OpenMP;Pthread","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","","There are no unnecessary features","I prefer to have new API which is simpler and/or easier-to-use.","4"
"2019/04/01 11:16:00 AM AST","College/University","Sweden","3","3","C/C++","more than 10 years","more than 10 years","Workflow and/or In-situ;Tool development (performance tuning, debugging, etc.)","Performance tuning of MPI program(s);Debugging MPI programs","I read only the chapters of interest for my work.","I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Parallel Programming with MPI","Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Performance tuning","Dynamic process creation","Point-to-point communications;Collective communications;One-sided communications","MPI_THREAD_SINGLE","No appropriate lecture / book / info.","I rely on the default ‘Errors abort’ error handling","No, MPI calls are scattered in my programs.","OpenMP;OpenACC","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","Dynamic process creation","Yes, compatibility is very important for me.","3"
"2019/04/01 11:20:28 AM AST","Other","Denmark","6","5","C/C++;Java;Python;Rust","more than 10 years","between 5 and 10 years","Numerical application and/or library;Big data","Research and development of application(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","Parallel Programming with MPI","MPICH;Open MPI;MVAPICH;Intel MPI","I like to use it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).","Implementation issue workaround","PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;One-sided communications","MPI_THREAD_SERIALIZED;MPI_THREAD_MULTIPLE","Too many routines.;It would be nice with a standard library of data structures (e.g., hash table with granulated locking/compare-and-swap)","Mostly","No, my program is too small to do that.","OpenMP;Pthread","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Latency","MPI is providing all the communication semantics required by my application","Dynamic process creation","API should be clearly versioned.","5"
"2019/04/01 11:20:45 AM AST","Governmental institute","Germany","5","5","C/C++;Python","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s)","I read most of it.","I read the MPI standard document.;I read book(s).;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Parallel Programming with MPI;Using MPI","Open MPI;Intel MPI","I have no special reason.","I read the MPI Standard document (web/book).","Algorithm design","Dynamic process creation","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI with OpenMP (or multithread)","MPI_THREAD_SERIALIZED;MPI_THREAD_MULTIPLE","Too many routines.","Always","Yes, to minimize the changes of communication API.","OpenMP","No, my MPI programs are well-tuned.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Message injection rate","Latency hiding (including asynchronous completion);Endpoints (multi-thread, sessions)","There are no unnecessary features","I prefer to have new API for better performance.","3"
"2019/04/01 11:23:21 AM AST","College/University","United Kingdom","6","5","C/C++","more than 10 years","between 2 and 5 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","I have never read any MPI books","MPICH;Open MPI;Intel MPI","I was said to use it.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_MULTIPLE","Making sense of the errors that are reported. Often they are not clear about the exact cause, especially when resources are exhausted.","Always","No, MPI calls are scattered in my programs.","Pthread","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","MPI provides all semantics I need","Resilience (fault tolerance)","One-sided communication;Process topologies;Dynamic process creation","API should be clearly versioned.","5"
"2019/04/01 11:33:06 AM AST","College/University","United Kingdom","4","4","C/C++;Fortran 90 or newer;Perl","more than 10 years","between 5 and 10 years","Numerical application and/or library;Scientific software","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s)","I have not read it, but I plan to.","I had lecture(s) at school.;I read articles found on Internet.","I have never read any MPI books","MPICH;Open MPI;Intel MPI","I am familiar with it.","I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Domain decomposition","Communicator operations (split, duplicate, and so on);Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","I do not know or I do not care.","I do not like the API.","Mostly","Yes, to reduce API complexity","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).;A Domain Specific Language (DSL).","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","There are no unnecessary features","API should be clearly versioned.","4"
"2019/04/01 11:38:52 AM AST","College/University","United States","6","3","C/C++;Python;R, Javascript","more than 10 years","between 2 and 5 years","AI (Deep Learning);Big data;Workflow and/or In-situ","Research and development of application(s);Parallelization of sequential program(s)","No, and I will not read it.","I had lecture(s) at school.;I read articles found on Internet.","I have never read any MPI books","MPICH;Open MPI;Intel MPI;Cray MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Domain decomposition","Dynamic process creation;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes","I have never called MPI_INIT_THREAD","Not enough work requires it","Always","No, MPI calls are scattered in my programs.","OpenMP;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","Error handlers","I prefer to have new API for better performance.","5"
"2019/04/01 11:40:11 AM AST","Governmental institute","United Kingdom","5","4","Fortran 90 or newer;Python","more than 10 years","more than 10 years","Parallel language (incl. domain specific language)","Research and development software tool(s);Parallelization of sequential program(s);Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","Using MPI","Open MPI;Intel MPI;Cray MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Domain decomposition","PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes","I have never called MPI_INIT_THREAD","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","OpenMP;OpenACC","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.;A Domain Specific Language (DSL).","Multi-threading support","Endpoints (multi-thread, sessions)","Dynamic process creation","Yes, compatibility is very important for me.","3"
"2019/04/01 11:42:22 AM AST","College/University","Netherlands","4","1","Fortran 90 or newer;Python","between 5 and 10 years","less than 2 years","Numerical application and/or library","Research and development of application(s)","","I read book(s).;I read articles found on Internet.","Using MPI","MPICH;Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","Point-to-point communications;Communicator operations (split, duplicate, and so on);Dynamic process creation;Persistent communication;PMPI interface","Collective communications","I do not know or I do not care.","No appropriate lecture / book / info.;I have nobody to ask.","Always","No, my program is too small to do that.","No","most happens within PETSc, which is a well-tuned MPI library (I think)","A framework or library using MPI.","","","","API should be clearly versioned.","3"
"2019/04/01 11:43:18 AM AST","College/University","United Kingdom","5","5","C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer;Java","more than 10 years","more than 10 years","System software development (OS, runtime library, communication library, etc.);Numerical application and/or library;Tool development (performance tuning, debugging, etc.)","Research and development on system software (OS and/or runtime library);Research and development software tool(s);Parallelization of sequential program(s);Performance tuning of MPI program(s)","I read all.","I read the MPI standard document.;I read book(s).;I read articles found on Internet.","Parallel Programming with MPI;Using MPI;MPI: The Complete Reference","MPICH;Open MPI;MVAPICH","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).;I know almost all MPI routines.","Performance tuning","Persistent communication","Point-to-point communications;Collective communications;MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED;MPI_THREAD_SERIALIZED;MPI_THREAD_MULTIPLE","I have no obstacles.;Too many routines.","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","OpenMP;Pthread","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.;A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Multi-threading support","Latency hiding (including asynchronous completion);Endpoints (multi-thread, sessions);Resilience (fault tolerance);Another API which is easier and/or simpler to use","There are no unnecessary features","I prefer to have new API which is simpler and/or easier-to-use.","5"
"2019/04/01 11:51:08 AM AST","College/University","United States","6","5"," Julia","more than 10 years","between 5 and 10 years","System software development (OS, runtime library, communication library, etc.);Parallel language (incl. domain specific language);Numerical application and/or library;AI (Deep Learning);Tool development (performance tuning, debugging, etc.)","Research and development on system software (OS and/or runtime library);Research and development software tool(s)","I read only the chapters of interest for my work.","I read book(s).","Using MPI","Open MPI;IBM MPI (BG/Q, PE, Spectrum)","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","","Point-to-point communications;One-sided communications;PMPI interface","I have never called MPI_INIT_THREAD","Too many routines.;I do not like the API.","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","OpenMP;OpenCL;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.);Another API which is easier and/or simpler to use;Accelerator triggered communication","Collective operations","I prefer to have new API which is simpler and/or easier-to-use.","5"
"2019/04/01 11:52:07 AM AST","Software vendor","Austria","6","4","C/C++;Fortran 90 or newer","more than 10 years","between 2 and 5 years","Numerical application and/or library","Research and development of application(s)","I read most of it.","I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","Using MPI","Open MPI;Intel MPI;HPE MPI","I have no special reason.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","Dynamic process creation;Persistent communication","Point-to-point communications;Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE","Too many routines.;I do not like the API.","I rely on the default ‘Errors abort’ error handling","Yes, but the abstraction is so leaky, I couldn't replace the communication layer","OpenMP;CUDA","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","","MPI provides all semantics I need","Latency hiding (including asynchronous completion)","One-sided communication;Process topologies","API should be clearly versioned.","1"
"2019/04/01 11:53:16 AM AST","College/University","United Kingdom","6","5","C/C++","more than 10 years","between 5 and 10 years","Numerical application and/or library","Research and development software tool(s)","I read only the chapters of interest for my work.","I had lecture(s) at school.","","MPICH;Open MPI;Intel MPI;Cray MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).;MUST","Performance tuning","Persistent communication","Point-to-point communications;Collective communications;MPI datatypes;MPI with OpenMP (or multithread);PMPI interface","MPI_THREAD_MULTIPLE","Performance/application issues such as appropriate progression","Always","Yes, to minimize the changes of communication API.","OpenMP;OpenACC;TBB","I think there is room but I do not know how to tune it.","I am not investigating any alternatives.","Multi-threading support","Latency hiding (including asynchronous completion);Endpoints (multi-thread, sessions)","Communicator and group management;Dynamic process creation","I prefer to have new API which is simpler and/or easier-to-use.","4"
"2019/04/01 12:09:36 PM AST","College/University","Italy","5","5","Fortran (older one than Fortran 90);Fortran 90 or newer","between 2 and 5 years","between 2 and 5 years","Numerical application and/or library","","No, and I will not read it.","Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","I have never read any MPI books","MPICH;Open MPI;Intel MPI","I have no special reason.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread);PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes","I do not know or I do not care.","","Never","Yes, to minimize the changes of communication API.","No","No, my MPI programs are well-tuned.","I am not investigating any alternatives.","","","There are no unnecessary features","Yes, compatibility is very important for me.","4"
"2019/04/01 12:31:11 PM AST","College/University","Germany","5","4","C/C++","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","MPICH;Open MPI;MVAPICH;Intel MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).","Performance tuning","Dynamic process creation;Persistent communication","Point-to-point communications;Collective communications;MPI with OpenMP (or multithread)","I do not know or I do not care.","how to get optimal performance","Mostly","Yes, to minimize the changes of communication API.","OpenMP;Pthread;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.","Latency","Latency hiding (including asynchronous completion);Another API which is easier and/or simpler to use","Datatypes;Communicator and group management","Yes, compatibility is very important for me.","5"
"2019/04/01 12:39:52 PM AST","Private research institute","Spain","6","4","C/C++;Fortran 90 or newer","more than 10 years","between 2 and 5 years","Workflow and/or In-situ;Performance analysis","Research and development of application(s);Research and development software tool(s);Performance tuning of MPI program(s);Debugging MPI programs","I read only the chapters of interest for my work.","I read articles found on Internet.","I have never read any MPI books","Intel MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Implementation issue workaround","Dynamic process creation","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE","I have no obstacles.","Always","Yes, to minimize the changes of communication API.","OpenMP;OpenACC","Yes and we are working on that ","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Another API which is easier and/or simpler to use","Datatypes","I prefer to have new API which is simpler and/or easier-to-use.","3"
"2019/04/01 12:57:59 PM AST","College/University","Germany","4","3","Fortran (older one than Fortran 90);Fortran 90 or newer;Python","between 5 and 10 years","between 5 and 10 years","Numerical application and/or library;Big data","Research and development of application(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).","Using MPI","Open MPI","I was said to use it.","I read book(s) (except the MPI standard).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Domain decomposition","One-sided communications;Dynamic process creation;Persistent communication;MPI with OpenMP (or multithread);PMPI interface","Point-to-point communications;Collective communications","I do not know or I do not care.","I have no obstacles.","Sometimes","No, MPI calls are scattered in my programs.","No","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","There are no unnecessary features","Yes, compatibility is very important for me.","3"
"2019/04/01 1:17:02 PM AST","College/University","Germany","5","4","C/C++;Python","more than 10 years","more than 10 years","Parallel language (incl. domain specific language);Numerical application and/or library;Workflow and/or In-situ","Research and development of application(s);Research and development software tool(s);Performance tuning of MPI program(s)","I read most of it.","I read articles found on Internet.","","MPICH;Open MPI;Intel MPI;MS MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).","Debugging","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;PMPI interface","MPI_THREAD_MULTIPLE","I have no obstacles.","Mostly","Yes, to minimize the changes of communication API.","OpenMP;Pthread;OpenCL;CUDA","Yes, there is room, but the time consuming parts are already optimised","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).;A Domain Specific Language (DSL).","Multi-threading support","Latency hiding (including asynchronous completion);Endpoints (multi-thread, sessions);Resilience (fault tolerance)","One-sided communication","API should be clearly versioned.","4"
"2019/04/01 1:49:16 PM AST","Governmental institute","United Kingdom","6","4","C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s);Performance tuning of MPI program(s);Debugging MPI programs","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Using MPI","MPICH;Open MPI;MVAPICH;Cray MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_SERIALIZED;MPI_THREAD_MULTIPLE","I have no obstacles.","Mostly","Yes, to minimize the changes of communication API.","OpenMP;Pthread","No, my MPI programs are well-tuned.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).;A Domain Specific Language (DSL).","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","Dynamic process creation","API should be clearly versioned.","3"
"2019/04/01 2:13:10 PM AST","Governmental institute","Italy","5","4","C/C++","between 5 and 10 years","between 5 and 10 years","Numerical application and/or library;Image processing","Parallelization of sequential program(s);Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).","I have never read any MPI books","MPICH;Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Domain decomposition","Dynamic process creation;Persistent communication","Point-to-point communications;Collective communications;MPI datatypes;One-sided communications;MPI with OpenMP (or multithread);PMPI interface","MPI_THREAD_MULTIPLE","I do not like the API.","Never","Yes, to minimize the changes of communication API.","OpenMP;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.;A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","Communicator and group management","API should be clearly versioned.","2"
"2019/04/01 2:17:31 PM AST","College/University","United States","6","6","Fortran 90 or newer;Python","more than 10 years","more than 10 years","Numerical application and/or library","Research and development software tool(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).;Other lectures or tutorials (workplace, conference).","Using MPI","MPICH;Open MPI;Intel MPI;IBM MPI (BG/Q, PE, Spectrum);PGI MPI","I am familiar with it.","I read book(s) (except the MPI standard).;I read online documents (such as man pages).;I look at my existing code","Debugging","PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes","I have never called MPI_INIT_THREAD","I have no obstacles.","Sometimes","No, MPI calls are scattered in my programs.","OpenMP;OpenACC;OpenCL","Yes, I know there is room for tuning but I do not have enough resources to do that.","","Multi-threading support","Latency hiding (including asynchronous completion)","There are no unnecessary features","Yes, compatibility is very important for me.","3"
"2019/04/01 2:22:56 PM AST","College/University","Germany","5","3","C/C++;Fortran 90 or newer;Python","between 5 and 10 years","between 2 and 5 years","Numerical application and/or library","Research and development of application(s);Research and development software tool(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","I have never read any MPI books","MPICH;Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).","Debugging","PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","OpenMP","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","There are no unnecessary features","Yes, compatibility is very important for me.","3"
"2019/04/01 2:34:55 PM AST","Hardware vendor","United States","4","3","C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer;Python","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).","Using MPI;MPI: The Complete Reference","MPICH;Open MPI;MVAPICH","I am familiar with it.","I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Domain decomposition","Communicator operations (split, duplicate, and so on)","Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","Time to practice.","","","OpenMP;OpenACC;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","","Latency","Latency hiding (including asynchronous completion);Resilience (fault tolerance)","Process topologies;Dynamic process creation","API should be clearly versioned.","3"
"2019/04/01 2:41:40 PM AST","Governmental institute","United Kingdom","5","5","C/C++;Python","more than 10 years","between 2 and 5 years","Numerical application and/or library;Workflow and/or In-situ;Tool development (performance tuning, debugging, etc.)","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","I read only the chapters of interest for my work.","I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Beginning MPI (An Introduction in C);Using MPI;MPI: The Complete Reference","MPICH;Open MPI;Intel MPI","I like to use it.","I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Algorithm design","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_MULTIPLE","Too many routines.;Too complicated and hard to understand.","Mostly","Yes, to minimize the changes of communication API.","OpenMP;OpenACC;CUDA","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A framework or library using MPI.;A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).;A Domain Specific Language (DSL).","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Latency hiding (including asynchronous completion);Resilience (fault tolerance);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.);Another API which is easier and/or simpler to use","There are no unnecessary features","I prefer to have new API which is simpler and/or easier-to-use.","3"
"2019/04/01 3:03:25 PM AST","College/University","Germany","5","2","C/C++;Matlab","more than 10 years","between 2 and 5 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","Parallel Programming in MPI and OpenMP, Victor Eijkhout","Open MPI;Intel MPI","I like to use it.","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Performance tuning","PMPI interface","Point-to-point communications;Collective communications;MPI datatypes","I do not know or I do not care.","Too many routines.","I rely on the default ‘Errors abort’ error handling","No, my program is too small to do that.","No","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A framework or library using MPI.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","One-sided communication;Communicator and group management;Dynamic process creation","I prefer to have new API for better performance.","4"
"2019/04/01 3:17:38 PM AST","College/University","France","5","4","C/C++;Python","more than 10 years","more than 10 years","Parallel language (incl. domain specific language);Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I had lecture(s) at school.","","MPICH;Open MPI;Intel MPI","I have no special reason.","I search the Internet (Google / Stack Overflow).","Performance tuning","One-sided communications;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes","I do not know or I do not care.","I do not like the API.","Always","Yes, to minimize the changes of communication API.","No","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.;A Domain Specific Language (DSL).","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Another API which is easier and/or simpler to use","There are no unnecessary features","I prefer to have new API which is simpler and/or easier-to-use.","3"
"2019/04/01 3:28:11 PM AST","Software vendor","United arab Emirates ","6","3","C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer;Java;C# VB","more than 10 years","less than 2 years","System software development (OS, runtime library, communication library, etc.);Parallel language (incl. domain specific language);Numerical application and/or library;AI (Deep Learning);Image processing;Big data;Workflow and/or In-situ;Visualization","Research and development of application(s);Research and development software tool(s);Performance tuning of MPI program(s);Debugging MPI programs","I read only the chapters of interest for my work.","I read the MPI standard document.;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Beginning MPI (An Introduction in C);Using MPI;Parallel Programming in C with MPI and OpenMP","Open MPI","I was said to use it.","I read the MPI Standard document (web/book).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Domain decomposition","Persistent communication","MPI with OpenMP (or multithread)","MPI_THREAD_SERIALIZED","Too many routines.;No appropriate lecture / book / info.;Too complicated and hard to understand.","Mostly","Yes, to minimize the changes of communication API.","No","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.;A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).;A Domain Specific Language (DSL).;Low-level communication layer provided by vendor (Verbs, DCMF, ...).","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Latency hiding (including asynchronous completion);Endpoints (multi-thread, sessions);Resilience (fault tolerance);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","Process topologies","Yes, compatibility is very important for me.","2"
"2019/04/01 3:43:03 PM AST","College/University","United Kingdom","5","3","C/C++;Fortran 90 or newer;Python","more than 10 years","between 5 and 10 years","Numerical application and/or library","Research and development software tool(s);Performance tuning of MPI program(s)","No, and I will not read it.","from peers and search engines","I have never read any MPI books","MPICH;Intel MPI","I was said to use it.","I search the Internet (Google / Stack Overflow).","Debugging","Communicator operations (split, duplicate, and so on);One-sided communications;Dynamic process creation;MPI with OpenMP (or multithread);PMPI interface","Point-to-point communications;Collective communications","I have never called MPI_INIT_THREAD","I have nobody to ask.","I rely on the default ‘Errors abort’ error handling","No, MPI calls are scattered in my programs.","No","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Latency","Latency hiding (including asynchronous completion);Resilience (fault tolerance)","Communicator and group management;Process topologies;Dynamic process creation","I do not know or I do not care.","4"
"2019/04/01 3:46:36 PM AST","Governmental institute","United States","3","4","C/C++;Fortran 90 or newer;Python","between 5 and 10 years","between 2 and 5 years","Numerical application and/or library;AI (Deep Learning)","Research and development of application(s);Performance tuning of MPI program(s)","I have not read it, but I plan to.","I read book(s).;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Using MPI","MPICH;Open MPI;Intel MPI;Cray MPI;IBM MPI (BG/Q, PE, Spectrum)","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).","Algorithm design","","Point-to-point communications;Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","I have no obstacles.","Mostly","No, MPI calls are scattered in my programs.","OpenMP","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A framework or library using MPI.;A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","There are no unnecessary features","Yes, compatibility is very important for me.","4"
"2019/04/01 4:03:43 PM AST","College/University","Germany","4","2","Fortran (older one than Fortran 90);Fortran 90 or newer;Python","more than 10 years","between 2 and 5 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).","MPI: The Complete Reference","MPICH","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation;Persistent communication;PMPI interface","Collective communications","I have never called MPI_INIT_THREAD","I have no obstacles.","Never","No, MPI calls are scattered in my programs.","No","No, my MPI programs are well-tuned.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","There are no unnecessary features","Yes, compatibility is very important for me.","3"
"2019/04/01 4:35:12 PM AST","College/University","United States","5","5","C/C++;Fortran 90 or newer;Python","more than 10 years","","Numerical application and/or library;AI (Deep Learning);Big data;Workflow and/or In-situ;Visualization","Research and development of application(s)","I read only the chapters of interest for my work.","I read book(s).;Other lectures or tutorials (workplace, conference).","Using MPI;MPI: The Complete Reference","MPICH;Open MPI;Intel MPI;Cray MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","Dynamic process creation;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;One-sided communications","I have never called MPI_INIT_THREAD","","Sometimes","Yes, to minimize the changes of communication API.","CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Latency hiding (including asynchronous completion);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","Communicator and group management","Yes, compatibility is very important for me.","3"
"2019/04/01 5:10:51 PM AST","Governmental institute","Sweden","6","4","C/C++;CUDA, OpenCL","more than 10 years","between 5 and 10 years","biophysics simluation software","Research and development of application(s);Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","MPI: The Complete Reference","MPICH;Open MPI;Intel MPI;Cray MPI","I have no special reason.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Implementation issue workaround","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);One-sided communications","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","I do not like the API.","Mostly","Yes, to minimize the changes of communication API.","OpenMP;OpenCL;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).;Low-level communication layer provided by vendor (Verbs, DCMF, ...).","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Latency hiding (including asynchronous completion);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.);notified access","Dynamic process creation","I prefer to have new API for better performance.","3"
"2019/04/01 5:58:41 PM AST","College/University","United States","5","3","C/C++;Julia","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I had lecture(s) at school.;I read articles found on Internet.","I have never read any MPI books","MPICH;Open MPI;MVAPICH","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).","","","Point-to-point communications;Collective communications","I do not know or I do not care.","","Never","Yes, to minimize the changes of communication API.","OpenMP;OpenCL;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","Low-level communication layer provided by vendor (Verbs, DCMF, ...).","","","","API should be clearly versioned.","3"
"2019/04/01 5:59:43 PM AST","College/University","United States","6","6","C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer;Python;Julia","more than 10 years","more than 10 years","Parallel language (incl. domain specific language);Numerical application and/or library;AI (Deep Learning);Big data","Research and development of application(s)","I read most of it.","","","MPICH;Open MPI;MVAPICH;Intel MPI","I have no special reason.","I know almost all MPI routines.","Algorithm design","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);One-sided communications","I have never called MPI_INIT_THREAD;I do not know or I do not care.","I have no obstacles.","Mostly","Yes, to minimize the changes of communication API.","OpenMP;Pthread;OpenACC;CUDA","No, my MPI programs are well-tuned.","A framework or library using MPI.;A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).;A Domain Specific Language (DSL).;Low-level communication layer provided by vendor (Verbs, DCMF, ...).","Latency","","Datatypes;Process topologies","I prefer to have new API for better performance.","3"
"2019/04/01 6:06:03 PM AST","College/University","Czech Republic","5","3","C/C++;Python","more than 10 years","between 5 and 10 years","AI (Deep Learning);Image processing;Big data;Workflow and/or In-situ;Visualization;Tool development (performance tuning, debugging, etc.)","Research and development software tool(s)","","I read book(s).;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","MPI: The Complete Reference","Open MPI","I like to use it.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","Too many routines.","Never","No, my program is too small to do that.","OpenMP;CUDA","I have no chance to investigate.","I am not investigating any alternatives.","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Latency hiding (including asynchronous completion);Resilience (fault tolerance);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","Dynamic process creation","I prefer to have new API for better performance.","5"
"2019/04/01 6:19:10 PM AST","College/University","Switzerland","4","4","C/C++;Fortran 90 or newer;Python","between 5 and 10 years","between 2 and 5 years","Parallel language (incl. domain specific language);Numerical application and/or library","Research and development software tool(s);Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","I have never read any MPI books","MPICH;Open MPI;Intel MPI;Cray MPI","I like to use it.","I read the MPI Standard document (web/book).;I search the Internet (Google / Stack Overflow).","Algorithm design","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;Dynamic process creation;MPI with OpenMP (or multithread)","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);Dynamic process creation","I have never called MPI_INIT_THREAD","I have no obstacles.","Never","No, MPI calls are scattered in my programs.","OpenMP;Just as exercise in classes, or seen in others' programs","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A framework or library using MPI.","I am thinking whether I will need HWLOC","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.);MPI is providing all the communication semantics required by my application","Process topologies;I don't think I need them. But they are useful for domain decomposition.","Yes, compatibility is very important for me.","2"
"2019/04/01 7:15:22 PM AST","College/University","United Kingdom","5","4","Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Using MPI","MPICH;Open MPI;MVAPICH;Intel MPI;Cray MPI;IBM MPI (BG/Q, PE, Spectrum);HPE MPI","I like to use it.","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Implementation issue workaround","","","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED;MPI_THREAD_SERIALIZED","I find the shared memory window API a bit confusing, and always have to relearn how to use it","Always","Yes, to minimize the changes of communication API.","OpenMP;Pthread;OpenACC","Yes, I know there is room for tuning but I do not have enough resources to do that.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Latency","MPI is providing all the communication semantics required by my application","There are no unnecessary features","I prefer to have new API for better performance.","3"
"2019/04/01 7:58:59 PM AST","College/University","Canada","6","4","C/C++;Fortran 90 or newer;Python","more than 10 years","more than 10 years","Parallel language (incl. domain specific language);Numerical application and/or library;AI (Deep Learning);Big data","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","I read only the chapters of interest for my work.","I read book(s).;Other lectures or tutorials (workplace, conference).","Using MPI","Open MPI;Intel MPI;IBM MPI (BG/Q, PE, Spectrum)","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).;I read online documents (such as man pages).","Debugging","Persistent communication","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_FUNNELED","Too complicated and hard to understand.;I do not like the API.","I rely on the default ‘Errors abort’ error handling","No, MPI calls are scattered in my programs.","OpenMP;OpenACC","I have no chance to investigate.","A framework or library using MPI.;A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Message injection rate","MPI is providing all the communication semantics required by my application","There are no unnecessary features","API should be clearly versioned.","4"
"2019/04/01 9:31:00 PM AST","College/University","Finland","5","3","C/C++;Fortran 90 or newer;Python","between 5 and 10 years","between 2 and 5 years","Parallel language (incl. domain specific language);Numerical application and/or library;Image processing;Visualization","Scientific computing","I have not read it, but I plan to.","I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","I have never read any MPI books","Open MPI;Intel MPI","I was said to use it.","I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI with OpenMP (or multithread)","I do not know or I do not care.","Modifying old MPI code.","Sometimes","Yes, to minimize the changes of communication API.","CUDA","I think there is room but I do not know how to tune it.","A framework or library using MPI.;A Domain Specific Language (DSL).","Multi-threading support","","There are no unnecessary features","Yes, compatibility is very important for me.","2"
"2019/04/01 9:42:19 PM AST","Governmental institute","Singapore","5","4","C/C++","between 5 and 10 years","between 2 and 5 years","System software development (OS, runtime library, communication library, etc.)","Research and development on system software (OS and/or runtime library)","I have not read it, but I plan to.","I had lecture(s) at school.;I read articles found on Internet.","I have never read any MPI books","Open MPI;Intel MPI","I am familiar with it.","I read online documents (such as man pages).","Algorithm design","Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes","MPI_THREAD_SINGLE;I have never called MPI_INIT_THREAD","No appropriate lecture / book / info.","Never","No, my program is too small to do that.","OpenMP;CUDA","I think there is room but I do not know how to tune it.","A framework or library using MPI.","MPI provides all semantics I need","","One-sided communication","Yes, compatibility is very important for me.","4"
"2019/04/01 10:13:20 PM AST","Governmental institute","United States","4","2","C/C++;Fortran 90 or newer;Python","between 5 and 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s);Research and development software tool(s);Parallelization of sequential program(s);Performance tuning of MPI program(s)","","I read book(s).;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Parallel Programming with MPI;Using MPI","Open MPI;MVAPICH;Intel MPI","I am familiar with it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","Dynamic process creation;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;One-sided communications","MPI_THREAD_SERIALIZED","Too many routines.;No appropriate lecture / book / info.","Sometimes","No, MPI calls are scattered in my programs.","OpenMP;OpenACC;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","There are no unnecessary features","I prefer to have new API which is simpler and/or easier-to-use.","4"
"2019/04/01 10:27:58 PM AST","Governmental institute","Netherlands","5","5","C/C++;Python","more than 10 years","between 5 and 10 years","Image processing;Big data","Research and development of application(s);Parallelization of sequential program(s)","I read most of it.","I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","Parallel Programming with MPI","MPICH;Open MPI;Intel MPI","I have no special reason.","I read the MPI Standard document (web/book).;I know almost all MPI routines.","Algorithm design","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;Dynamic process creation;Persistent communication;MPI with OpenMP (or multithread);PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;One-sided communications","I have never called MPI_INIT_THREAD","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","No","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","Dynamic process creation","Yes, compatibility is very important for me.","1"
"2019/04/01 10:38:46 PM AST","College/University","United States","5","4","C/C++;Python","between 2 and 5 years","less than 2 years","System software development (OS, runtime library, communication library, etc.);Big data","Research and development of application(s);Research and development software tool(s)","I have not read it, but I plan to.","I had lecture(s) at school.;I read articles found on Internet.","","Open MPI","I am familiar with it.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","Persistent communication;PMPI interface","Point-to-point communications;MPI datatypes;Dynamic process creation;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","No appropriate lecture / book / info.;Too complicated and hard to understand.","Sometimes","No, my program is too small to do that.","OpenMP;CUDA","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","I am not investigating any alternatives.","Multi-threading support","Another API which is easier and/or simpler to use","There are no unnecessary features","API should be clearly versioned.","4"
"2019/04/01 11:46:39 PM AST","College/University","Germany","5","3","C/C++","more than 10 years","between 2 and 5 years","Numerical application and/or library","Research and development software tool(s)","I read most of it.","I read the MPI standard document.;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","","MPICH;Open MPI","I have no special reason.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation;Persistent communication","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","I do not know or I do not care.","I have no obstacles.","Mostly","No, MPI calls are scattered in my programs.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Latency","MPI is providing all the communication semantics required by my application","Dynamic process creation","I do not know or I do not care.","5"
"2019/04/01 11:47:08 PM AST","College/University","Germany","6","5","Fortran (older one than Fortran 90);Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library;Big data","Research and development of application(s)","I read most of it.","I read the MPI standard document.;Experimenting. I've been using MPI since 1993","Using MPI","Open MPI;Intel MPI;Cray MPI;NEC MPI","I like to use it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;Persistent communications;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","I have no obstacles.","Sometimes","No, MPI calls are scattered in my programs.","OpenMP;OpenACC;OpenCL","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.;HDF5","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Resilience (fault tolerance)","Dynamic process creation","Yes, compatibility is very important for me.","1"
"2019/04/02 12:58:29 AM AST","Private research institute","Switzerland","6","4","C/C++","more than 10 years","more than 10 years","System software development (OS, runtime library, communication library, etc.);Workflow and/or In-situ;Tool development (performance tuning, debugging, etc.)","Research and development of application(s);Research and development on system software (OS and/or runtime library);Research and development software tool(s)","I read all.","I read the MPI standard document.","I have never read any MPI books","MPICH;Open MPI;MVAPICH;Intel MPI;Cray MPI","I have no special reason.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I ask colleagues.","Implementation issue workaround","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;Dynamic process creation;MPI with OpenMP (or multithread);PMPI interface","MPI_THREAD_SINGLE;MPI_THREAD_SERIALIZED;MPI_THREAD_MULTIPLE","I have no obstacles.","Mostly","Yes, to minimize the changes of communication API.","OpenMP;Pthread","","A framework or library using MPI.;A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).;Low-level communication layer provided by vendor (Verbs, DCMF, ...).","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Endpoints (multi-thread, sessions);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","Datatypes","API should be clearly versioned.","3"
"2019/04/02 2:15:48 AM AST","Governmental institute","Spain","4","1","C/C++;Fortran 90 or newer;Python","more than 10 years","less than 2 years","Numerical application and/or library;Visualization","Research and development of application(s)","","I have not learned MPI.","I have never read any MPI books","Open MPI;Intel MPI","I have no special reason.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Finding appropriate MPI routines","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;Dynamic process creation;Persistent communication;PMPI interface","MPI with OpenMP (or multithread)","I do not know or I do not care.","I have nobody to ask.","I rely on the default ‘Errors abort’ error handling","No, my program is too small to do that.","OpenMP","I think there is room but I do not know how to tune it.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","There are no unnecessary features","I prefer to have new API which is simpler and/or easier-to-use.","4"
"2019/04/02 2:30:30 AM AST","College/University","Germany","4","5","C/C++;Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library","Performance tuning of MPI program(s)","I read most of it.","I read the MPI standard document.","I have never read any MPI books","MPICH;Open MPI;Cray MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).","Performance tuning","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread);PMPI interface","MPI_THREAD_SERIALIZED;MPI_THREAD_MULTIPLE","Too many routines.","I rely on the default ‘Errors abort’ error handling","","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).;A Domain Specific Language (DSL).","Latency","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","the performance of some features needs improvement","API should be clearly versioned.","4"
"2019/04/02 2:31:46 AM AST","College/University","Russia","5","5","C/C++;Python;haskell, matlab, wolfram mathematica","more than 10 years","more than 10 years","Numerical application and/or library;AI (Deep Learning);Tool development (performance tuning, debugging, etc.)","Research and development of application(s);Research and development software tool(s);Parallelization of sequential program(s);Scientific HPC solvers for fluid dynamics and quantum physics","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","Beginning MPI (An Introduction in C);Parallel Programming in C with MPI and OpenMP;MPI: The Complete Reference","MPICH;Open MPI","I am familiar with it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).;mpi must be CUDA-AWARE. We have 1024 GPUs","Performance tuning","MPI with OpenMP (or multithread)","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;Dynamic process creation;Persistent communications;PMPI interface","MPI_THREAD_SINGLE","I have no obstacles.;I do not like the API.","Mostly","Yes, to minimize the changes of communication API.","Pthread;OpenCL;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.;A Domain Specific Language (DSL).","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.);Another API which is easier and/or simpler to use","There are no unnecessary features","API should be clearly versioned.","5"
"2019/04/02 2:39:42 AM AST","College/University","Germany","4","3","C/C++;Python","more than 10 years","between 2 and 5 years","Numerical application and/or library","Research and development of application(s)","No, and I will not read it.","I had lecture(s) at school.;I read articles found on Internet.","I have never read any MPI books","MPICH;Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Algorithm design","Communicator operations (split, duplicate, and so on);Dynamic process creation;Persistent communication;MPI with OpenMP (or multithread);PMPI interface","Point-to-point communications;Collective communications;MPI datatypes","I have never called MPI_INIT_THREAD","I do not like the API.","I rely on the default ‘Errors abort’ error handling","No, MPI calls are scattered in my programs.","No","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Bandwidth","Endpoints (multi-thread, sessions);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","Process topologies;Dynamic process creation","I prefer to have new API for better performance.","4"
"2019/04/02 2:50:00 AM AST","College/University","Germany","4","3","C/C++;Python","between 5 and 10 years","between 2 and 5 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","I have never read any MPI books","MPICH;Open MPI","I have no special reason.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","Persistent communication","Point-to-point communications;Collective communications;MPI datatypes","I have never called MPI_INIT_THREAD","I have no obstacles.","Sometimes","Yes, but I have no special reason for doing that.","No","I think there is room but I do not know how to tune it.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","Process topologies;Dynamic process creation","I prefer to have new API for better performance.","5"
"2019/04/02 2:54:37 AM AST","College/University","Belgium","5","4","C/C++;Fortran 90 or newer;Python","more than 10 years","between 5 and 10 years","AI (Deep Learning);Tool development (performance tuning, debugging, etc.)","Research and development software tool(s);Training","I read most of it.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).","MPI: The Complete Reference","Open MPI;MVAPICH;Intel MPI","I like to use it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Domain decomposition","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_FUNNELED","I have no obstacles.","Sometimes","Yes, to minimize the changes of communication API.","OpenMP","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Resilience (fault tolerance);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","There are no unnecessary features","API should be clearly versioned.","3"
"2019/04/02 3:16:10 AM AST","Governmental institute","Germany","5","5","C/C++;Fortran 90 or newer;Python","more than 10 years","more than 10 years","Numerical application and/or library;Tool development (performance tuning, debugging, etc.)","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","","I read book(s).;I read articles found on Internet.","MPI: The Complete Reference","MPICH;Intel MPI","I am familiar with it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).","Performance tuning","Dynamic process creation;Persistent communication","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread);MPI-IO","I have never called MPI_INIT_THREAD","I have no obstacles.","Mostly","Yes, to minimize the changes of communication API.","OpenMP;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.;A Domain Specific Language (DSL).","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","One-sided communication;Dynamic process creation","Yes, compatibility is very important for me.","4"
"2019/04/02 3:17:33 AM AST","College/University","Sweden","3","1","Fortran (older one than Fortran 90);Fortran 90 or newer","less than 2 years","less than 2 years","Numerical application and/or library;Visualization","Research and development of application(s)","I have not read it, but I plan to.","I have not learned MPI.","I have never read any MPI books","Open MPI;Intel MPI;Cray MPI","I am familiar with it.","I search the Internet (Google / Stack Overflow).","Algorithm design","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;Dynamic process creation;Persistent communication;PMPI interface","MPI with OpenMP (or multithread)","I do not know or I do not care."," not my main priority / lack of time","I rely on the default ‘Errors abort’ error handling","No, MPI calls are scattered in my programs.","OpenMP","I do not have (know) tools to find performance bottlenecks.","A framework or library using MPI.","","","","API should be clearly versioned.","4"
"2019/04/02 3:31:08 AM AST","College/University","Sweden","6","5","C/C++","more than 10 years","more than 10 years","Parallel language (incl. domain specific language);Numerical application and/or library","Research and development of application(s)","I have not read it, but I plan to.","I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","Parallel Programming with MPI;Using MPI","MPICH;Open MPI;MVAPICH;Cray MPI","I am familiar with it.","I read book(s) (except the MPI standard).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Finding appropriate MPI routines","Communicator operations (split, duplicate, and so on);Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","I do not know or I do not care.","Time limit","Sometimes","No, MPI calls are scattered in my programs.","OpenMP;CUDA","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Another API which is easier and/or simpler to use","There are no unnecessary features","I do not know or I do not care.","3"
"2019/04/02 3:38:09 AM AST","Governmental institute","Germany","4","4","C/C++;Fortran 90 or newer;Python","between 5 and 10 years","between 2 and 5 years","Numerical application and/or library;Tool development (performance tuning, debugging, etc.)","Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","I read only the chapters of interest for my work.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","I have never read any MPI books","Open MPI;Intel MPI","I am familiar with it.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Point-to-point communications;Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","Point-to-point communications;Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","I have no obstacles.","Sometimes","No, MPI calls are scattered in my programs.","OpenMP","No, my MPI programs are well-tuned.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Resilience (fault tolerance);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","There are no unnecessary features","Yes, compatibility is very important for me.","4"
"2019/04/02 3:43:19 AM AST","Governmental institute","Germany","5","5","C/C++;Fortran 90 or newer;Python","more than 10 years","between 5 and 10 years","Numerical application and/or library;Visualization","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","I read most of it.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","I have never read any MPI books","MPICH;Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I search the Internet (Google / Stack Overflow).","Algorithm design","Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","No, MPI calls are scattered in my programs.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","One-sided communication","API should be clearly versioned.","4"
"2019/04/02 3:50:19 AM AST","College/University","Denmark","5","5","Fortran (older one than Fortran 90);Fortran 90 or newer;Python","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Using MPI;MPI: The Complete Reference","MPICH;Open MPI;Intel MPI;IBM MPI (BG/Q, PE, Spectrum)","I like to use it.","I read online documents (such as man pages).","Performance tuning","Dynamic process creation;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_MULTIPLE","I have no obstacles.","Sometimes","Yes, to minimize the changes of communication API.","OpenMP;OpenACC","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.","Multi-threading support","Latency hiding (including asynchronous completion);Endpoints (multi-thread, sessions)","Process topologies;Dynamic process creation;Error handlers","API should be clearly versioned.","4"
"2019/04/02 3:52:21 AM AST","College/University","Germany","5","3","C/C++;Fortran (older one than Fortran 90);Python","between 5 and 10 years","less than 2 years","Numerical application and/or library;AI (Deep Learning)","Parallelization of sequential program(s);Research and development of scientific software","I read only the chapters of interest for my work.","I had lecture(s) at school.;I read articles found on Internet.","I have never read any MPI books","Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation;PMPI interface","Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes","MPI_THREAD_SINGLE;MPI_THREAD_SERIALIZED;MPI_THREAD_MULTIPLE","No appropriate lecture / book / info.;I have nobody to ask.","Mostly","No, my program is too small to do that.","OpenMP;OpenACC","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.;A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","MPI is providing all the communication semantics required by my application","There are no unnecessary features","I prefer to have new API which is simpler and/or easier-to-use.","4"
"2019/04/02 4:00:30 AM AST","Private research institute","Netherlands","5","5","C/C++;Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library;Tool development (performance tuning, debugging, etc.)","Research and development of application(s);Parallelization of sequential program(s)","I read only the chapters of interest for my work.","I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","","Open MPI;Intel MPI","I was said to use it.","I read the MPI Standard document (web/book).;I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","Too complicated and hard to understand.;Debug","Mostly","Yes, to minimize the changes of communication API.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.;I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Resilience (fault tolerance);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","There are no unnecessary features","Yes, compatibility is very important for me.","4"
"2019/04/02 4:02:08 AM AST","Governmental institute","United Kingdom","5","4","Fortran (older one than Fortran 90);Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library","Parallelization of sequential program(s);Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).","Using MPI","MPICH;Cray MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).","Algorithm design","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED;MPI_THREAD_SERIALIZED;MPI_THREAD_MULTIPLE","Too many routines.","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","OpenMP","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A framework or library using MPI.","Multi-threading support","Resilience (fault tolerance)","There are no unnecessary features","Yes, compatibility is very important for me.","3"
"2019/04/02 4:02:37 AM AST","College/University","Italy","3","2","C/C++;Python","between 5 and 10 years","between 2 and 5 years","Numerical application and/or library","Research and development of application(s)","I have not read it, but I plan to.","Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","I have never read any MPI books","Open MPI;Intel MPI","I am familiar with it.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Domain decomposition","One-sided communications;Dynamic process creation;Persistent communication;PMPI interface","Collective communications","I have never called MPI_INIT_THREAD","I have nobody to ask.;Interfacing with external libraries (e.g. using pnetcdf with MPI is not trivial)","Never","No, MPI calls are scattered in my programs.","No","I do not have (know) tools to find performance bottlenecks.","","Interfacing with/switching from CUDA","Another API which is easier and/or simpler to use","There are no unnecessary features","I prefer to have new API which is simpler and/or easier-to-use.","1"
"2019/04/02 4:08:48 AM AST","Governmental institute","Germany","5","4","Fortran 90 or newer","more than 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.;learning by doing; course","don't remember","Open MPI;Intel MPI","I have no special reason.","I read the MPI Standard document (web/book).;I search the Internet (Google / Stack Overflow).","Algorithm design","PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI with OpenMP (or multithread)","MPI_THREAD_MULTIPLE","I have nobody to ask.","Sometimes","No, MPI calls are scattered in my programs.","OpenMP;Pthread;MPI + Pthread but only via library (PaStiX)","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","MPI provides all semantics I need","","There are no unnecessary features","API should be clearly versioned.","3"
"2019/04/02 4:17:18 AM AST","Governmental institute","United Kingdom","5","5","C/C++;Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s);Performance tuning of MPI program(s);Strategic management and HPC procurement","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.;Discussions with peers","Parallel Programming with MPI;Using MPI;Using MPI 2, Using Advanced MPI","MPICH;Cray MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Algorithm design","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread);MPI-IO, non-blocking collectives","MPI_THREAD_FUNNELED;MPI_THREAD_SERIALIZED;MPI_THREAD_MULTIPLE","Too much else to do!","I rely on the default ‘Errors abort’ error handling","Yes, to abstract interfaces to 32-bit/64-bit libraries","OpenMP","Yes, and am constantly doing so as the code evolves (>100 devs)","A Domain Specific Language (DSL).","Network congestion control","QOS by communicator - I know which traffic I wish to prioritise from a latency perspective!","Process topologies;Dynamic process creation;Error handlers","The weasel response - I want the code I use to be backward compatible, but don't mind if other bits break!","4"
"2019/04/02 4:46:30 AM AST","College/University","United Kingdom","4","3","C/C++;Fortran 90 or newer;Python","more than 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s)","No, and I will not read it.","I had lecture(s) at school.","","MPICH;Open MPI;Intel MPI","I have no special reason.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Performance tuning","Dynamic process creation;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes","I have never called MPI_INIT_THREAD","Too complicated and hard to understand.;I do not like the API.;Performance tuning is a black art","Sometimes","Yes, to minimize the changes of communication API.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.;A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Latency hiding (including asynchronous completion);Another API which is easier and/or simpler to use","","API should be clearly versioned.","3"
"2019/04/02 4:53:28 AM AST","Governmental institute","Germany","4","3","C/C++;Fortran 90 or newer;Python","between 2 and 5 years","between 2 and 5 years","Numerical application and/or library;Visualization","Research and development of application(s);Performance tuning of MPI program(s)","No, and I will not read it.","Other lectures or tutorials (workplace, conference).","I have never read any MPI books","Intel MPI;IBM MPI (BG/Q, PE, Spectrum)","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Finding appropriate MPI routines","Persistent communication","Point-to-point communications;Collective communications;One-sided communications","I do not know or I do not care.","No appropriate lecture / book / info.","I rely on the default ‘Errors abort’ error handling","No, MPI calls are scattered in my programs.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","There are no unnecessary features","I prefer to have new API which is simpler and/or easier-to-use.","4"
"2019/04/02 4:59:07 AM AST","Governmental institute","Spain","2","3","C/C++","between 5 and 10 years","between 2 and 5 years","Visualization;Tool development (performance tuning, debugging, etc.)","Research and development of application(s);Research and development on system software (OS and/or runtime library);Research and development software tool(s);Performance tuning of MPI program(s)","I read most of it.","I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","I have never read any MPI books","MPICH;Open MPI;Intel MPI","I am familiar with it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Performance tuning","MPI datatypes;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;One-sided communications;Dynamic process creation;MPI with OpenMP (or multithread)","MPI_THREAD_MULTIPLE","I have no obstacles.","Always","No, my program is too small to do that.","OpenMP;CUDA","I think there is room but I do not know how to tune it.","I am not investigating any alternatives.","Bandwidth","MPI is providing all the communication semantics required by my application","There are no unnecessary features","I prefer to have new API for better performance.","3"
"2019/04/02 5:03:54 AM AST","College/University","Austria","4","2","Fortran (older one than Fortran 90)","more than 10 years","between 5 and 10 years","Numerical application and/or library","Performance tuning of MPI program(s)","No, and I will not read it.","I read book(s).;Other lectures or tutorials (workplace, conference).","I have never read any MPI books","Open MPI;Intel MPI;HPE MPI;NEC MPI","I like to use it.","I read online documents (such as man pages).","Domain decomposition","Persistent communication","Point-to-point communications","MPI_THREAD_SERIALIZED","No appropriate lecture / book / info.","I rely on the default ‘Errors abort’ error handling","No, MPI calls are scattered in my programs.","OpenMP","I think there is room but I do not know how to tune it.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Multi-threading support","Resilience (fault tolerance)","There are no unnecessary features","Yes, compatibility is very important for me.","4"
"2019/04/02 5:04:42 AM AST","College/University","Spain","5","5","C/C++;Fortran 90 or newer;Python","between 2 and 5 years","between 2 and 5 years","Parallel language (incl. domain specific language);Numerical application and/or library;Tool development (performance tuning, debugging, etc.)","Research and development of application(s);Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","I have never read any MPI books","MPICH;Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation;Persistent communication","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread);PMPI interface","MPI_THREAD_MULTIPLE","I have no obstacles.","Mostly","Yes, to minimize the changes of communication API.","OpenMP;Pthread;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.;A Domain Specific Language (DSL).","Latency","Latency hiding (including asynchronous completion)","There are no unnecessary features","I do not know or I do not care.","3"
"2019/04/02 5:06:15 AM AST","College/University","United States","4","3","Fortran 90 or newer","between 5 and 10 years","between 2 and 5 years","Parallel language (incl. domain specific language)","","No, and I will not read it.","Other lectures or tutorials (workplace, conference).;I read articles found on Internet.;I have not learned MPI.","Introduction to High Performance Computing for Scientists and Engineers","Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","Persistent communication;PMPI interface","Point-to-point communications;Collective communications;One-sided communications","I have never called MPI_INIT_THREAD","Too many routines.","I rely on the default ‘Errors abort’ error handling","No, MPI calls are scattered in my programs.","OpenMP","I think there is room but I do not know how to tune it.","I am not investigating any alternatives.","varies","Resilience (fault tolerance)","There are no unnecessary features","I do not know or I do not care.","3"
"2019/04/02 5:12:31 AM AST","College/University","United Kingdom","5","3","C/C++;Fortran 90 or newer;Python","between 5 and 10 years","between 5 and 10 years","Numerical application and/or library;Workflow and/or In-situ;Visualization;Tool development (performance tuning, debugging, etc.)","Research and development of application(s);Research and development software tool(s)","No, and I will not read it.","I had lecture(s) at school.;I read articles found on Internet.","","Open MPI","I was said to use it.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Communicator operations (split, duplicate, and so on);One-sided communications;Dynamic process creation;PMPI interface","Point-to-point communications;Collective communications","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","","I rely on the default ‘Errors abort’ error handling","No, MPI calls are scattered in my programs.","","I do not have (know) tools to find performance bottlenecks.","","MPI provides all semantics I need","","","","3"
"2019/04/02 5:18:31 AM AST","Governmental institute","Spain","5","2","C/C++;Python","between 2 and 5 years","less than 2 years","Parallel language (incl. domain specific language);AI (Deep Learning);Tool development (performance tuning, debugging, etc.)","Research and development software tool(s);Parallelization of sequential program(s)","I have not read it, but I plan to.","I had lecture(s) at school.","I have never read any MPI books","Intel MPI;IBM MPI (BG/Q, PE, Spectrum)","I have no special reason.","I ask colleagues.;I search the Internet (Google / Stack Overflow).","Debugging","PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);Dynamic process creation;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","Too many routines.","Sometimes","No, my program is too small to do that.","OpenMP;CUDA","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","I am not investigating any alternatives.","Multi-threading support","Another API which is easier and/or simpler to use","Datatypes","I prefer to have new API for better performance.","4"
"2019/04/02 5:24:32 AM AST","Governmental institute","France","4","3","C/C++;Python","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).;Other lectures or tutorials (workplace, conference).","Using MPI","MPICH;Open MPI","I like to use it.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Domain decomposition","","Point-to-point communications;Collective communications","I have never called MPI_INIT_THREAD","Have not kept up with recent changes","I rely on the default ‘Errors abort’ error handling","Mostly use through libraries","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.","","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","One-sided communication;Dynamic process creation","API should be clearly versioned.","2"
"2019/04/02 5:43:40 AM AST","Software vendor","Germany","6","6","C/C++","more than 10 years","more than 10 years","System software development (OS, runtime library, communication library, etc.)","Research and development on system software (OS and/or runtime library)","I read most of it.","I read the MPI standard document.;I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","Using MPI","MPICH;MVAPICH;Intel MPI;ParaStation MPI","I am familiar with it.","I know almost all MPI routines.","Other","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;Dynamic process creation;MPI with OpenMP (or multithread)","MPI_THREAD_MULTIPLE","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","No, MPI calls are scattered in my programs.","OpenMP;Pthread;CUDA","No, my MPI programs are well-tuned.","I am not investigating any alternatives.","MPI provides all semantics I need","Endpoints (multi-thread, sessions);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","One-sided communication;Process topologies","API should be clearly versioned.","3"
"2019/04/02 5:44:19 AM AST","Governmental institute","France","6","4","Fortran (older one than Fortran 90);Fortran 90 or newer;Python","more than 10 years","more than 10 years","Numerical application and/or library;Big data","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","I have never read any MPI books","Open MPI;Intel MPI;HPE MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I search the Internet (Google / Stack Overflow).","Debugging","Communicator operations (split, duplicate, and so on);Dynamic process creation;PMPI interface","Point-to-point communications;Collective communications;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE","I have no obstacles.","Sometimes","Yes so that other non-mpi part developers does not get bothered by mpi functions","CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","(dask)","MPI provides all semantics I need","Resilience (fault tolerance);Another API which is easier and/or simpler to use","There are no unnecessary features","I prefer to have new API which is simpler and/or easier-to-use.","3"
"2019/04/02 5:50:33 AM AST","College/University","Germany","3","2","Fortran (older one than Fortran 90);Python","between 2 and 5 years","less than 2 years","Numerical application and/or library","Research and development of application(s)","No, and I will not read it.","Other lectures or tutorials (workplace, conference).","I have never read any MPI books","Open MPI;Intel MPI","I like to use it.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Communicator operations (split, duplicate, and so on);Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications","I do not know or I do not care.","I have nobody to ask.","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","","No, my MPI programs are well-tuned.","I am not investigating any alternatives.","","","","I prefer to have new API for better performance.","4"
"2019/04/02 6:10:39 AM AST","Hardware vendor","Germany","4","2","C/C++;Fortran 90 or newer;Python","more than 10 years","more than 10 years","Tool development (performance tuning, debugging, etc.)","Performance tuning of MPI program(s)","I read most of it.","I read the MPI standard document.;I read book(s).;Other lectures or tutorials (workplace, conference).","Using MPI;MPI: The Complete Reference","Open MPI;MVAPICH;Intel MPI;NEC MPI","I am familiar with it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Domain decomposition","Persistent communication","Point-to-point communications;Collective communications;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE","Too many routines.;I do not like the API.","Mostly","No, MPI calls are scattered in my programs.","OpenMP;Pthread","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","","Communicator and group management;Dynamic process creation","I prefer to have new API for better performance.","4"
"2019/04/02 6:30:42 AM AST","College/University","Germany","4","4","C/C++;Fortran 90 or newer;Python","between 5 and 10 years","between 2 and 5 years","Parallel language (incl. domain specific language);Numerical application and/or library","Research and development of application(s)","","I read articles found on Internet.","","Intel MPI;ParaStation MPI","I was said to use it.","I ask colleagues.;I search the Internet (Google / Stack Overflow).","Debugging","Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_MULTIPLE","Too many routines.","Never","No, MPI calls are scattered in my programs.","OpenMP","I think there is room but I do not know how to tune it.","I am not investigating any alternatives.","Latency","MPI is providing all the communication semantics required by my application","One-sided communication;Communicator and group management;Process topologies;Dynamic process creation;Error handlers","Yes, compatibility is very important for me.","3"
"2019/04/02 6:34:20 AM AST","Software vendor","Germany","5","4","C/C++;Python","more than 10 years","more than 10 years","System software development (OS, runtime library, communication library, etc.)","Research and development of application(s)","","","","ParaStation MPI","I like to use it.","","Debugging","","","MPI_THREAD_MULTIPLE","I do not like the API.","Always","","","Yes, I know there is room for tuning but I do not have enough resources to do that.","","","","","Yes, compatibility is very important for me.",""
"2019/04/02 6:35:45 AM AST","Software vendor","Germany","5","4","C/C++;Python","between 5 and 10 years","between 2 and 5 years","Parallel language (incl. domain specific language);Image processing;Tool development (performance tuning, debugging, etc.)","Research and development of application(s);Research and development software tool(s);Performance tuning of MPI program(s);Debugging MPI programs","I read most of it.","I read the MPI standard document.;I read book(s).;I had lecture(s) at school.;I read articles found on Internet.","Beginning MPI (An Introduction in C);Parallel Programming with MPI;Parallel Programming in C with MPI and OpenMP;MPI: The Complete Reference","ParaStation MPI","I like to use it.","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Performance tuning","PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;Dynamic process creation;Persistent communications","MPI_THREAD_SINGLE;MPI_THREAD_SERIALIZED;MPI_THREAD_MULTIPLE","I have no obstacles.","Mostly","Yes, to minimize the changes of communication API.","OpenMP;CUDA","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A framework or library using MPI.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","There are no unnecessary features","Yes, compatibility is very important for me.","4"
"2019/04/02 6:40:35 AM AST","College/University","United Kingdom","5","3","Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).;I read articles found on Internet.","Using MPI;MPI: The Complete Reference","MPICH;Open MPI;Cray MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","One-sided communications;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes","I have never called MPI_INIT_THREAD","I have nobody to ask.","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","OpenMP","No, my MPI programs are well-tuned.","I am not investigating any alternatives.","MPI provides all semantics I need","","There are no unnecessary features","Yes, compatibility is very important for me.","2"
"2019/04/02 7:00:13 AM AST","Software vendor","Germany","6","6","C/C++","more than 10 years","more than 10 years","System software development (OS, runtime library, communication library, etc.);Tool development (performance tuning, debugging, etc.)","Research and development on system software (OS and/or runtime library);Research and development software tool(s);Performance tuning of MPI program(s)","","I read the MPI standard document.;I read articles found on Internet.","I have never read any MPI books","MPICH;Open MPI;Intel MPI;ParaStation MPI","I am familiar with it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).","Performance tuning","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;Dynamic process creation;Persistent communications;MPI with OpenMP (or multithread);PMPI interface","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED;MPI_THREAD_SERIALIZED;MPI_THREAD_MULTIPLE","I have no obstacles.;Too many routines.","","No, MPI calls are scattered in my programs.","OpenMP;Pthread;OpenCL;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.","Latency","","Datatypes;Dynamic process creation","Yes, compatibility is very important for me.","3"
"2019/04/02 7:02:20 AM AST","Other","Germany","6","3","C/C++;Python","more than 10 years","more than 10 years","System software development (OS, runtime library, communication library, etc.)","Research and development on system software (OS and/or runtime library)","I read only the chapters of interest for my work.","I read the MPI standard document.;I had lecture(s) at school.","","ParaStation MPI","I like to use it.","I read the MPI Standard document (web/book).","Performance tuning","","","","","Always","","No","","","","","","","5"
"2019/04/02 7:46:03 AM AST","College/University","United Kingdom","4","4","Fortran 90 or newer","between 5 and 10 years","between 5 and 10 years","Numerical application and/or library","Parallelization of sequential program(s)","I have not read it, but I plan to.","trial, error and google","","MPICH;Open MPI;Intel MPI","I have no special reason.","I search the Internet (Google / Stack Overflow).","Performance tuning","One-sided communications;Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","I have nobody to ask.","Mostly","No, MPI calls are scattered in my programs.","OpenMP;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","Process topologies;Dynamic process creation","Yes, compatibility is very important for me.","3"
"2019/04/02 7:55:07 AM AST","Governmental institute","Germany","6","5","Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Parallel Programming with MPI;MPI: The Complete Reference","Open MPI;Intel MPI;IBM MPI (BG/Q, PE, Spectrum);NEC MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","Persistent communication","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread);PMPI interface","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED;MPI_THREAD_SERIALIZED;MPI_THREAD_MULTIPLE","I have no obstacles.","Mostly","Yes, to minimize the changes of communication API.","OpenMP;OpenACC;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Latency","Latency hiding (including asynchronous completion);Resilience (fault tolerance);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","There are no unnecessary features","API should be clearly versioned.","3"
"2019/04/02 7:58:02 AM AST","College/University","United Kingdom","6","3","C/C++;Java;Python;Perl","more than 10 years","between 5 and 10 years","Research software development","Research and development of application(s);Research and development software tool(s);Parallelization of sequential program(s);Performance tuning of MPI program(s)","No, and I will not read it.","Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","I have never read any MPI books","MPICH;Open MPI;Intel MPI;HPE MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).","Domain decomposition","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","No, MPI calls are scattered in my programs.","OpenMP;Pthread;OpenACC;CUDA","Yes but ""premature optimisation is the root of all evil"" - i.e. it's good enough so better investing time elsewhere","Low-level communication layer provided by vendor (Verbs, DCMF, ...).","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","There are no unnecessary features","Yes, compatibility is very important for me.","2"
"2019/04/02 7:59:07 AM AST","College/University","Germany","4","3","C/C++","between 2 and 5 years","less than 2 years","Numerical application and/or library","Research and development of application(s)","I have not read it, but I plan to.","I had lecture(s) at school.","I have never read any MPI books","Open MPI","I have no special reason.","I read the MPI Standard document (web/book).","Performance tuning","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","Point-to-point communications;Collective communications;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE","Too complicated and hard to understand.","Sometimes","No, MPI calls are scattered in my programs.","OpenMP","I do not know how to find bottlenecks.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","There are no unnecessary features","I do not know or I do not care.","3"
"2019/04/02 8:02:53 AM AST","Other","Germany","5","4","C/C++;Python","more than 10 years","between 5 and 10 years","Numerical application and/or library;Tool development (performance tuning, debugging, etc.)","Research and development of application(s);Debugging MPI programs","I read only the chapters of interest for my work.","I read articles found on Internet.","","Open MPI;MVAPICH;Intel MPI","","","Debugging","Dynamic process creation;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);Persistent communications","","Too complicated and hard to understand.","Mostly","Yes, to minimize the changes of communication API.","OpenMP","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","","Latency","","","API should be clearly versioned.",""
"2019/04/02 8:03:24 AM AST","College/University","Germany","4","2","C/C++","between 2 and 5 years","less than 2 years","System software development (OS, runtime library, communication library, etc.);Numerical application and/or library;Visualization","Research and development of application(s)","","Other lectures or tutorials (workplace, conference).","","Open MPI","I was said to use it.","I read online documents (such as man pages).","Algorithm design","Dynamic process creation;PMPI interface","Collective communications;Communicator operations (split, duplicate, and so on)","MPI_THREAD_SINGLE","I have nobody to ask.","Sometimes","No, my program is too small to do that.","No","","I am not investigating any alternatives.","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","","There are no unnecessary features","Yes, compatibility is very important for me.","2"
"2019/04/02 8:17:52 AM AST","Governmental institute","Germany","5","3","Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I read the MPI standard document.","I have never read any MPI books","MPICH;Intel MPI;IBM MPI (BG/Q, PE, Spectrum)","I am familiar with it.","I read the MPI Standard document (web/book).","Domain decomposition","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);One-sided communications;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","No, MPI calls are scattered in my programs.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","","MPI is providing all the communication semantics required by my application","Dynamic process creation","Yes, compatibility is very important for me.","1"
"2019/04/02 8:20:27 AM AST","College/University","Austria","4","2","C/C++","more than 10 years","between 2 and 5 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I had lecture(s) at school.","I have never read any MPI books","Intel MPI","I like to use it.","I read the MPI Standard document (web/book).;I search the Internet (Google / Stack Overflow).","Debugging","Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_FUNNELED;MPI_THREAD_MULTIPLE","I do not like the API.","Mostly","Yes, to minimize the changes of communication API.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.","MPI provides all semantics I need","Another API which is easier and/or simpler to use;MPI is providing all the communication semantics required by my application","Dynamic process creation","I prefer to have new API which is simpler and/or easier-to-use.","4"
"2019/04/02 8:53:33 AM AST","Software vendor","United Kingdom","5","3","C/C++;Fortran 90 or newer","more than 10 years","less than 2 years","Numerical application and/or library","Research and development of application(s);Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Using MPI","Open MPI;Intel MPI;IBM MPI (BG/Q, PE, Spectrum)","I am familiar with it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I ask colleagues.","Debugging","Dynamic process creation;Persistent communication","Point-to-point communications;Collective communications","I have never called MPI_INIT_THREAD","I have no obstacles.","Sometimes","No, my program is too small to do that.","No","No, my MPI programs are well-tuned.","A Domain Specific Language (DSL).","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","MPI is providing all the communication semantics required by my application","There are no unnecessary features","Yes, compatibility is very important for me.","3"
"2019/04/02 9:16:54 AM AST","College/University","Germany","5","4","Fortran 90 or newer;Julia","more than 10 years","between 2 and 5 years","Numerical application and/or library","Research and development software tool(s);Parallelization of sequential program(s);Performance tuning of MPI program(s)","","I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","I have never read any MPI books","Intel MPI","I like to use it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).","Algorithm design","One-sided communications;Dynamic process creation;Persistent communication;MPI with OpenMP (or multithread);PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on)","I do not know or I do not care.","I do not like the API.","Sometimes","Yes, to minimize the changes of communication API.","OpenMP","I think there is room but I do not know how to tune it.","A framework or library using MPI.;A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Latency","Resilience (fault tolerance)","One-sided communication","I prefer to have new API which is simpler and/or easier-to-use.","4"
"2019/04/02 9:17:40 AM AST","College/University","United States","6","4","Fortran 90 or newer;Java;Python","between 5 and 10 years","between 2 and 5 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","Parallel Programming with MPI;Using MPI;MPI: The Complete Reference","MPICH;Open MPI;Intel MPI","I am familiar with it.","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Domain decomposition","Dynamic process creation;PMPI interface","Collective communications;MPI datatypes;Persistent communications","I have never called MPI_INIT_THREAD","I have nobody to ask.","Sometimes","Yes, to minimize the changes of communication API.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Latency","Latency hiding (including asynchronous completion)","There are no unnecessary features","I prefer to have new API for better performance.","3"
"2019/04/02 10:39:42 AM AST","Software vendor","Germany","5","2","C/C++;Python","between 5 and 10 years","less than 2 years","Tool development (performance tuning, debugging, etc.)","Research and development of application(s);Research and development software tool(s)","","Other lectures or tutorials (workplace, conference).","","MPICH;Open MPI;IBM MPI (BG/Q, PE, Spectrum)","I have no special reason.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Implementation issue workaround","Communicator operations (split, duplicate, and so on);One-sided communications;Dynamic process creation;Persistent communication","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread);PMPI interface","I do not know or I do not care.","","Sometimes","Yes, to minimize the changes of communication API.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","","","MPI is providing all the communication semantics required by my application","","I prefer to have new API for better performance.","4"
"2019/04/02 10:45:15 AM AST","College/University","Germany","5","3","C/C++","between 5 and 10 years","between 2 and 5 years","Visualization","Research and development software tool(s)","I have not read it, but I plan to.","I had lecture(s) at school.;I read articles found on Internet.","","MPICH;Open MPI;Cray MPI","I could not have any choice (the one provided by a vendor).","I ask colleagues.;I search the Internet (Google / Stack Overflow).","Algorithm design","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","I do not know or I do not care.","Undocumented behavior","Mostly","Yes, using templates for type safety and for transportation of own classes","OpenMP","I think there is room but I do not know how to tune it.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","There are no unnecessary features","I do not know or I do not care.","2"
"2019/04/02 11:12:24 AM AST","Other","Spain","5","3","Fortran 90 or newer","between 5 and 10 years","between 5 and 10 years","Tool development (performance tuning, debugging, etc.)","Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","I have never read any MPI books","MPICH;Open MPI;Intel MPI","I was said to use it.","I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Finding appropriate MPI routines","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);One-sided communications;MPI with OpenMP (or multithread)","I do not know or I do not care.","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","OpenMP","Yes, we are working on it.","I am not investigating any alternatives.","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Latency hiding (including asynchronous completion)","There are no unnecessary features","I do not know or I do not care.","3"
"2019/04/02 11:14:10 AM AST","Software vendor","Germany","5","3","C/C++","more than 10 years","less than 2 years","Numerical application and/or library;Visualization;Tool development (performance tuning, debugging, etc.)","Research and development of application(s);Performance tuning of MPI program(s);Debugging MPI programs","I read only the chapters of interest for my work.","I read articles found on Internet.","","MPICH","I have no special reason.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","One-sided communications;PMPI interface","Point-to-point communications;Collective communications;MPI with OpenMP (or multithread)","MPI_THREAD_SERIALIZED","I have nobody to ask.","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","Datatypes","API should be clearly versioned.","4"
"2019/04/02 11:24:15 AM AST","Governmental institute","Netherlands","5","5","C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer;Python","more than 10 years","more than 10 years","System software development (OS, runtime library, communication library, etc.);Numerical application and/or library","Support for research","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","Parallel Programming with MPI;Using MPI;MPI: The Complete Reference","MPICH;Open MPI;Intel MPI","I am familiar with it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).","Implementation issue workaround","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","I have no obstacles.","Mostly","No, my program is too small to do that.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.;A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","MPI is providing all the communication semantics required by my application","Dynamic process creation","Yes, compatibility is very important for me.","4"
"2019/04/02 3:43:12 PM AST","Software vendor","Germany","4","4","C/C++","more than 10 years","between 5 and 10 years","System software development (OS, runtime library, communication library, etc.);Parallel language (incl. domain specific language)","Research and development of application(s);Research and development on system software (OS and/or runtime library)","I read only the chapters of interest for my work.","I read the MPI standard document.;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Using MPI","MPICH;Open MPI;MVAPICH;Intel MPI;ParaStation MPI","I like to use it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Performance tuning","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on)","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","Too many routines.","Sometimes","No, my program is too small to do that.","OpenMP;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Resilience (fault tolerance)","","Yes, compatibility is very important for me.","3"
"2019/04/02 3:54:22 PM AST","Governmental institute","Germany","6","5","C/C++;Python","more than 10 years","between 5 and 10 years","Numerical application and/or library","Research and development software tool(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).","I have never read any MPI books","MPICH;Open MPI;Intel MPI;HPE MPI","I have no special reason.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Algorithm design","PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","I have no obstacles.","Mostly","Yes, to minimize the changes of communication API.","OpenMP","Yes, based on regular benchmarking other people in my team do the tuning.","GASPI","Latency","Latency hiding (including asynchronous completion)","There are no unnecessary features","API should be clearly versioned.","3"
"2019/04/02 5:09:15 PM AST","College/University","United Kingdom","6","6","Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s)","","Other lectures or tutorials (workplace, conference).","I have never read any MPI books","MPICH;Open MPI;MVAPICH;Intel MPI;Cray MPI","I have no special reason.","I read the MPI Standard document (web/book).;I ask colleagues.","Algorithm design","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread);MPI-I/O, Shared Memory","MPI_THREAD_SERIALIZED","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","Yes, to allow a serial implementation of the application when MPI is not readily  available","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.;A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","MPI_Comm_ifree and similar would make life simpler. But most needed is something more subtle than MPI_Abort for handling errors in applications. At the very least a portable way to make sure the error message actually gets to the user before the abort kicks in. To be clear I am NOT talking about errors within MPI, I am talking about MPI providing cleaner mechanisms to deal with application level errors","","Dynamic process creation","Yes, compatibility is very important for me.","1"
"2019/04/02 6:35:14 PM AST","Governmental institute","Germany","5","5","Fortran (older one than Fortran 90);Fortran 90 or newer;Python","between 5 and 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","MPICH;Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Performance tuning","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes","I have never called MPI_INIT_THREAD","I have no obstacles.","Sometimes","Yes, but I have no special reason for doing that.","No","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Latency hiding (including asynchronous completion)","One-sided communication;Dynamic process creation","I prefer to have new API for better performance.","3"
"2019/04/03 3:08:24 AM AST","College/University","Germany","4","3","C/C++;Python","more than 10 years","between 2 and 5 years","research","researcher","I read only the chapters of interest for my work.","I read articles found on Internet.","","MPICH;Open MPI","I have no special reason.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Performance tuning","MPI with OpenMP (or multithread)","MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE","I have nobody to ask.","Sometimes","No, MPI calls are scattered in my programs.","OpenMP","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","I am not investigating any alternatives.","Multi-threading support","MPI is providing all the communication semantics required by my application","There are no unnecessary features","I do not know or I do not care.","3"
"2019/04/03 4:46:44 AM AST","Governmental institute","Germany","6","4","C/C++;Python","more than 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s);Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","Open MPI","I like to use it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).","Algorithm design","Dynamic process creation;Persistent communication","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on)","MPI_THREAD_SERIALIZED;MPI_THREAD_MULTIPLE","I have no obstacles.","Mostly","Yes, to minimize the changes of communication API.","OpenMP","I think there is room but I do not know how to tune it.","GASPI / GPI2","Multi-threading support","MPI is providing all the communication semantics required by my application","Datatypes;Dynamic process creation;Error handlers","API should be clearly versioned.","3"
"2019/04/03 5:11:22 AM AST","College/University","Germany","4","5","C/C++;Python","more than 10 years","between 2 and 5 years","Numerical application and/or library","Research and development of application(s);Research and development software tool(s);Debugging MPI programs","I read only the chapters of interest for my work.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","I have never read any MPI books","MPICH;Open MPI;Intel MPI;Cray MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).","Debugging","Persistent communication","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;Dynamic process creation","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED","I have no obstacles.","Never","Make standard operations easier","No","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","One-sided communication","API should be clearly versioned.","2"
"2019/04/03 5:17:41 AM AST","Software vendor","Germany","5","3","C/C++","more than 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).","","Intel MPI;Cray MPI;IBM MPI (BG/Q, PE, Spectrum)","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).","","Communicator operations (split, duplicate, and so on);Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications","I have never called MPI_INIT_THREAD;I do not know or I do not care.","I have no obstacles.;MPI should allow doing in-place operations by specifying identical pointers for send and receive buffer","I rely on the default ‘Errors abort’ error handling","Yes, but I have no special reason for doing that.","OpenMP","I think there is room but I do not know how to tune it.","A framework or library using MPI.","Multi-threading support","Latency hiding (including asynchronous completion);Endpoints (multi-thread, sessions);Need a way to tell when processes first go out of sync.","","API should be clearly versioned.","3"
"2019/04/03 5:29:28 AM AST","Software vendor","Germany","5","5","C/C++;Python","more than 10 years","more than 10 years","System software development (OS, runtime library, communication library, etc.);Tool development (performance tuning, debugging, etc.)","Research and development on system software (OS and/or runtime library);Research and development software tool(s)","I read most of it.","I read the MPI standard document.;I read book(s).;I read articles found on Internet.","Parallel Programming with MPI;Using MPI","ParaStation MPI","I like to use it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I know almost all MPI routines.","Performance tuning","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;Dynamic process creation;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED;MPI_THREAD_SERIALIZED;MPI_THREAD_MULTIPLE","I have no obstacles.","Mostly","Yes, to minimize the changes of communication API.","OpenMP;Pthread;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","Low-level communication layer provided by vendor (Verbs, DCMF, ...).","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Resilience (fault tolerance);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","There are no unnecessary features","API should be clearly versioned.","3"
"2019/04/03 5:30:28 AM AST","Governmental institute","Germany","5","5","C/C++;Python","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s);Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).;Other lectures or tutorials (workplace, conference).","","MPICH;Open MPI;Intel MPI","I like to use it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Performance tuning","PMPI interface","Point-to-point communications;Collective communications;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED;MPI_THREAD_SERIALIZED;MPI_THREAD_MULTIPLE","","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","OpenMP;GASPI","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","GASPI","","Latency hiding (including asynchronous completion)","Dynamic process creation","I prefer to have new API for better performance.","3"
"2019/04/03 6:43:12 AM AST","Private research institute","Germany","5","5","C/C++;Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library;Tool development (performance tuning, debugging, etc.)","Research and development of application(s);Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Using MPI;MPI: The Complete Reference","Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Domain decomposition","Dynamic process creation;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED","Too many routines.","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","OpenMP;MPI-3 shared memory windows","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","MPI is providing all the communication semantics required by my application","","I prefer to have new API which is simpler and/or easier-to-use.","3"
"2019/04/03 7:05:04 AM AST","College/University","Germany","4","2","C/C++","between 5 and 10 years","less than 2 years","Numerical application and/or library","Research and development of application(s);Parallelization of sequential program(s)","I have not read it, but I plan to.","Other lectures or tutorials (workplace, conference).","","Open MPI","I have no special reason.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes","I do not know or I do not care.","I have no obstacles.","Never","Yes, to minimize the changes of communication API.","No","I do not know if there is room for performance tuning.","A framework or library using MPI.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","There are no unnecessary features","API should be clearly versioned.","3"
"2019/04/03 7:05:25 AM AST","College/University","United Kingdom","4","3","Python","more than 10 years","less than 2 years","Big data","Research and development software tool(s)","I have not read it, but I plan to.","I read book(s).;I read articles found on Internet.","Using MPI;Using Advanced MPI","MPICH;Open MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","Persistent communication;PMPI interface","Point-to-point communications;Collective communications","I have never called MPI_INIT_THREAD","I have nobody to ask.","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","No","I do not have (know) tools to find performance bottlenecks.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","MPI provides all semantics I need","I would like to increase the maximum number of communicators.","Process topologies;Dynamic process creation","I do not know or I do not care.","3"
"2019/04/03 7:49:44 AM AST","College/University","United Kingdom","5","4","C/C++;bash, R","more than 10 years","between 5 and 10 years","System software development (OS, runtime library, communication library, etc.);Visualization;Tool development (performance tuning, debugging, etc.);Applications","Research and development of application(s);Research and development software tool(s)","I read only the chapters of interest for my work.","I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Parallel Programming with MPI;Using MPI;Parallel Programming in C with MPI and OpenMP;MPI: The Complete Reference;Introduction to Parallel Programming by P Pacheco","MPICH;Open MPI;MVAPICH;Intel MPI;Cray MPI","I have no special reason.","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Algorithm design","Persistent communication","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED;MPI_THREAD_SERIALIZED","Too many routines.;Too complicated and hard to understand.","","No, MPI calls are scattered in my programs.","OpenMP","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A framework or library using MPI.;A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).;A Domain Specific Language (DSL).","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Resilience (fault tolerance);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.);Another API which is easier and/or simpler to use","There are no unnecessary features","API should be clearly versioned.","5"
"2019/04/03 9:17:34 AM AST","Governmental institute","Germany","6","5","C/C++;Java;Python","between 5 and 10 years","between 2 and 5 years","Numerical application and/or library","Research and development of application(s);Parallelization of sequential program(s)","I read most of it.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).","Using MPI","MPICH;Open MPI;MVAPICH;Intel MPI;Cray MPI","I have no special reason.","I read the MPI Standard document (web/book).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Domain decomposition","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;Persistent communication;MPI with OpenMP (or multithread);PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications","MPI_THREAD_MULTIPLE","I have no obstacles.","Never","Yes, to minimize the changes of communication API.","OpenMP;CUDA;Intel TBB","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","HPX","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","There are no unnecessary features","Yes, compatibility is very important for me.","4"
"2019/04/03 9:59:26 AM AST","Private research institute","France","5","5","C/C++;Fortran 90 or newer","between 5 and 10 years","between 5 and 10 years","Numerical application and/or library","Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","No, and I will not read it.","I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Parallel Programming with MPI","MPICH;Open MPI;MVAPICH;Intel MPI","I like to use it.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","I have no obstacles.","Mostly","I am not the main architect of the codes, so I do the same as what is already done","OpenMP;OpenACC;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","MPI provides all semantics I need","","One-sided communication;Communicator and group management;Dynamic process creation","I do not know or I do not care.","3"
"2019/04/03 10:10:08 AM AST","College/University","France","5","3","Fortran 90 or newer;Python","more than 10 years","between 2 and 5 years","Big data;Visualization;Astronomical simulations","Research","I read only the chapters of interest for my work.","I read the MPI standard document.;I read articles found on Internet.","","Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Domain decomposition","Dynamic process creation","Point-to-point communications;Collective communications;MPI datatypes","I have never called MPI_INIT_THREAD","No appropriate lecture / book / info.;I have nobody to ask.","Sometimes","No, MPI calls are scattered in my programs.","No","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","","","There are no unnecessary features","Yes, compatibility is very important for me.","4"
"2019/04/03 11:19:52 AM AST","","Austria","5","2","C/C++;Python;Octave","more than 10 years","less than 2 years","Parallel language (incl. domain specific language);Numerical application and/or library;AI (Deep Learning);Big data","Research and development of application(s)","I read most of it.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).","","Open MPI","","","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","","","I do not like the API.","","","OpenMP;CUDA","","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","","","","I do not know or I do not care.",""
"2019/04/03 4:06:54 PM AST","College/University","United Kingdom","5","5","C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer;Java","more than 10 years","more than 10 years","System software development (OS, runtime library, communication library, etc.);Numerical application and/or library;Tool development (performance tuning, debugging, etc.)","Research and development on system software (OS and/or runtime library);Research and development software tool(s);Parallelization of sequential program(s);Performance tuning of MPI program(s)","I read all.","I read the MPI standard document.;I read book(s).;I read articles found on Internet.","Parallel Programming with MPI;Using MPI;MPI: The Complete Reference","MPICH;Open MPI;MVAPICH","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).;I know almost all MPI routines.","Performance tuning","Persistent communication","Point-to-point communications;Collective communications;MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED;MPI_THREAD_SERIALIZED;MPI_THREAD_MULTIPLE","I have no obstacles.;Too many routines.","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","OpenMP;Pthread","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.;A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Multi-threading support","Latency hiding (including asynchronous completion);Endpoints (multi-thread, sessions);Resilience (fault tolerance);Another API which is easier and/or simpler to use","There are no unnecessary features","I prefer to have new API which is simpler and/or easier-to-use.","5"
"2019/04/04 3:40:15 AM AST","College/University","Luxembourg","6","4","Fortran 90 or newer;Python;Guile Scheme, R","more than 10 years","between 5 and 10 years","Parallel language (incl. domain specific language);Numerical application and/or library;Big data;Visualization","Research and development of application(s);Research and development software tool(s);Parallelization of sequential program(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).","I have never read any MPI books","Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Implementation issue workaround","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_FUNNELED","I have no obstacles.","Never","1) I make a special Fortran library (low level abstraction) 2) Create Scheme macros that do different things depending on the type of parellisation needed (high level abstraction)","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).;A Domain Specific Language (DSL).;I made my own DSL","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","OpenMP like pragma/comment calls that can easily be switched off when not needed. Of course, not needed in parallelisation aware languages like Fortran; which brings me to another point: ability to influence how MPI interfaces with co-arrays.","I do not know :)","Comnpatibility is important, but it is okay to delegate old API to a different module/header","5"
"2019/04/04 4:13:10 AM AST","College/University","Germany","4","4","C/C++","more than 10 years","between 2 and 5 years","System software development (OS, runtime library, communication library, etc.);Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","MPICH;Open MPI;Intel MPI;IBM MPI (BG/Q, PE, Spectrum)","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).;I ask colleagues.;I search the Internet (Google / Stack Overflow).;I know almost all MPI routines.","Performance tuning","PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes","I do not know or I do not care.","Unexpected running times of MPI routines such as slow MPI_Comm_create,...","Never","No, MPI calls are scattered in my programs.","No","I think there is room but I do not know how to tune it.","A framework or library using MPI.","The first communication seems to be very slow with many MPI implementations (IBM MPI, Intel MPI,...)","Sparse Alltoall routines","","Yes, compatibility is very important for me.","4"
"2019/04/04 8:51:07 AM AST","College/University","United Kingdom","5","5","C/C++;Fortran (older one than Fortran 90)","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).","Using MPI;MPI: The Complete Reference","MPICH;Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).","Debugging","Dynamic process creation;Persistent communication","Point-to-point communications;Collective communications;MPI with OpenMP (or multithread)","I do not know or I do not care.","I have no obstacles.","Sometimes","No, MPI calls are scattered in my programs.","No","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","I am not investigating any alternatives.","Bandwidth","MPI is providing all the communication semantics required by my application","One-sided communication;Communicator and group management;Process topologies;Dynamic process creation","Yes, compatibility is very important for me.","5"
"2019/04/04 9:34:58 AM AST","College/University","Germany","5","4","C/C++","between 5 and 10 years","between 2 and 5 years","Big data;Algorithms","Research and development of application(s)","I read only the chapters of interest for my work.","I read book(s).;I had lecture(s) at school.;I read articles found on Internet.","Parallel Programming with MPI","MPICH;Open MPI","I have no special reason.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).","Debugging","One-sided communications;Dynamic process creation;Persistent communication","Point-to-point communications;Collective communications;MPI datatypes","I have never called MPI_INIT_THREAD","I have no obstacles.","Never","No, MPI calls are scattered in my programs.","OpenMP","No, my MPI programs are well-tuned.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Latency hiding (including asynchronous completion);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","One-sided communication;Process topologies;Dynamic process creation;Error handlers","I prefer to have new API for better performance.","4"
"2019/04/05 4:36:24 AM AST","College/University","France","5","4","C/C++;Fortran 90 or newer;Python","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s)","No, and I will not read it.","I read articles found on Internet.","","MPICH;Open MPI;Intel MPI;IBM MPI (BG/Q, PE, Spectrum)","I am familiar with it.","I read online documents (such as man pages).;I ask colleagues.","Performance tuning","Communicator operations (split, duplicate, and so on);Dynamic process creation;Persistent communication;PMPI interface","Collective communications;MPI datatypes;One-sided communications","I have never called MPI_INIT_THREAD","Too many routines.;No appropriate lecture / book / info.","Never","No, MPI calls are scattered in my programs.","No","No, my MPI programs are well-tuned.","I am not investigating any alternatives.","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","MPI is providing all the communication semantics required by my application","Error handlers","I do not know or I do not care.","4"
"2019/04/05 6:07:56 AM AST","College/University","Italy","5","5","Fortran 90 or newer","between 2 and 5 years","between 2 and 5 years","Parallel language (incl. domain specific language)","Research and development of application(s);Research and development on system software (OS and/or runtime library)","I read only the chapters of interest for my work.","I had lecture(s) at school.","Parallel Programming with MPI","MPICH;Open MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).","Domain decomposition","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes","I do not know or I do not care.","Too many routines.","Sometimes","Yes, but I have no special reason for doing that.","OpenMP","No, my MPI programs are well-tuned.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Bandwidth","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","Dynamic process creation","API should be clearly versioned.","5"
"2019/04/05 6:10:45 AM AST","College/University","Austria","5","4","C/C++","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s)","","I read the MPI standard document.;I read book(s).;I had lecture(s) at school.","Parallel Programming with MPI;Using MPI;MPI: The Complete Reference","Open MPI","I like to use it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Performance tuning","Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","I have no obstacles.","Sometimes","No, MPI calls are scattered in my programs.","OpenMP;OpenACC;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","MPI provides all semantics I need","","There are no unnecessary features","I prefer to have new API for better performance.","3"
"2019/04/05 6:11:04 AM AST","College/University","Austria","4","2","C/C++","between 2 and 5 years","less than 2 years","Numerical application and/or library","Research and development of application(s)","I have not read it, but I plan to.","I had lecture(s) at school.","","Open MPI","I have no special reason.","I search the Internet (Google / Stack Overflow).","Algorithm design","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);Dynamic process creation;PMPI interface","MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","No appropriate lecture / book / info.","Sometimes","No, MPI calls are scattered in my programs.","CUDA","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","Dynamic process creation","Yes, compatibility is very important for me.","3"
"2019/04/05 6:11:53 AM AST","College/University","Austria","6","6","Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","I read articles found on Internet.","I have never read any MPI books","Open MPI;Intel MPI","I like to use it.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Performance tuning","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","I have no obstacles.","Sometimes","No, MPI calls are scattered in my programs.","OpenMP;Pthread","No, my MPI programs are well-tuned.","A framework or library using MPI.","Latency","Latency hiding (including asynchronous completion)","There are no unnecessary features","Yes, compatibility is very important for me.","3"
"2019/04/05 6:12:43 AM AST","College/University","Germany","5","5","C/C++;Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library;Peformance analysis","Performance analysis","I read only the chapters of interest for my work.","I read the MPI standard document.;I read articles found on Internet.","Using MPI","Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).","Algorithm design","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","Too complicated and hard to understand.;Generally over-engineered IMO","Never","No, MPI calls are scattered in my programs.","OpenMP","No, my MPI programs are well-tuned.","I am not investigating any alternatives.","MPI provides all semantics I need","Latency hiding (including asynchronous completion);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.);Another API which is easier and/or simpler to use","Dynamic process creation;Error handlers","I prefer to have new API which is simpler and/or easier-to-use.","4"
"2019/04/05 6:13:28 AM AST","College/University","Germany","3","2","C/C++;Julia","between 5 and 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s)","No, and I will not read it.","I had lecture(s) at school.;I read articles found on Internet.","","MPICH;Open MPI;MVAPICH","I have no special reason.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Communicator operations (split, duplicate, and so on);One-sided communications;Dynamic process creation;Persistent communication;PMPI interface","Collective communications;MPI datatypes","I do not know or I do not care.","I have nobody to ask.","Never","No, MPI calls are scattered in my programs.","No","I do not know if there is room for performance tuning.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","Process topologies","Yes, compatibility is very important for me.","2"
"2019/04/05 6:14:40 AM AST","College/University","France","5","4","C/C++;Fortran 90 or newer;Python","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s)","No, and I will not read it.","I read book(s).","MPI: The Complete Reference","Open MPI;Intel MPI","I like to use it.","I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED","I have no obstacles.","Mostly","Yes, to minimize the changes of communication API.","OpenMP;OpenACC","I do not have (know) tools to find performance bottlenecks.","A framework or library using MPI.","Much better error handling","Latency hiding (including asynchronous completion);Resilience (fault tolerance)","","I prefer to have new API which is simpler and/or easier-to-use.","2"
"2019/04/05 6:17:22 AM AST","Private research institute","Italy","5","4","Python","between 2 and 5 years","less than 2 years","Parallel language (incl. domain specific language);Numerical application and/or library;AI (Deep Learning)","Research and development of application(s);Research and development software tool(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I had lecture(s) at school.;I read articles found on Internet.","Pacheco","MPICH;Open MPI","I have no special reason.","I search the Internet (Google / Stack Overflow).","Algorithm design","PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;One-sided communications","I have never called MPI_INIT_THREAD","I have nobody to ask.","Always","Yes, to minimize the changes of communication API.","","I think there is room but I do not know how to tune it.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","There are no unnecessary features","API should be clearly versioned.","4"
"2019/04/05 6:18:12 AM AST","College/University","Austria","6","4","Fortran 90 or newer;Python","more than 10 years","between 5 and 10 years","Theoretical/computational condensed matter physics","Research and development of application(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).","Using MPI","MPICH;Open MPI;Intel MPI","I am familiar with it.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Communicator operations (split, duplicate, and so on);Dynamic process creation;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","I have no obstacles.","Mostly","No, MPI calls are scattered in my programs.","OpenMP","I have no chance to investigate.","I am not investigating any alternatives.","Latency","Latency hiding (including asynchronous completion);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","There are no unnecessary features","Yes, compatibility is very important for me.","3"
"2019/04/05 6:18:14 AM AST","College/University","Germany","6","3","Fortran (older one than Fortran 90)","more than 10 years","between 2 and 5 years","Numerical application and/or library;Visualization;Tool development (performance tuning, debugging, etc.)","Research and development of application(s)","I read only the chapters of interest for my work.","I read articles found on Internet.;I have not learned MPI.","I have never read any MPI books","Intel MPI","I like to use it.","I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Domain decomposition","Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes","I have never called MPI_INIT_THREAD","No appropriate lecture / book / info.","Mostly","Yes, to minimize the changes of communication API.","No","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","There are no unnecessary features","Yes, compatibility is very important for me.","3"
"2019/04/05 6:28:59 AM AST","Private research institute","Italy","3","2","C/C++;Python","less than 2 years","less than 2 years","scientific software development","Research and development of application(s)","I read only the chapters of interest for my work.","I had lecture(s) at school.","MPI: A Message-Passing Interface Standard Version 3.1","Open MPI","I was said to use it.","I read the MPI Standard document (web/book).;I search the Internet (Google / Stack Overflow).","Algorithm design","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes","I do not know or I do not care.","Too complicated and hard to understand.","Never","No, my program is too small to do that.","OpenMP","I do not know if there is room for performance tuning.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","There are no unnecessary features","Yes, compatibility is very important for me.","4"
"2019/04/05 6:33:23 AM AST","College/University","Austria","5","2","Fortran 90 or newer;Python","more than 10 years","less than 2 years","Numerical application and/or library","Research and development of application(s)","No, and I will not read it.","I read the MPI standard document.","I have never read any MPI books","MPICH;Open MPI","I have no special reason.","I read online documents (such as man pages).","Algorithm design","","Collective communications;Communicator operations (split, duplicate, and so on);One-sided communications;Persistent communications;PMPI interface","I do not know or I do not care.","Too complicated and hard to understand.;I have nobody to ask.","Always","No, MPI calls are scattered in my programs.","No","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.","Bandwidth","","","API should be clearly versioned.","4"
"2019/04/05 6:47:47 AM AST","College/University","United States","5","4","C/C++;Python","more than 10 years","more than 10 years","System software development (OS, runtime library, communication library, etc.);Numerical application and/or library;AI (Deep Learning);Tool development (performance tuning, debugging, etc.)","Research and development of application(s);Research and development software tool(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","MPICH;Open MPI;MVAPICH;Intel MPI;Cray MPI","I like to use it.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","","Point-to-point communications;Collective communications;MPI datatypes;One-sided communications;Persistent communications;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","I have no obstacles.","Sometimes","Yes, to minimize the changes of communication API.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Latency","Latency hiding (including asynchronous completion)","","I prefer to have new API which is simpler and/or easier-to-use.","4"
"2019/04/05 6:52:07 AM AST","College/University","Germany","6","6","C/C++;Python","more than 10 years","more than 10 years","Numerical application and/or library;AI (Deep Learning)","Research and development of application(s)","I read all.","I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","Parallel Programming with MPI;Using MPI","MPICH;Open MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).;I read online documents (such as man pages).","Algorithm design","PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on)","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","I have no obstacles.","Always","Yes, to minimize the changes of communication API.","OpenMP;OpenACC;CUDA","No, my MPI programs are well-tuned.","I am not investigating any alternatives.","Latency","Resilience (fault tolerance)","There are no unnecessary features","I prefer to have new API for better performance.","5"
"2019/04/05 7:02:36 AM AST","College/University","Austria","2","2","Java;Python;R, Perl","more than 10 years","between 5 and 10 years","Bioinformatics","Data analysis","I have not read it, but I plan to.","I read articles found on Internet.","","Open MPI","I could not have any choice (the one provided by a vendor).","I search the Internet (Google / Stack Overflow).","Algorithm design","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;Dynamic process creation;Persistent communication;PMPI interface","MPI with OpenMP (or multithread)","I do not know or I do not care.","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","no","OpenMP;Pthread;OpenCL;CUDA","I have no chance to investigate.","I am not investigating any alternatives.","Multi-threading support","","","I prefer to have new API for better performance.","4"
"2019/04/05 7:12:59 AM AST","College/University","Austria","5","3","C/C++","between 5 and 10 years","between 2 and 5 years","Parallel language (incl. domain specific language);Big data","Research and development of application(s);Parallelization of sequential program(s)","I read only the chapters of interest for my work.","I had lecture(s) at school.","I have never read any MPI books","Open MPI","I have no special reason.","I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","","Never","No, MPI calls are scattered in my programs.","OpenMP","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A framework or library using MPI.","MPI provides all semantics I need","Another API which is easier and/or simpler to use","Communicator and group management;Collective operations;Process topologies;Dynamic process creation","I prefer to have new API for better performance.","5"
"2019/04/05 7:14:06 AM AST","College/University","Austria","5","5","C/C++","more than 10 years","between 2 and 5 years","","Reaserch (Physics)","I read only the chapters of interest for my work.","I read the MPI standard document.","I have never read any MPI books","Open MPI","I like to use it.","I ask colleagues.","Algorithm design","","Collective communications;Dynamic process creation;MPI with OpenMP (or multithread)","I do not know or I do not care.","I have no obstacles.","Sometimes","Yes, to minimize the changes of communication API.","OpenMP","I think there is room but I do not know how to tune it.","I am not investigating any alternatives.","Multi-threading support","MPI is providing all the communication semantics required by my application","","I do not know or I do not care.","4"
"2019/04/05 7:19:26 AM AST","College/University","Germany","5","4","Fortran 90 or newer;Python","more than 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","I have never read any MPI books","Open MPI;Intel MPI;Cray MPI","I have no special reason.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on)","MPI_THREAD_SINGLE","Too complicated and hard to understand.;I do not like the API.","Mostly","Yes, to minimize the changes of communication API.","OpenMP","I have no chance to investigate.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Multi-threading support","Another API which is easier and/or simpler to use","Process topologies;Error handlers","I prefer to have new API which is simpler and/or easier-to-use.","2"
"2019/04/05 8:26:15 AM AST","College/University","Germany","5","4","C/C++;Fortran 90 or newer;Python","more than 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s);Research and development software tool(s)","","I read the MPI standard document.;I read book(s).","Parallel Programming with MPI;Parallel Programming in C with MPI and OpenMP","Open MPI;Intel MPI","I am familiar with it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Persistent communication","","","Too many routines.","Sometimes","No, MPI calls are scattered in my programs.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.;A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","MPI is providing all the communication semantics required by my application","Dynamic process creation","I prefer to have new API which is simpler and/or easier-to-use.","4"
"2019/04/05 8:42:39 AM AST","College/University","Austria","6","5","C/C++","more than 10 years","more than 10 years","Numerical application and/or library;Visualization","Research and development of application(s);Research and development software tool(s);Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Using MPI;MPI: The Complete Reference","MPICH;Open MPI;MVAPICH","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).","Algorithm design","Dynamic process creation;Persistent communication","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","I have no obstacles.","Sometimes","Yes, to extend the abstraction provided by MPI.","OpenMP;CUDA","Tuning employed when economically viable.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","There are no unnecessary features","Yes, compatibility is very important for me.","4"
"2019/04/05 9:40:30 AM AST","College/University","United Kingdom","6","6","C/C++;Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library","Parallelization of sequential program(s);Performance tuning of MPI program(s)","","","","Open MPI","I have no special reason.","","","","","","","","","","","","","","","",""
"2019/04/05 9:56:15 AM AST","College/University","Austria","5","3","C/C++;Python","between 5 and 10 years","between 2 and 5 years","Numerical application and/or library","Research and development of application(s);Research and development software tool(s);Parallelization of sequential program(s);Debugging MPI programs","I have not read it, but I plan to.","I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","I have never read any MPI books","MPICH;Open MPI;MVAPICH;Intel MPI;Cray MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Algorithm design","Dynamic process creation;Persistent communication;MPI with OpenMP (or multithread);PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes","I have never called MPI_INIT_THREAD","Too many routines.;No appropriate lecture / book / info.;Too complicated and hard to understand.","Sometimes","No, MPI calls are scattered in my programs.","No","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Resilience (fault tolerance);Another API which is easier and/or simpler to use","There are no unnecessary features","API should be clearly versioned.","3"
"2019/04/05 9:56:54 AM AST","College/University","Estonia","3","4","C/C++;Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s)","I read most of it.","I read the MPI standard document.;I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","Parallel Programming with MPI;Using MPI;Parallel Programming in C with MPI and OpenMP;MPI: The Complete Reference","MPICH;Open MPI;MVAPICH;Intel MPI;Cray MPI;Fujistu MPI;NEC MPI","I like to use it.","","Performance tuning","","Point-to-point communications;Collective communications;MPI datatypes;One-sided communications;Persistent communications;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","","Sometimes","No, MPI calls are scattered in my programs.","OpenMP;OpenACC;CUDA;CUDA Fortran","Yes, I know there is room for tuning but I do not have enough resources to do that.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).;Low-level communication layer provided by vendor (Verbs, DCMF, ...).","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","A simple API would be good, not everybody wants all the expressiveness in MPI","There are no unnecessary features","Compatibility is helpful because of the large codebase. ","3"
"2019/04/05 10:11:57 AM AST","College/University","Egypt","6","1","Fortran (older one than Fortran 90);Fortran 90 or newer","more than 10 years","less than 2 years","Numerical application and/or library","Research and Teaching","I have not read it, but I plan to.","Other lectures or tutorials (workplace, conference).","I have never read any MPI books","I do not know","I was said to use it.","I ask colleagues.","Algorithm design","Collective communications;Communicator operations (split, duplicate, and so on);One-sided communications;Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications","I have never called MPI_INIT_THREAD","I am too busy","Never","No, my program is too small to do that.","No","I do not know if there is room for performance tuning.","I am not investigating any alternatives.","Message injection rate","MPI is providing all the communication semantics required by my application","Error handlers","Yes, compatibility is very important for me.","3"
"2019/04/05 10:15:21 AM AST","College/University","Austria","5","3","C/C++;Python","between 5 and 10 years","between 2 and 5 years","Numerical application and/or library","Research and development of application(s);Performance tuning of MPI program(s);Debugging MPI programs","I read only the chapters of interest for my work.","I had lecture(s) at school.;I read articles found on Internet.","I have never read any MPI books","Open MPI;Intel MPI","I have no special reason.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","Dynamic process creation","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes","MPI_THREAD_SINGLE;I have never called MPI_INIT_THREAD","I have nobody to ask.","Never","Yes, to minimize the changes of communication API.","Pthread","I have no chance to investigate.","I am not investigating any alternatives.","","Latency hiding (including asynchronous completion)","Dynamic process creation;Error handlers","I prefer to have new API for better performance.","2"
"2019/04/05 11:35:56 AM AST","College/University","Italy","5","4","C/C++;Python","between 5 and 10 years","less than 2 years","Numerical application and/or library","Research and development software tool(s);Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).;I had lecture(s) at school.","Using MPI","Open MPI","I am familiar with it.","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Algorithm design","One-sided communications;Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_FUNNELED","I have no obstacles.","Always","Yes, to minimize the changes of communication API.","OpenMP;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","MPI is providing all the communication semantics required by my application","Error handlers","I prefer to have new API for better performance.","5"
"2019/04/05 12:51:57 PM AST","Private research institute","Germany","5","3","C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer;Python","more than 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s)","No, and I will not read it.","I read articles found on Internet.;I have not learned MPI.","","MPICH;Open MPI;Intel MPI","I was said to use it.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Communicator operations (split, duplicate, and so on);One-sided communications;Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications","I do not know or I do not care.","Too complicated and hard to understand.","I rely on the default ‘Errors abort’ error handling","Yes, but I have no special reason for doing that.","No","I do not know if there is room for performance tuning.","A framework or library using MPI.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","There are no unnecessary features","I prefer to have new API for better performance.","5"
"2019/04/05 1:43:30 PM AST","College/University","United States","5","5","C/C++;Python","between 2 and 5 years","between 2 and 5 years","Parallel language (incl. domain specific language);Numerical application and/or library","Research and development of application(s);Research and development software tool(s);Parallelization of sequential program(s)","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","introduction to high performance computing for scientists and engineers","Open MPI","I am familiar with it.","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);One-sided communications","MPI_THREAD_SINGLE","Too many routines.","Sometimes","No, my program is too small to do that.","No","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A framework or library using MPI.;A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","Datatypes;Communicator and group management;Process topologies;Dynamic process creation","API should be clearly versioned.","4"
"2019/04/05 2:07:44 PM AST","College/University","Austria","6","2","C/C++;Python","more than 10 years","less than 2 years","Numerical application and/or library;AI (Deep Learning);Image processing","Research and development of application(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I read articles found on Internet.","","MPICH;Open MPI","I have no special reason.","I read the MPI Standard document (web/book).","Finding appropriate MPI routines","PMPI interface","Point-to-point communications;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED","I have nobody to ask.","Mostly","No, my program is too small to do that.","OpenMP;OpenCL;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Multi-threading support","","There are no unnecessary features","API should be clearly versioned.","3"
"2019/04/06 3:06:25 PM AST","College/University","Poland","4","4","C/C++;Python","more than 10 years","between 5 and 10 years","Tool development (performance tuning, debugging, etc.)","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","","I had lecture(s) at school.;I read articles found on Internet.","Beginning MPI (An Introduction in C);Parallel Programming with MPI;Using MPI","Open MPI","I have no special reason.","I search the Internet (Google / Stack Overflow).","Algorithm design","One-sided communications;MPI with OpenMP (or multithread);PMPI interface","","I do not know or I do not care.","I have nobody to ask.","","No, MPI calls are scattered in my programs.","No","I have no chance to investigate.","I am not investigating any alternatives.","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","MPI is providing all the communication semantics required by my application","There are no unnecessary features","Yes, compatibility is very important for me.","3"
"2019/04/07 10:17:34 AM AST","College/University","Norway","5","4","C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer;Python","more than 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s);Performance tuning of MPI program(s);Debugging MPI programs","I read only the chapters of interest for my work.","I read book(s).;Other lectures or tutorials (workplace, conference).","Using MPI","Open MPI;Intel MPI","I am familiar with it.","I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Debugging","Persistent communication","Collective communications;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE","Too many routines.","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Bandwidth","Resilience (fault tolerance)","Datatypes","I prefer to have new API which is simpler and/or easier-to-use.","4"
"2019/04/07 10:17:59 AM AST","College/University","United Kingdom","5","4","C/C++;Fortran 90 or newer;Python","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s)","No, and I will not read it.","I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","Parallel Programming with MPI;Using MPI","MPICH;Open MPI;Intel MPI","I have no special reason.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes","I do not know or I do not care.","I have no obstacles.","Sometimes","No, MPI calls are scattered in my programs.","CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.;A Domain Specific Language (DSL).","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Resilience (fault tolerance);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","There are no unnecessary features","I do not know or I do not care.","2"
"2019/04/07 10:35:39 AM AST","College/University","Austria","3","2","Python","less than 2 years","less than 2 years","thermal physics and fluiddynamics","calculation of a heat storage modell","No, and I will not read it.","I had lecture(s) at school.","","I do not know","I was said to use it.","I ask colleagues.;I search the Internet (Google / Stack Overflow).","Implementation issue workaround","Collective communications;MPI datatypes;Dynamic process creation;PMPI interface","I have no idea","I do not know or I do not care.","Too complicated and hard to understand.","Never","Yes, but I have no special reason for doing that.","No","I think there is room but I do not know how to tune it.","I am not investigating any alternatives.","MPI provides all semantics I need","Another API which is easier and/or simpler to use","One-sided communication","I do not know or I do not care.","5"
"2019/04/07 10:42:28 AM AST","College/University","United Kingdom","6","4","C/C++","more than 10 years","between 5 and 10 years","Numerical application and/or library;Tool development (performance tuning, debugging, etc.)","Research and development of application(s);HPC Management","I read most of it.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).","I have never read any MPI books","Open MPI;MVAPICH;Intel MPI","I was said to use it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).","Debugging","Communicator operations (split, duplicate, and so on);Dynamic process creation;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes","MPI_THREAD_SINGLE","Too many routines.","Mostly","Sometimes, for the same reasons as subroutines in general","No","I think there is room but I do not know how to tune it.","I am not investigating any alternatives.","Multi-threading support","Endpoints (multi-thread, sessions)","Process topologies","Yes, compatibility is very important for me.","2"
"2019/04/07 11:40:00 AM AST","Governmental institute","Denmark","5","3","Fortran 90 or newer;Python","between 5 and 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I read book(s).;I read articles found on Internet.","Parallel Programming with MPI;Using MPI","MPICH;Open MPI;Intel MPI","I like to use it.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes","I have never called MPI_INIT_THREAD","I have no obstacles.","Sometimes","No, MPI calls are scattered in my programs.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","MPI is providing all the communication semantics required by my application","Dynamic process creation","I prefer to have new API for better performance.","3"
"2019/04/07 11:42:48 AM AST","College/University","United Kingdom","5","4","C/C++;Python","between 5 and 10 years","between 2 and 5 years","Parallel language (incl. domain specific language);Numerical application and/or library","Research and development of application(s);Research and development software tool(s);Parallelization of sequential program(s);Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","MPICH;Open MPI;Intel MPI;Cray MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Implementation issue workaround","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED","performance portable  implentation specific workarounds for bugs","Always","No, MPI calls are scattered in my programs.","OpenMP;CUDA;MPI + MPI","Yes, there is room for improvement. Justifying the developer time for the improvement can be challenging if the current performance is ""good enough"".","I am not investigating any alternatives.","Multi-threading support","","Datatypes;Dynamic process creation","Yes, compatibility is very important for me.","3"
"2019/04/07 1:11:57 PM AST","College/University","Sweden","5","4","C/C++","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I read book(s).;Other lectures or tutorials (workplace, conference).","I have never read any MPI books","Open MPI","I am familiar with it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Performance tuning","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_SERIALIZED","No reason to master it. If I propose using something fancy, I also have to demonstrate that it provides a performance or programmability benefit, while not degrading the implementation quality or performance on other MPI implementations.","Never","Yes, to minimize the changes of communication API.","OpenMP;OpenCL;CUDA","The application is latency bound, so even measuring at scale where a problem might exist is so hard it means we tackle other projects","I am not investigating any alternatives.","Latency","Latency hiding (including asynchronous completion)","Process topologies;Dynamic process creation","API should be clearly versioned.","2"
"2019/04/07 1:20:09 PM AST","College/University","United Kingdom","4","2","C/C++;Fortran 90 or newer;Python","between 2 and 5 years","less than 2 years","Numerical application and/or library;Big data","University Student","I read only the chapters of interest for my work.","I read the MPI standard document.;I had lecture(s) at school.;I read articles found on Internet.","","Open MPI;Intel MPI","I was said to use it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation;Persistent communication;MPI with OpenMP (or multithread);PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications","I have never called MPI_INIT_THREAD;I do not know or I do not care.","Too many routines.;Too complicated and hard to understand.","Sometimes","No, my program is too small to do that.","No","I think there is room but I do not know how to tune it.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","Communicator and group management;Process topologies;Dynamic process creation;Error handlers","I prefer to have new API which is simpler and/or easier-to-use.","3"
"2019/04/07 2:14:59 PM AST","College/University","Sweden","6","6","C/C++","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s);Management","I read most of it.","I read the MPI standard document.;I read book(s).;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Parallel Programming with MPI;Parallel Programming in C with MPI and OpenMP;MPI: The Complete Reference","MPICH;Open MPI;MVAPICH;Intel MPI;Cray MPI;IBM MPI (BG/Q, PE, Spectrum);Fujistu MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I search the Internet (Google / Stack Overflow).","Algorithm design","Dynamic process creation","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED;MPI_THREAD_MULTIPLE","Too many routines.;I do not like the API.","Mostly","Yes, to minimize the changes of communication API.","OpenMP;Pthread;OpenCL;CUDA;C++ threads","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","Low-level communication layer provided by vendor (Verbs, DCMF, ...).","Latency","Latency hiding (including asynchronous completion);Endpoints (multi-thread, sessions);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","Error handlers","I prefer to have new API for better performance.","4"
"2019/04/08 4:59:51 AM AST","College/University","Austria","1","1","Fortran (older one than Fortran 90)","less than 2 years","less than 2 years","Image processing;Visualization","use of programs for image analysis and reconstruction","","I have not learned MPI.","","Open MPI","I could not have any choice (the one provided by a vendor).","I do not write any","Other","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;Dynamic process creation;Persistent communication;PMPI interface","MPI with OpenMP (or multithread)","I do not know or I do not care.","I do not write any but use them","Mostly","I do not write programs","No","I do not know how to find bottlenecks.","I am not investigating any alternatives.","I do not know","I do not know","I do not know","Yes, compatibility is very important for me.","5"
"2019/04/08 5:02:32 AM AST","Governmental institute","Netherlands","5","2","Fortran 90 or newer;Python","between 2 and 5 years","less than 2 years","Numerical application and/or library;Big data;Visualization","Research and development of application(s)","No, and I will not read it.","I read articles found on Internet.","I have never read any MPI books","Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).","Debugging","PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes","MPI_THREAD_MULTIPLE","I have no obstacles.","Never","No, MPI calls are scattered in my programs.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","Process topologies;There are no unnecessary features","Yes, compatibility is very important for me.","3"
"2019/04/08 5:08:09 AM AST","College/University","Italy","5","4","Fortran 90 or newer","between 5 and 10 years","between 2 and 5 years","Numerical application and/or library","Research and development software tool(s)","No, and I will not read it.","I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","I have never read any MPI books","Open MPI;Intel MPI;Cray MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","Communicator operations (split, duplicate, and so on);Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","Too complicated and hard to understand.","Mostly","No, MPI calls are scattered in my programs.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Another API which is easier and/or simpler to use","Process topologies;Dynamic process creation","Yes, compatibility is very important for me.","3"
"2019/04/08 5:08:24 AM AST","College/University","Germany","5","5","C/C++;Fortran 90 or newer;Python","between 2 and 5 years","between 2 and 5 years","Parallel language (incl. domain specific language);Numerical application and/or library","Research and development of application(s);Research and development software tool(s);Performance tuning of MPI program(s);Debugging MPI programs","I read only the chapters of interest for my work.","I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","MPICH;Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Debugging","One-sided communications;Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","No appropriate lecture / book / info.;I do not like the API.","Mostly","Using boost::mpi","OpenMP;CUDA","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A framework or library using MPI.;A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).;HPX with MPI parcelport","Latency","Latency hiding (including asynchronous completion);Resilience (fault tolerance);Another API which is easier and/or simpler to use","One-sided communication;Dynamic process creation","I prefer to have new API which is simpler and/or easier-to-use.","5"
"2019/04/08 5:08:59 AM AST","Other","Spain","6","4","C/C++;Fortran 90 or newer","more than 10 years","between 5 and 10 years","Simulation","Scientist: Numerical simulations","No, and I will not read it.","I read book(s).;Other lectures or tutorials (workplace, conference).","Using MPI","Open MPI;Intel MPI","I was said to use it.","I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Performance tuning","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI with OpenMP (or multithread)","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes","I do not know or I do not care.","","Always","Yes, but I have no special reason for doing that.","","I do not know if there is room for performance tuning.","","","","","Yes, compatibility is very important for me.","3"
"2019/04/08 5:09:37 AM AST","College/University","Italy","4","3","Python","between 2 and 5 years","less than 2 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I read articles found on Internet.","I have never read any MPI books","Open MPI;Intel MPI","I have no special reason.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","PMPI interface","Point-to-point communications;Collective communications;MPI datatypes","I do not know or I do not care.","No appropriate lecture / book / info.;I have nobody to ask.","I rely on the default ‘Errors abort’ error handling","No, MPI calls are scattered in my programs.","No","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","I am not investigating any alternatives.","MPI provides all semantics I need","","There are no unnecessary features","I prefer to have new API which is simpler and/or easier-to-use.","2"
"2019/04/08 5:10:02 AM AST","College/University","Italy","5","4","C/C++","between 2 and 5 years","between 2 and 5 years","Numerical application and/or library","Research and development of application(s)","I have not read it, but I plan to.","I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","Open MPI","I am familiar with it.","I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Domain decomposition","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes","I have never called MPI_INIT_THREAD","Too many routines.;Too complicated and hard to understand.;I do not like the API.","Sometimes","Yes, but I have no special reason for doing that.","OpenMP","I do not have (know) tools to find performance bottlenecks.","I am not investigating any alternatives.","MPI provides all semantics I need","Another API which is easier and/or simpler to use","One-sided communication;Communicator and group management;Process topologies;Dynamic process creation","I prefer to have new API which is simpler and/or easier-to-use.","3"
"2019/04/08 5:10:21 AM AST","Governmental institute","Italy","5","6","C/C++;Fortran 90 or newer;Python","between 5 and 10 years","between 5 and 10 years","Numerical application and/or library","Parallelization of sequential program(s);Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","Using MPI","Open MPI;Intel MPI","I have no special reason.","I read online documents (such as man pages).","Debugging","Dynamic process creation;Persistent communication","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED","I have no obstacles.","Mostly","Yes, to minimize the changes of communication API.","OpenMP;CUDA","No, my MPI programs are well-tuned.","A Domain Specific Language (DSL).","Multi-threading support","Endpoints (multi-thread, sessions)","There are no unnecessary features","Yes, compatibility is very important for me.","3"
"2019/04/08 5:11:46 AM AST","College/University","Italy","5","3","Fortran 90 or newer","between 5 and 10 years","less than 2 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","looking at pre-existing codes","I have never read any MPI books","MPICH;MVAPICH;Intel MPI","I have no special reason.","I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Algorithm design","MPI datatypes;Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","","Sometimes","Yes, to minimize the changes of communication API.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","Process topologies","Yes, compatibility is very important for me.","3"
"2019/04/08 5:11:54 AM AST","Private research institute","Italy","4","5","C/C++;Fortran (older one than Fortran 90);Python","more than 10 years","more than 10 years","Parallel language (incl. domain specific language);Numerical application and/or library;Big data","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s)","I have not read it, but I plan to.","I had lecture(s) at school.","Parallel Programming in C with MPI and OpenMP;MPI: The Complete Reference","MPICH","I am familiar with it.","I read the MPI Standard document (web/book).","Finding appropriate MPI routines","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;Persistent communication;MPI with OpenMP (or multithread);PMPI interface","Point-to-point communications;MPI datatypes;Dynamic process creation;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED;MPI_THREAD_MULTIPLE;I have never called MPI_INIT_THREAD","I have no obstacles.","Always","","No","No, my MPI programs are well-tuned.","A framework or library using MPI.","Latency","Endpoints (multi-thread, sessions)","Datatypes;Communicator and group management","Yes, compatibility is very important for me.","3"
"2019/04/08 5:11:57 AM AST","Governmental institute","Germany","5","5","C/C++;Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s)","I read most of it.","I read the MPI standard document.","Using MPI","MPICH;Open MPI;Intel MPI","I like to use it.","I read the MPI Standard document (web/book).","Performance tuning","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE","Too many routines.","Sometimes","Yes, to minimize the changes of communication API.","OpenMP","No, my MPI programs are well-tuned.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Resilience (fault tolerance)","There are no unnecessary features","Yes, compatibility is very important for me.","4"
"2019/04/08 5:13:54 AM AST","Governmental institute","United Kingdom","3","3","C/C++;Fortran 90 or newer;Python","between 5 and 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s)","No, and I will not read it.","I read articles found on Internet.;Learned from how MPI is used in existing code-base","I have never read any MPI books","MPICH;Open MPI;Intel MPI","I have no special reason.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications","I have never called MPI_INIT_THREAD","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","No","I think there is room for tuning, but other developers are looking at it.","I am not investigating any alternatives.","Latency","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","There are no unnecessary features","I prefer to have new API for better performance.","3"
"2019/04/08 5:14:00 AM AST","College/University","Germany","4","5","C/C++;Fortran 90 or newer","more than 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s)","","I read the MPI standard document.","MPI: The Complete Reference","Intel MPI","I like to use it.","I read the MPI Standard document (web/book).","Debugging","Dynamic process creation","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);One-sided communications;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","Too complicated and hard to understand.","Sometimes","No, MPI calls are scattered in my programs.","OpenMP","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","I am not investigating any alternatives.","Bandwidth","Latency hiding (including asynchronous completion)","Dynamic process creation;Error handlers","I prefer to have new API for better performance.","5"
"2019/04/08 5:14:47 AM AST","Governmental institute","Italy","3","3","C/C++;Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s);Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).","","Open MPI;Intel MPI","I am familiar with it.","I read online documents (such as man pages).","Debugging","Persistent communication","Point-to-point communications;Collective communications;MPI datatypes;One-sided communications;Dynamic process creation;MPI with OpenMP (or multithread);PMPI interface","MPI_THREAD_FUNNELED","Too many routines.","Never","No, MPI calls are scattered in my programs.","OpenMP","","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).;A Domain Specific Language (DSL).","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Resilience (fault tolerance)","Communicator and group management","Yes, compatibility is very important for me.","4"
"2019/04/08 5:16:21 AM AST","Hardware vendor","Germany","6","5","C/C++;Fortran (older one than Fortran 90);Python","more than 10 years","more than 10 years","System software development (OS, runtime library, communication library, etc.);Parallel language (incl. domain specific language);Tool development (performance tuning, debugging, etc.)","Research and development of application(s);Research and development on system software (OS and/or runtime library);Research and development software tool(s);Performance tuning of MPI program(s)","I read most of it.","I read the MPI standard document.;I read book(s).;I read articles found on Internet.","Parallel Programming in C with MPI and OpenMP","MPICH;Open MPI;MVAPICH;Intel MPI","I like to use it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Performance tuning","Dynamic process creation;Persistent communication","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread);PMPI interface","MPI_THREAD_MULTIPLE","I have no obstacles.","Always","Yes, to minimize the changes of communication API.","OpenMP;Pthread","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.;Low-level communication layer provided by vendor (Verbs, DCMF, ...).","Message injection rate","Latency hiding (including asynchronous completion);Resilience (fault tolerance)","Dynamic process creation","API should be clearly versioned.","4"
"2019/04/08 5:18:20 AM AST","College/University","Italy","4","1","Fortran 90 or newer;Python","between 2 and 5 years","less than 2 years","Numerical application and/or library","Research and development of application(s)","I have not read it, but I plan to.","Other lectures or tutorials (workplace, conference).","I have never read any MPI books","Open MPI;Intel MPI","I was said to use it.","I ask colleagues.;I search the Internet (Google / Stack Overflow).","Domain decomposition","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_MULTIPLE","I have no obstacles.","Mostly","Yes, to minimize the changes of communication API.","OpenMP","I do not know how to find bottlenecks.","I am not investigating any alternatives.","Bandwidth","MPI is providing all the communication semantics required by my application","There are no unnecessary features","Yes, compatibility is very important for me.","4"
"2019/04/08 5:18:57 AM AST","Governmental institute","Italy","5","4","C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer","more than 10 years","more than 10 years","Image processing;Visualization;three-dimensional magnetohydrodynamic parallel codes","Research and development of application(s)","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","I have never read any MPI books","MPICH;Open MPI;MVAPICH","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).","Debugging","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications","I have never called MPI_INIT_THREAD","I have nobody to ask.","Sometimes","Yes, to minimize the changes of communication API.","No","I have no chance to investigate.","","Bandwidth","MPI is providing all the communication semantics required by my application","There are no unnecessary features","Yes, compatibility is very important for me.","3"
"2019/04/08 5:19:18 AM AST","Governmental institute","Switzerland","4","4","C/C++;Fortran 90 or newer","more than 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","I have never read any MPI books","MPICH;Open MPI;Intel MPI;Cray MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","One-sided communications;Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","I do not know or I do not care.","I have no obstacles.","Never","Yes, to minimize the changes of communication API.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","There are no unnecessary features","I prefer to have new API for better performance.","4"
"2019/04/08 5:19:39 AM AST","College/University","Italy","4","3","C/C++;Python","between 5 and 10 years","between 2 and 5 years","Numerical application and/or library;AI (Deep Learning);Big data;Scientific software, Molecular Dynamics, Monte Carlo","Research and development of application(s);Research and development software tool(s);Parallelization of sequential program(s)","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).;By learning from already written codes","I have never read any MPI books","Open MPI;Intel MPI","I was said to use it.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Implementation issue workaround","One-sided communications;Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes","I do not know or I do not care.","I have no obstacles.","Never","No, MPI calls are scattered in my programs.","No","I think there is room but I do not know how to tune it.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","There are no unnecessary features","Yes, compatibility is very important for me.","2"
"2019/04/08 5:19:50 AM AST","Private research institute","Italy","6","5","C/C++","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s);Performance tuning of MPI program(s);Debugging MPI programs","I read all.","I read the MPI standard document.;I read book(s).","Parallel Programming with MPI;Using MPI;MPI: The Complete Reference","MPICH;Open MPI;MVAPICH;Intel MPI","I am familiar with it.","I read the MPI Standard document (web/book).;I know almost all MPI routines.","Other","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread);MPI-IO","MPI_THREAD_MULTIPLE","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","OpenMP;OpenACC;OpenCL;CUDA","No, my MPI programs are well-tuned.","A framework or library using MPI.;I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.);many interfaces uses int types for size, whereas they should use size_t to deal with buffers longer than 2^31 bytes","Dynamic process creation","API should be clearly versioned.","3"
"2019/04/08 5:23:00 AM AST","Other","Italy","4","4","C/C++","more than 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).","","Open MPI","I am familiar with it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","time to spend on it","Sometimes","Yes, to minimize the changes of communication API.","OpenMP","Yes, we plan to tune performance periodically","I am not investigating any alternatives.","Multi-threading support","Resilience (fault tolerance)","There are no unnecessary features","API should be clearly versioned.","5"
"2019/04/08 5:23:09 AM AST","College/University","Italy","4","4","C/C++;Python","between 2 and 5 years","less than 2 years","Parallel language (incl. domain specific language);Numerical application and/or library","Research and development of application(s);Parallelization of sequential program(s)","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","Open MPI","I am familiar with it.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Domain decomposition","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes","I do not know or I do not care.","I have nobody to ask.","Always","Yes, to minimize the changes of communication API.","No","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Latency","Latency hiding (including asynchronous completion)","There are no unnecessary features","I prefer to have new API for better performance.","4"
"2019/04/08 5:23:25 AM AST","College/University","United Kingdom","6","5","C/C++;Fortran 90 or newer;Python","more than 10 years","more than 10 years","Numerical application and/or library;Big data;Tool development (performance tuning, debugging, etc.)","Research and development of application(s);Research and development software tool(s);Performance tuning of MPI program(s);Science","I read only the chapters of interest for my work.","I read the MPI standard document.;I read articles found on Internet.;Experimented","I have never read any MPI books","MPICH;Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Implementation issue workaround","Dynamic process creation;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","Buggy implementations","Mostly","Yes, to minimize the changes of communication API.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","More robust implementations","Resilience (fault tolerance)","There are no unnecessary features","Yes, compatibility is very important for me.","2"
"2019/04/08 5:28:29 AM AST","Governmental institute","United Kingdom","4","4","Fortran (older one than Fortran 90)","more than 10 years","between 5 and 10 years","Numerical application and/or library;Plasma Physics","","No, and I will not read it.","I read book(s).;I had lecture(s) at school.;I read articles found on Internet.","Parallel Programming with MPI","MPICH;Open MPI;MVAPICH;Intel MPI","I could not have any choice (the one provided by a vendor).","I search the Internet (Google / Stack Overflow).","Other","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;Dynamic process creation;Persistent communication;MPI with OpenMP (or multithread)","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;Dynamic process creation;Persistent communications;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED","Too complicated and hard to understand.","Never","Yes, to minimize the changes of communication API.","OpenMP","I think there is room but I do not know how to tune it.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Latency hiding (including asynchronous completion);Resilience (fault tolerance);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","One-sided communication;Dynamic process creation","API should be clearly versioned.","3"
"2019/04/08 5:30:04 AM AST","College/University","Italy","6","4","C/C++","more than 10 years","less than 2 years","Parallel language (incl. domain specific language);Numerical application and/or library","Parallelization of sequential program(s);Performance tuning of MPI program(s);RESEARCH IN PHYSICS","I read only the chapters of interest for my work.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).","I have never read any MPI books","Open MPI","I have no special reason.","I read the MPI Standard document (web/book).","Debugging","Dynamic process creation;Persistent communication","Collective communications;Communicator operations (split, duplicate, and so on);One-sided communications","MPI_THREAD_MULTIPLE","I do not like the API.","Always","No, my program is too small to do that.","OpenMP;CUDA","No, my MPI programs are well-tuned.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","Datatypes;Dynamic process creation","API should be clearly versioned.","5"
"2019/04/08 5:35:20 AM AST","Governmental institute","Germany","4","2","C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer;Python","between 5 and 10 years","less than 2 years","Numerical application and/or library;Big data","Research and development of application(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","MPICH;Open MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Implementation issue workaround","PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on)","","","Sometimes","No, MPI calls are scattered in my programs.","OpenMP","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","Global Arrays","","MPI is providing all the communication semantics required by my application","One-sided communication","API should be clearly versioned.","2"
"2019/04/08 5:40:17 AM AST","College/University","Italy","5","4","Fortran 90 or newer;Matlab","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).","Designing and Building Parallel Programs, by Ian Foster","Intel MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes","I do not know or I do not care.","Too many routines.","I rely on the default ‘Errors abort’ error handling","No, MPI calls are scattered in my programs.","No","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","MPI is providing all the communication semantics required by my application","Error handlers","Yes, compatibility is very important for me.","3"
"2019/04/08 5:40:19 AM AST","College/University","Switzerland","4","","C/C++;Fortran 90 or newer","between 5 and 10 years","between 2 and 5 years","Parallel language (incl. domain specific language);Numerical application and/or library","Research and development of application(s)","No, and I will not read it.","I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","I have never read any MPI books","Intel MPI","I was said to use it.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Communicator operations (split, duplicate, and so on);Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications","I do not know or I do not care.","Too many routines.","Mostly","No, MPI calls are scattered in my programs.","No","I think there is room but I do not know how to tune it.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","Process topologies;Dynamic process creation","Yes, compatibility is very important for me.","2"
"2019/04/08 5:41:34 AM AST","College/University","Italy","5","4","C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer;Python","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I read the MPI standard document.","I have never read any MPI books","MPICH;Open MPI;MVAPICH;Intel MPI;Cray MPI;IBM MPI (BG/Q, PE, Spectrum)","I have no special reason.","I read the MPI Standard document (web/book).","Debugging","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;Dynamic process creation;Persistent communication;MPI with OpenMP (or multithread)","Point-to-point communications;Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","Too many routines.","Mostly","Yes, to minimize the changes of communication API.","No","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Latency","Latency hiding (including asynchronous completion);Endpoints (multi-thread, sessions);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","There are no unnecessary features","Yes, compatibility is very important for me.","3"
"2019/04/08 5:49:38 AM AST","Governmental institute","Italy","6","5","C/C++;Fortran 90 or newer;Python","more than 10 years","between 5 and 10 years","System software development (OS, runtime library, communication library, etc.);Numerical application and/or library","Research and development of application(s)","I read most of it.","I read the MPI standard document.;I read book(s).;Other lectures or tutorials (workplace, conference).","Parallel Programming with MPI","Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).","Domain decomposition","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE","I have no obstacles.","Always","Yes, to minimize the changes of communication API.","OpenMP","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).;A Domain Specific Language (DSL).","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","MPI is providing all the communication semantics required by my application","Dynamic process creation","I prefer to have new API for better performance.","5"
"2019/04/08 5:52:00 AM AST","College/University","United Kingdom","5","5","C/C++;Fortran 90 or newer;Python;Matlab","more than 10 years","between 5 and 10 years","Numerical application and/or library;Big data","Research and development of application(s);Research and development software tool(s)","I read only the chapters of interest for my work.","I read book(s).;I had lecture(s) at school.;I read articles found on Internet.","Parallel Programming with MPI","Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","Dynamic process creation;Persistent communication","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","I have no obstacles.","Mostly","I pack elementary vector operations into their own files. In turn, those are small enough to call MPI directly.","OpenMP","I think there is room but I do not know how to tune it.","A framework or library using MPI.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Latency hiding (including asynchronous completion);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.);Custom reduction operations of variable data size","There are no unnecessary features","API should be clearly versioned.","4"
"2019/04/08 5:58:01 AM AST","Governmental institute","Italy","4","2","Fortran (older one than Fortran 90);Fortran 90 or newer","between 5 and 10 years","less than 2 years","Theoretical nuclear physics","Research and development of application(s)","No, and I will not read it.","I read articles found on Internet.","I have never read any MPI books","Intel MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Communicator operations (split, duplicate, and so on);Dynamic process creation;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","No appropriate lecture / book / info.;I have nobody to ask.","Mostly","No, MPI calls are scattered in my programs.","OpenMP","I think there is room but I do not know how to tune it.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","Datatypes;Communicator and group management","API should be clearly versioned.","4"
"2019/04/08 6:02:24 AM AST","Governmental institute","Italy","6","6","C/C++","more than 10 years","between 5 and 10 years","Parallel language (incl. domain specific language);Numerical application and/or library;AI (Deep Learning)","Research and development of application(s);Research and development software tool(s);Parallelization of sequential program(s);Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","I read book(s).;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Parallel Programming with MPI;Using MPI","Open MPI;MVAPICH;Intel MPI","I have no special reason.","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Algorithm design","Dynamic process creation","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED;MPI_THREAD_SERIALIZED;MPI_THREAD_MULTIPLE","I have no obstacles.","Always","No, MPI calls are scattered in my programs.","OpenMP;Pthread;OpenACC;OpenCL;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","Dynamic process creation","I prefer to have new API for better performance.","4"
"2019/04/08 6:13:54 AM AST","College/University","Italy","5","4","C/C++;Python;CUDA ","more than 10 years","between 2 and 5 years","Numerical application and/or library;AI (Deep Learning);Image processing;Visualization;Tool development (performance tuning, debugging, etc.)","Research and development of application(s);Parallelization of sequential program(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;Collegues","I have never read any MPI books","Open MPI;MS MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Debugging","Collective communications;Communicator operations (split, duplicate, and so on);Persistent communication;MPI with OpenMP (or multithread);PMPI interface","Point-to-point communications","I do not know or I do not care.","I have nobody to ask.","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","No","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A framework or library using MPI.","Latency","","There are no unnecessary features","I prefer to have new API which is simpler and/or easier-to-use.","1"
"2019/04/08 6:17:23 AM AST","College/University","Italy","4","3","Python","more than 10 years","between 5 and 10 years","Big data;Workflow and/or In-situ","Research and development software tool(s)","I have not read it, but I plan to.","Other lectures or tutorials (workplace, conference).","I have never read any MPI books","Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;MPI with OpenMP (or multithread)","MPI_THREAD_MULTIPLE","Too complicated and hard to understand.","I rely on the default ‘Errors abort’ error handling","No, my program is too small to do that.","No","I do not know how to find bottlenecks.","A framework or library using MPI.","Message injection rate","Latency hiding (including asynchronous completion)","There are no unnecessary features","Yes, compatibility is very important for me.","3"
"2019/04/08 6:45:39 AM AST","Governmental institute","Italy","5","5","C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer;Python","more than 10 years","more than 10 years","Parallel language (incl. domain specific language)","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","I read most of it.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).","Using MPI;MPI: The Complete Reference","MPICH;Open MPI;Intel MPI;IBM MPI (BG/Q, PE, Spectrum)","I am familiar with it.","I read the MPI Standard document (web/book).","Other","PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED;MPI_THREAD_SERIALIZED","I have no obstacles.","Sometimes","Yes, to minimize the changes of communication API.","OpenMP","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Resilience (fault tolerance)","There are no unnecessary features","I prefer to have new API for better performance.","4"
"2019/04/08 6:58:44 AM AST","College/University","Italy","5","5","C/C++;Python","more than 10 years","between 2 and 5 years","System software development (OS, runtime library, communication library, etc.);Parallel language (incl. domain specific language);Tool development (performance tuning, debugging, etc.)","Research and development on system software (OS and/or runtime library);Research and development software tool(s);Performance tuning of MPI program(s);Debugging MPI programs","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","MPICH;Open MPI;MVAPICH;Intel MPI","I like to use it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Performance tuning","Persistent communication","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;Dynamic process creation;PMPI interface","MPI_THREAD_SINGLE;I have never called MPI_INIT_THREAD","I have no obstacles.;Too many routines.","Never","No, my program is too small to do that.","OpenMP","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A framework or library using MPI.;Low-level communication layer provided by vendor (Verbs, DCMF, ...).","Latency","Resilience (fault tolerance);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","Dynamic process creation","I prefer to have new API for better performance.","5"
"2019/04/08 7:04:57 AM AST","Governmental institute","Italy","6","6","C/C++","more than 10 years","more than 10 years","Numerical application and/or library;Big data","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s)","No, and I will not read it.","I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).","Debugging","Dynamic process creation;Persistent communication","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_MULTIPLE","Too many routines.","Always","Yes, to minimize the changes of communication API.","OpenMP;Pthread;OpenCL;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Endpoints (multi-thread, sessions)","There are no unnecessary features","API should be clearly versioned.","2"
"2019/04/08 7:21:44 AM AST","College/University","Italy","5","4","Fortran 90 or newer;Python","between 5 and 10 years","between 5 and 10 years","Numerical application and/or library;Big data","design and optimization of nonlinear PDE solvers for fluid physics.","I have not read it, but I plan to.","I read book(s).;I read articles found on Internet.","I have never read any MPI books","Open MPI;Intel MPI","I like to use it.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Point-to-point communications;Dynamic process creation;Persistent communication;PMPI interface","Collective communications;MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_FUNNELED","Too many routines.","Sometimes","Yes, but I have no special reason for doing that.","OpenMP","I think there is room but I do not know how to tune it.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Endpoints (multi-thread, sessions)","Dynamic process creation","I prefer to have new API for better performance.","3"
"2019/04/08 7:38:30 AM AST","College/University","Italy","5","3","C/C++","more than 10 years","between 2 and 5 years","Parallel language (incl. domain specific language);Numerical application and/or library","Research and development of application(s)","No, and I will not read it.","I read book(s).;I read articles found on Internet.","Parallel Programming in C with MPI and OpenMP","Open MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).","Algorithm design","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","I do not know or I do not care.","Lack of time to learn MPI comprehensively","Sometimes","No, my program is too small to do that.","OpenMP","I do not have (know) tools to find performance bottlenecks.","I am not investigating any alternatives.","Latency","","Communicator and group management","API should be clearly versioned.","2"
"2019/04/08 8:12:44 AM AST","College/University","Italy","4","3","C/C++;Fortran 90 or newer;Python","between 2 and 5 years","less than 2 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I had lecture(s) at school.","I have never read any MPI books","Open MPI;Intel MPI","I was said to use it.","I read the MPI Standard document (web/book).;I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications","I have never called MPI_INIT_THREAD","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","OpenMP;OpenACC","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Latency","Latency hiding (including asynchronous completion)","Dynamic process creation","I prefer to have new API which is simpler and/or easier-to-use.","3"
"2019/04/08 8:20:23 AM AST","Other","Italy","4","3","C/C++;Fortran 90 or newer;Python","between 2 and 5 years","less than 2 years","Numerical application and/or library","Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","I have not read it, but I plan to.","I had lecture(s) at school.","I have never read any MPI books","Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I ask colleagues.","Domain decomposition","One-sided communications;Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED;MPI_THREAD_SERIALIZED;MPI_THREAD_MULTIPLE","I have no obstacles.","Sometimes","Yes, but I have no special reason for doing that.","OpenMP","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","I am not investigating any alternatives.","Message injection rate","MPI is providing all the communication semantics required by my application","","I prefer to have new API which is simpler and/or easier-to-use.","4"
"2019/04/08 8:46:31 AM AST","College/University","Switzerland","6","4","C/C++;Python","more than 10 years","between 2 and 5 years","System software development (OS, runtime library, communication library, etc.);Parallel language (incl. domain specific language);Numerical application and/or library;AI (Deep Learning)","Research and development on system software (OS and/or runtime library)","I read only the chapters of interest for my work.","I read book(s).","Using MPI;MPI: The Complete Reference","Open MPI;MVAPICH;Cray MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).","Finding appropriate MPI routines","Dynamic process creation;Persistent communication","Point-to-point communications;Collective communications;One-sided communications;MPI with OpenMP (or multithread);PMPI interface","MPI_THREAD_MULTIPLE","I do not like the API.;Doesn't perform well with other systems and accelerators","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","OpenMP;OpenCL;CUDA","There is always room for more tuning","A framework or library using MPI.;Low-level communication layer provided by vendor (Verbs, DCMF, ...).","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Latency hiding (including asynchronous completion);Endpoints (multi-thread, sessions)","Communicator and group management;Process topologies","I prefer to have new API for better performance.","3"
"2019/04/08 8:47:33 AM AST","College/University","Switzerland","5","5","C/C++;Fortran 90 or newer;Python","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","Parallel Programming with MPI;Using MPI","MPICH;Open MPI;MVAPICH;Cray MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).","Debugging","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED;MPI_THREAD_SERIALIZED","Too many routines.","Never","Yes, to minimize the changes of communication API.","OpenMP;OpenACC;OpenCL;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).;A Domain Specific Language (DSL).;HPX","Multi-threading support","","Dynamic process creation","Yes, compatibility is very important for me.","3"
"2019/04/08 8:48:16 AM AST","College/University","Switzerland","5","5","C/C++;Python","between 5 and 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s)","I read most of it.","I read the MPI standard document.;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","MPICH;Open MPI;MVAPICH;Cray MPI","I am familiar with it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Algorithm design","Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","I have no obstacles.","Always","No, MPI calls are scattered in my programs.","OpenMP;CUDA","No, my MPI programs are well-tuned.","I am not investigating any alternatives.","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","MPI is providing all the communication semantics required by my application","One-sided communication;Dynamic process creation","Yes, compatibility is very important for me.","4"
"2019/04/08 8:50:01 AM AST","College/University","Switzerland","3","3","Fortran 90 or newer;Python","between 2 and 5 years","between 2 and 5 years","Workflow and/or In-situ;material science simulation","Research and development software tool(s)","I read only the chapters of interest for my work.","I had lecture(s) at school.;I read articles found on Internet.","","MPICH;Open MPI;Intel MPI;Cray MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).","Algorithm design","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","","OpenMP;OpenCL;CUDA","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A framework or library using MPI.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","","","Yes, compatibility is very important for me.","5"
"2019/04/08 8:50:53 AM AST","College/University","Switzerland","5","3","Fortran 90 or newer","between 2 and 5 years","less than 2 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","I have never read any MPI books","MPICH","I was said to use it.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","One-sided communications;Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications","I have never called MPI_INIT_THREAD","No appropriate lecture / book / info.","Mostly","Yes, to minimize the changes of communication API.","No","I think there is room but I do not know how to tune it.","A framework or library using MPI.","Bandwidth","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.);Another API which is easier and/or simpler to use","","API should be clearly versioned.","3"
"2019/04/08 8:52:58 AM AST","College/University","Switzerland","5","3","Fortran (older one than Fortran 90);Fortran 90 or newer;Python","more than 10 years","between 2 and 5 years","Numerical application and/or library","Research and development of application(s)","","Other lectures or tutorials (workplace, conference).","I have never read any MPI books","MPICH;Open MPI","I could not have any choice (the one provided by a vendor).","I ask colleagues.","Domain decomposition","MPI datatypes;Dynamic process creation;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI with OpenMP (or multithread)","I do not know or I do not care.","No appropriate lecture / book / info.;Too complicated and hard to understand.","Mostly","Yes, to minimize the changes of communication API.","OpenMP","I think there is room but I do not know how to tune it.","A framework or library using MPI.","Latency","MPI is providing all the communication semantics required by my application","There are no unnecessary features","I do not know or I do not care.","4"
"2019/04/08 8:53:11 AM AST","Governmental institute","Switzerland","5","4","C/C++;Rust","between 5 and 10 years","between 2 and 5 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I had lecture(s) at school.;I read articles found on Internet.","","MPICH;Open MPI;Cray MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Debugging","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes","I have never called MPI_INIT_THREAD","I do not like the API.","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","OpenMP;CUDA;ROCm","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Another API which is easier and/or simpler to use","Dynamic process creation","I prefer to have new API which is simpler and/or easier-to-use.","3"
"2019/04/08 8:53:42 AM AST","Governmental institute","Switzerland","5","4","Fortran (older one than Fortran 90);Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s)","No, and I will not read it.","Other lectures or tutorials (workplace, conference).;I read articles found on Internet.;I have not learned MPI.","","MPICH;MVAPICH;Cray MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Domain decomposition","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications","MPI_THREAD_SINGLE;MPI_THREAD_SERIALIZED;MPI_THREAD_MULTIPLE","Too many routines.","Always","Yes, to minimize the changes of communication API.","OpenACC","I think there is room but I do not know how to tune it.","A framework or library using MPI.;A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).;A Domain Specific Language (DSL).","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Latency hiding (including asynchronous completion);Endpoints (multi-thread, sessions)","Process topologies;Dynamic process creation","I prefer to have new API for better performance.","3"
"2019/04/08 8:54:58 AM AST","College/University","Spain","5","3","C/C++;Fortran 90 or newer;Python","more than 10 years","between 5 and 10 years","Big data;Workflow and/or In-situ","Research and development of application(s);Parallelization of sequential program(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I had lecture(s) at school.;I read articles found on Internet.","I have never read any MPI books","Open MPI;MVAPICH;Intel MPI","I was said to use it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","No appropriate lecture / book / info.","Never","No, my program is too small to do that.","OpenMP;Pthread","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Resilience (fault tolerance);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","There are no unnecessary features","I prefer to have new API for better performance.","5"
"2019/04/08 8:56:51 AM AST","College/University","Czech Republic","5","3","C/C++;Python;Rust","between 5 and 10 years","between 2 and 5 years","System software development (OS, runtime library, communication library, etc.);AI (Deep Learning);Workflow and/or In-situ;Tool development (performance tuning, debugging, etc.)","Research and development of application(s);Research and development software tool(s)","I have not read it, but I plan to.","I read articles found on Internet.","I have never read any MPI books","MPICH;Open MPI;Intel MPI","I was said to use it.","I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation;Persistent communication","Point-to-point communications;Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","Too many routines.;I do not like the API.","Always","No, my program is too small to do that.","OpenMP","I do not know if there is room for performance tuning.","A framework or library using MPI.;Low-level communication layer provided by vendor (Verbs, DCMF, ...).","Latency","Latency hiding (including asynchronous completion);Resilience (fault tolerance);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.);Another API which is easier and/or simpler to use","Process topologies;Dynamic process creation;Error handlers","I prefer to have new API which is simpler and/or easier-to-use.","4"
"2019/04/08 8:58:03 AM AST","Governmental institute","Switzerland","5","5","C/C++;Python","more than 10 years","more than 10 years","System software development (OS, runtime library, communication library, etc.);Tool development (performance tuning, debugging, etc.)","Research and development on system software (OS and/or runtime library)","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Using MPI;MPI: The Complete Reference","MPICH;MVAPICH;Cray MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","Persistent communication","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);One-sided communications","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED","Too many routines.;No appropriate lecture / book / info.","Sometimes","Yes, to minimize the changes of communication API.","OpenMP;Pthread;CUDA","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A framework or library using MPI.;A Domain Specific Language (DSL).","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","Dynamic process creation;Error handlers","API should be clearly versioned.","3"
"2019/04/08 8:58:28 AM AST","College/University","Germany","6","6","C/C++","between 5 and 10 years","between 2 and 5 years","Numerical application and/or library","Research and development of application(s)","No, and I will not read it.","I read articles found on Internet.;I looked at code","I have never read any MPI books","MPICH;Open MPI;Intel MPI;Cray MPI","I could not have any choice (the one provided by a vendor).","I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications","I have never called MPI_INIT_THREAD","time consuming","Sometimes","No, MPI calls are scattered in my programs.","No","Yes, I know there is room for tuning but I do not have enough resources to do that.","Trilinos","MPI provides all semantics I need","","There are no unnecessary features","API should be clearly versioned.","3"
"2019/04/08 9:03:23 AM AST","College/University","Switzerland","5","5","C/C++;Fortran 90 or newer;Python","between 5 and 10 years","between 5 and 10 years","Numerical application and/or library;Image processing;Workflow and/or In-situ","Research and development of application(s);Research and development software tool(s)","I read only the chapters of interest for my work.","I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","","MPICH;Open MPI;Cray MPI","I am familiar with it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Implementation issue workaround","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_FUNNELED","No appropriate lecture / book / info.;Too complicated and hard to understand.","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","OpenMP;OpenACC;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Latency hiding (including asynchronous completion);Resilience (fault tolerance);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","Dynamic process creation","Yes, compatibility is very important for me.","3"
"2019/04/08 9:12:12 AM AST","Private research institute","Sweden","5","5","C/C++;Python","more than 10 years","more than 10 years","Parallel language (incl. domain specific language);Numerical application and/or library","Research and development of application(s);Research and development software tool(s);Parallelization of sequential program(s);Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).;I read articles found on Internet.","Using MPI","MPICH;Open MPI","I am familiar with it.","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).;I search the Internet (Google / Stack Overflow).","Debugging","","Point-to-point communications;Collective communications;MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","I have no obstacles.","Always","","OpenCL;CUDA","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","I am not investigating any alternatives.","Latency","Endpoints (multi-thread, sessions)","","",""
"2019/04/08 9:12:57 AM AST","College/University","Switzerland","5","3","C/C++","more than 10 years","less than 2 years","Parallel language (incl. domain specific language);Numerical application and/or library","Research and development software tool(s)","I read only the chapters of interest for my work.","I had lecture(s) at school.","I have never read any MPI books","MPICH;Open MPI;MVAPICH","I have no special reason.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).","Domain decomposition","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on)","MPI_THREAD_SERIALIZED;MPI_THREAD_MULTIPLE","","Never","No, MPI calls are scattered in my programs.","OpenMP","I do not know if there is room for performance tuning.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Unspecified message size","Unspecified message size","Datatypes;Dynamic process creation","API should be clearly versioned.","4"
"2019/04/08 9:17:13 AM AST","Hardware vendor","United States","5","5","C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer;Python","more than 10 years","more than 10 years","Tool development (performance tuning, debugging, etc.)","Performance tuning of MPI program(s)","I read most of it.","I read the MPI standard document.;I read articles found on Internet.","I have never read any MPI books","MPICH;Open MPI;MVAPICH;Intel MPI;Cray MPI","I am familiar with it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Domain decomposition","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;Persistent communications;MPI with OpenMP (or multithread);PMPI interface","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED;MPI_THREAD_MULTIPLE","No appropriate lecture / book / info.","Sometimes","No, MPI calls are scattered in my programs.","OpenMP;OpenACC;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.;A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Internal MPI statistics (off-node vs. on-node messages/bytes, etc.)","Resilience (fault tolerance);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","Error handlers","Yes, compatibility is very important for me.","1"
"2019/04/08 9:18:24 AM AST","College/University","United States","6","6","C/C++","more than 10 years","between 2 and 5 years","System software development (OS, runtime library, communication library, etc.)","Research and development on system software (OS and/or runtime library)","I read only the chapters of interest for my work.","I read the MPI standard document.;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","I have never read any MPI books","MVAPICH","I am familiar with it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Performance tuning","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;Persistent communication;MPI with OpenMP (or multithread);PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread);PMPI interface","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","No, MPI calls are scattered in my programs.","CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Another API which is easier and/or simpler to use","Process topologies;Dynamic process creation","Yes, compatibility is very important for me.","4"
"2019/04/08 9:24:49 AM AST","College/University","Germany","4","4","C/C++;Fortran (older one than Fortran 90)","between 2 and 5 years","between 2 and 5 years","Numerical application and/or library;Computational science","Research and development of application(s);Research and development software tool(s);Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","I have never read any MPI books","MPICH;Open MPI;Intel MPI;Cray MPI;IBM MPI (BG/Q, PE, Spectrum)","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I search the Internet (Google / Stack Overflow).","Implementation issue workaround","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","I do not like the API.","Sometimes","No, MPI calls are scattered in my programs.","OpenMP;CUDA","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","I am not investigating any alternatives.","Latency","Another API which is easier and/or simpler to use","There are no unnecessary features","I prefer to have new API for better performance.","3"
"2019/04/08 9:25:58 AM AST","Governmental institute","Germany","5","4","Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).","","MPICH;Open MPI;MVAPICH;Intel MPI;IBM MPI (BG/Q, PE, Spectrum)","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I ask colleagues.","Implementation issue workaround","Dynamic process creation","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread);PMPI interface;MPI I/O","MPI_THREAD_SERIALIZED;MPI_THREAD_MULTIPLE","Too many routines.;Lack in proper vendor/platform support","Sometimes","No, MPI calls are scattered in my programs.","OpenMP;Pthread;OpenACC;OpenCL;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Resilience (fault tolerance);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","There are no unnecessary features","API should be clearly versioned.","3"
"2019/04/08 9:33:49 AM AST","Hardware vendor","Switzerland","4","4","C/C++;Python","more than 10 years","more than 10 years","AI (Deep Learning);Image processing;Visualization","Research and development of application(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","I have never read any MPI books","MPICH;Open MPI;MVAPICH;Cray MPI","I like to use it.","I read the MPI Standard document (web/book).","Debugging","PMPI interface","Point-to-point communications;Collective communications;One-sided communications","MPI_THREAD_MULTIPLE","I have no obstacles.","Sometimes","No, MPI calls are scattered in my programs.","OpenMP;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Resilience (fault tolerance);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","Datatypes","Yes, compatibility is very important for me.","4"
"2019/04/08 9:41:01 AM AST","College/University","Germany","5","5","C/C++;Python","between 5 and 10 years","between 2 and 5 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","Open MPI;Intel MPI;Cray MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Communicator operations (split, duplicate, and so on);Dynamic process creation;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;Persistent communications;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","I have no obstacles.","Mostly","No, MPI calls are scattered in my programs.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.","MPI provides all semantics I need","Another API which is easier and/or simpler to use;MPI is providing all the communication semantics required by my application","Dynamic process creation","API should be clearly versioned.","3"
"2019/04/08 9:50:01 AM AST","Governmental institute","Germany","5","3","Fortran 90 or newer;Python","more than 10 years","between 2 and 5 years","Numerical application and/or library","Research and development of application(s);Research and development software tool(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","I have never read any MPI books","Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).","Debugging","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes","I have never called MPI_INIT_THREAD;I do not know or I do not care.","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","No, MPI calls are scattered in my programs.","No","I do not know how to find bottlenecks.","A framework or library using MPI.;A Domain Specific Language (DSL).","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","Dynamic process creation;Error handlers","API should be clearly versioned.","1"
"2019/04/08 9:50:57 AM AST","College/University","Switzerland","5","3","C/C++;Python","more than 10 years","between 5 and 10 years","Numerical application and/or library;Tool development (performance tuning, debugging, etc.)","Research and development of application(s)","No, and I will not read it.","I have not learned MPI.;Stackoverflow, Existing Code","I have never read any MPI books","MPICH;Cray MPI","I am familiar with it.","I search the Internet (Google / Stack Overflow).","Finding appropriate MPI routines","One-sided communications;Dynamic process creation;Persistent communication;PMPI interface","Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","Too many routines.","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","No","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Message injection rate","Latency hiding (including asynchronous completion)","There are no unnecessary features","Yes, compatibility is very important for me.","3"
"2019/04/08 9:54:43 AM AST","College/University","Denmark","5","3","C/C++;Python","more than 10 years","between 2 and 5 years","Numerical application and/or library","Research and development of application(s)","I have not read it, but I plan to.","I read articles found on Internet.","","MPICH;Open MPI;MVAPICH;Intel MPI","I have no special reason.","I search the Internet (Google / Stack Overflow).","Domain decomposition","One-sided communications;Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI with OpenMP (or multithread)","I do not know or I do not care.","No appropriate lecture / book / info.","Sometimes","Yes, to minimize the changes of communication API.","OpenMP","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A framework or library using MPI.","I sometimes want a feature which does not exist, at least in the most common implementations. An example would be MPI_Recvreduce.","","There are no unnecessary features","I prefer to have new API which is simpler and/or easier-to-use.","4"
"2019/04/08 10:12:52 AM AST","Private research institute","Switzerland","2","1","Python","more than 10 years","","Scientific calculations","Scientist analyst and Code maintainer","No, and I will not read it.","I have not learned MPI.","","MPICH;Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","","","","","","","","","No","","","","","","",""
"2019/04/08 10:28:30 AM AST","","United Kingdom","4","1","Fortran 90 or newer;Python","more than 10 years","less than 2 years","Numerical application and/or library","Research and development of application(s)","I have not read it, but I plan to.","Other lectures or tutorials (workplace, conference).","","MPICH","I could not have any choice (the one provided by a vendor).","I search the Internet (Google / Stack Overflow).","Debugging","Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications","MPI_THREAD_SINGLE","No appropriate lecture / book / info.","Sometimes","No, MPI calls are scattered in my programs.","OpenMP","I do not have (know) tools to find performance bottlenecks.","A framework or library using MPI.;A Domain Specific Language (DSL).","Bandwidth","Resilience (fault tolerance)","There are no unnecessary features","Yes, compatibility is very important for me.","2"
"2019/04/08 10:43:53 AM AST","College/University","Germany","4","5","C/C++;Python;bash ","between 5 and 10 years","between 5 and 10 years","System software development (OS, runtime library, communication library, etc.);Tool development (performance tuning, debugging, etc.)","Research and development on system software (OS and/or runtime library);Research and development software tool(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Using MPI;Parallel Programming in C with MPI and OpenMP;MPI: The Complete Reference","MPICH;Open MPI;MVAPICH;Intel MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","Persistent communication","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);One-sided communications;Dynamic process creation;MPI with OpenMP (or multithread);PMPI interface","MPI_THREAD_MULTIPLE","Non  Standardized MPI wrapper tools ( hydra process startup etc.)","I rely on the default ‘Errors abort’ error handling","No, MPI calls are scattered in my programs.","OpenMP","There is overhead analysis to be done (tools programming).","A framework or library using MPI.;I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.);MPI is providing all the communication semantics required by my application","","Yes, compatibility is very important for me.","2"
"2019/04/08 10:53:28 AM AST","Governmental institute","Germany","6","5","C/C++;Python","more than 10 years","more than 10 years","System software development (OS, runtime library, communication library, etc.);Parallel language (incl. domain specific language);Numerical application and/or library;AI (Deep Learning);Workflow and/or In-situ;Visualization;Tool development (performance tuning, debugging, etc.)","Research and development of application(s);Research and development software tool(s);Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","I read only the chapters of interest for my work.","I read the MPI standard document.;I read articles found on Internet.;I read man pages. I coded.","I have never read any MPI books","MPICH;Open MPI;MVAPICH;Intel MPI;IBM MPI (BG/Q, PE, Spectrum)","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).;I know almost all MPI routines.","Domain decomposition","Persistent communication","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;Dynamic process creation","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED;MPI_THREAD_SERIALIZED;MPI_THREAD_MULTIPLE","I have no obstacles.","Always","Yes, to minimize the changes of communication API.","OpenMP;Pthread;CUDA","No, my MPI programs are well-tuned.","A framework or library using MPI.","Latency","Resilience (fault tolerance)","There are no unnecessary features","API should be clearly versioned.","3"
"2019/04/08 11:02:00 AM AST","College/University","Switzerland","6","5","C/C++;Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s);Resarch","I read only the chapters of interest for my work.","I read the MPI standard document.;Like any other programming skill also through some trial-and-error","","MPICH;Open MPI;Cray MPI","I have no special reason.","I read the MPI Standard document (web/book).;I search the Internet (Google / Stack Overflow).","Algorithm design","PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_FUNNELED","","Mostly","It's a mix depending on how essential the MPI functionality is for the routine in question.","OpenMP","No, the performance-critical layer is primarily OpenMP.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.);Better debuggability.","One-sided communication;Dynamic process creation","Yes, compatibility is very important for me.","5"
"2019/04/08 11:15:51 AM AST","Other","United States","3","2","C/C++;Fortran (older one than Fortran 90);Python","more than 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).","I have never read any MPI books","MPICH;Open MPI;Cray MPI;IBM MPI (BG/Q, PE, Spectrum)","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).","Algorithm design","One-sided communications","Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_MULTIPLE","","Sometimes","Yes, but I have no special reason for doing that.","Pthread","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","I am not investigating any alternatives.","Latency","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","Dynamic process creation","I prefer to have new API for better performance.","5"
"2019/04/08 11:39:38 AM AST","College/University","Switzerland","1","1","Fortran 90 or newer;Python","between 5 and 10 years","less than 2 years","Numerical application and/or library","Research and development of application(s)","I have not read it, but I plan to.","I have not learned MPI.","","MPICH;Open MPI;Cray MPI","I could not have any choice (the one provided by a vendor).","I search the Internet (Google / Stack Overflow).","Algorithm design","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;Dynamic process creation;PMPI interface","MPI with OpenMP (or multithread)","I do not know or I do not care.","Too complicated and hard to understand.;I have nobody to ask.;lack of experience","Always","Yes, to minimize the changes of communication API.","No","I think there is room but I do not know how to tune it.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","","There are no unnecessary features","I do not know or I do not care.","3"
"2019/04/08 11:47:35 AM AST","College/University","Switzerland","6","5","C/C++","more than 10 years","more than 10 years","Astrophysics","Research and development of application(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).","Using MPI","MPICH;Open MPI","I am familiar with it.","I read online documents (such as man pages).","Debugging","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on)","MPI_THREAD_SINGLE","I have no obstacles.","Sometimes","Yes, to minimize the changes of communication API.","Pthread;CUDA","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","I am not investigating any alternatives.","Fault tolerance/mitigation methods","Resilience (fault tolerance)","Datatypes","Yes, compatibility is very important for me.","3"
"2019/04/08 12:30:36 PM AST","College/University","Switzerland","6","4","C/C++;Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","","I read the MPI standard document.;I read articles found on Internet.","I have never read any MPI books","MPICH;Open MPI;Intel MPI;Cray MPI;IBM MPI (BG/Q, PE, Spectrum)","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).","Algorithm design","Dynamic process creation;Persistent communication","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI with OpenMP (or multithread)","MPI_THREAD_MULTIPLE","Too many routines.","Sometimes","No, MPI calls are scattered in my programs.","OpenMP;Pthread;CUDA","I have no chance to investigate.","I am not investigating any alternatives.","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","One-sided communication","Yes, compatibility is very important for me.","3"
"2019/04/08 1:53:51 PM AST","College/University","Switzerland","5","3","C/C++","between 5 and 10 years","less than 2 years","Numerical application and/or library","Research and development software tool(s)","I have not read it, but I plan to.","I read the MPI standard document.;I read articles found on Internet.","","Open MPI;Cray MPI","I like to use it.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","One-sided communications;Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes","I do not know or I do not care.","I have no obstacles.","Always","Yes, to minimize the changes of communication API.","OpenMP;OpenACC","I think there is room but I do not know how to tune it.","I am not investigating any alternatives.","MPI provides all semantics I need","","There are no unnecessary features","API should be clearly versioned.","3"
"2019/04/08 2:32:15 PM AST","College/University","Switzerland","6","4","Fortran 90 or newer;Python","more than 10 years","between 5 and 10 years","Numerical application and/or library;Big data;Workflow and/or In-situ","Research and development of application(s)","No, and I will not read it.","Other lectures or tutorials (workplace, conference).;I read articles found on Internet.;Looking in existing MPI patterns into software application codes","","Open MPI;Intel MPI;Cray MPI","I have no special reason.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Performance tuning","One-sided communications;Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes","I have never called MPI_INIT_THREAD","I do not develop too many MPI applications, and the ones I maintain do not need too much further parallel optimisation","Mostly","Yes, to minimize the changes of communication API.","No","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Latency","Resilience (fault tolerance);Another API which is easier and/or simpler to use","One-sided communication;Process topologies;Dynamic process creation","API should be clearly versioned.","2"
"2019/04/08 2:55:34 PM AST","College/University","United Kingdom","5","3","C/C++","more than 10 years","between 2 and 5 years","Numerical application and/or library","Research and development of application(s);Parallelization of sequential program(s);Debugging MPI programs","","Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","I have never read any MPI books","Open MPI;Intel MPI","I have no special reason.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Point-to-point communications;Collective communications;MPI datatypes;One-sided communications;Dynamic process creation;MPI with OpenMP (or multithread)","Point-to-point communications;Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE","I have nobody to ask.;I do not like the API.","","Yes, to minimize the changes of communication API.","OpenMP","I have no chance to investigate.","I am not investigating any alternatives.","The limit on data that can be sent and recieved using the pack / unpack , send / recv pattern. This is a severe limitation. My only way around it is to rewrite code to use my own custom datatypes, which seems unneccessarily complicated and time-consuming.","Using custom data types safely to pack up a struct is far too complicated.","There are no unnecessary features","API should be clearly versioned.","4"
"2019/04/08 3:40:41 PM AST","College/University","Poland","5","5","C/C++;Fortran 90 or newer","more than 10 years","between 5 and 10 years","computational physics","Research and development of application(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","MPICH;Open MPI;Intel MPI;Cray MPI","I have no special reason.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Finding appropriate MPI routines","One-sided communications;Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on)","I have never called MPI_INIT_THREAD","No appropriate lecture / book / info.","Sometimes","No, MPI calls are scattered in my programs.","CUDA","I think there is room but I do not know how to tune it.","I am not investigating any alternatives.","Bandwidth","","One-sided communication;Process topologies;Dynamic process creation","Yes, compatibility is very important for me.","5"
"2019/04/08 4:48:00 PM AST","Governmental institute","Italy","5","4","C/C++","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s)","I have not read it, but I plan to.","I read articles found on Internet.","I have never read any MPI books","MPICH;Open MPI;MVAPICH;Intel MPI","I have no special reason.","I search the Internet (Google / Stack Overflow).","Algorithm design","Collective communications;Dynamic process creation;Persistent communication","Communicator operations (split, duplicate, and so on);PMPI interface","I have never called MPI_INIT_THREAD","No appropriate lecture / book / info.","Sometimes","No, MPI calls are scattered in my programs.","Pthread","I do not know how to find bottlenecks.","I am not investigating any alternatives.","Multi-threading support","","","Yes, compatibility is very important for me.","1"
"2019/04/08 4:52:38 PM AST","College/University","Switzerland","6","6","C/C++;Python","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I read the MPI standard document.","I have never read any MPI books","MPICH;Open MPI;MVAPICH;Intel MPI;Cray MPI;MS MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).;I know almost all MPI routines.","Algorithm design","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_FUNNELED","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","Pthread;OpenCL;CUDA","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A framework or library using MPI.;A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Multi-threading support","Latency hiding (including asynchronous completion)","There are no unnecessary features","Yes, compatibility is very important for me.","4"
"2019/04/08 5:02:16 PM AST","Governmental institute","Germany","4","5","C/C++","more than 10 years","more than 10 years","Tool development (performance tuning, debugging, etc.)","Research and development software tool(s);Parallelization of sequential program(s);Performance tuning of MPI program(s)","I read most of it.","Other lectures or tutorials (workplace, conference).","I have never read any MPI books","MPICH;Open MPI;MVAPICH;Intel MPI;IBM MPI (BG/Q, PE, Spectrum);ParaStation MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).","Algorithm design","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread);PMPI interface","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED","I have no obstacles.","Sometimes","","OpenMP;Pthread;OpenACC;CUDA","","A framework or library using MPI.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Endpoints (multi-thread, sessions)","There are no unnecessary features","API should be clearly versioned.","4"
"2019/04/08 5:09:32 PM AST","College/University","Switzerland","5","4","C/C++;Python","between 5 and 10 years","between 2 and 5 years","Numerical application and/or library;Image processing;Visualization","Research and development of application(s)","No, and I will not read it.","Other lectures or tutorials (workplace, conference).","","MPICH;Open MPI;Cray MPI;MS MPI","I could not have any choice (the one provided by a vendor).","I search the Internet (Google / Stack Overflow).","Debugging","Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Dynamic process creation;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","I do not like the API.","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","OpenMP;CUDA","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A framework or library using MPI.","Multi-threading support","Resilience (fault tolerance);Another API which is easier and/or simpler to use","There are no unnecessary features","I prefer to have new API which is simpler and/or easier-to-use.","3"
"2019/04/08 6:42:32 PM AST","College/University","Australia","6","5","Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s)","No, and I will not read it.","I read articles found on Internet.","","MPICH;Open MPI;Intel MPI;Cray MPI;IBM MPI (BG/Q, PE, Spectrum)","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_MULTIPLE","No appropriate lecture / book / info.","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","OpenMP;OpenACC","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Multi-threading support","Latency hiding (including asynchronous completion)","Process topologies","I prefer to have new API for better performance.","4"
"2019/04/08 8:34:46 PM AST","Other","Germany","5","4","C/C++;Java;Python","more than 10 years","more than 10 years","Numerical application and/or library;Workflow and/or In-situ","Research and development software tool(s)","","I had lecture(s) at school.;I read articles found on Internet.","I have never read any MPI books","MPICH;Open MPI;Intel MPI;IBM MPI (BG/Q, PE, Spectrum)","I am familiar with it.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","Too many routines.","Mostly","No, my program is too small to do that.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Latency","Resilience (fault tolerance);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","There are no unnecessary features","Yes, compatibility is very important for me.","3"
"2019/04/09 1:30:05 AM AST","College/University","Finland","4","4","C/C++;Python","more than 10 years","between 5 and 10 years","Numerical application and/or library;Big data;Visualization","Research and development of application(s);Research and development software tool(s)","No, and I will not read it.","Other lectures or tutorials (workplace, conference).","","MPICH;Open MPI;MVAPICH;Intel MPI;Cray MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Performance tuning","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_FUNNELED","I have no obstacles.","Always","Yes, to minimize the changes of communication API.","OpenMP","No, my MPI programs are well-tuned.","A framework or library using MPI.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","There are no unnecessary features","API should be clearly versioned.","3"
"2019/04/09 2:31:08 AM AST","Governmental institute","Switzerland","6","4","C/C++;Python","more than 10 years","between 5 and 10 years","Parallel language (incl. domain specific language);Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","","MPICH;Open MPI;MVAPICH;Intel MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).","Debugging","Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;MPI with OpenMP (or multithread);CUDA-aware MPI","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","OpenMP;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","A Domain Specific Language (DSL).","Latency","Latency hiding (including asynchronous completion)","Dynamic process creation","API should be clearly versioned.","3"
"2019/04/09 3:00:43 AM AST","Governmental institute","Italy","6","6","C/C++;Fortran (older one than Fortran 90)","more than 10 years","more than 10 years","Parallel language (incl. domain specific language)","Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","I read only the chapters of interest for my work.","I read the MPI standard document.;I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Using MPI","Open MPI;Intel MPI","I am familiar with it.","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Algorithm design","Dynamic process creation;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_MULTIPLE","I have no obstacles.","Mostly","No, MPI calls are scattered in my programs.","OpenMP;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","There are no unnecessary features","Yes, compatibility is very important for me.","4"
"2019/04/09 4:02:53 AM AST","College/University","Switzerland","2","2","Fortran 90 or newer","between 5 and 10 years","between 2 and 5 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I had lecture(s) at school.;I read articles found on Internet.","Using MPI","Open MPI","I was said to use it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","One-sided communications;Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes","I have never called MPI_INIT_THREAD","I have no obstacles.","Sometimes","No, MPI calls are scattered in my programs.","No","I do not know if there is room for performance tuning.","I am not investigating any alternatives.","","","","","2"
"2019/04/09 4:08:41 AM AST","College/University","Australia","6","5","C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer;Python","between 5 and 10 years","between 5 and 10 years","Parallel language (incl. domain specific language);Numerical application and/or library","Research and development of application(s);Performance tuning of MPI program(s);Debugging MPI programs","No, and I will not read it.","I had lecture(s) at school.;I read articles found on Internet.","","Open MPI;Cray MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).","Debugging","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","Too many routines.","Sometimes","Yes, to minimize the changes of communication API.","OpenMP;OpenACC;CUDA","No, my MPI programs are well-tuned.","I am not investigating any alternatives.","Multi-threading support","MPI is providing all the communication semantics required by my application","Dynamic process creation","Yes, compatibility is very important for me.","2"
"2019/04/09 4:53:48 AM AST","College/University","Sweden","3","4","C/C++;Fortran 90 or newer;Python","between 2 and 5 years","between 2 and 5 years","Numerical application and/or library","Research and development of application(s);Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","Parallel Programming with MPI;Using MPI","MPICH;Open MPI;Cray MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Domain decomposition","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes","I have never called MPI_INIT_THREAD","No appropriate lecture / book / info.","Never","No, MPI calls are scattered in my programs.","No","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A framework or library using MPI.;A Domain Specific Language (DSL).","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","load balancing","Error handlers","Yes, compatibility is very important for me.","5"
"2019/04/09 5:26:19 AM AST","College/University","Switzerland","3","3","C/C++;Python","between 2 and 5 years","between 2 and 5 years","Numerical application and/or library","Research and development of application(s)","","I had lecture(s) at school.","MPI: The Complete Reference","Open MPI","I am familiar with it.","I read online documents (such as man pages).","Debugging","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;One-sided communications","I have never called MPI_INIT_THREAD","No appropriate lecture / book / info.","Sometimes","Yes, but I have no special reason for doing that.","OpenMP","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A framework or library using MPI.","Message injection rate","Latency hiding (including asynchronous completion)","There are no unnecessary features","Yes, compatibility is very important for me.","3"
"2019/04/09 5:41:35 AM AST","College/University","Italy","5","3","C/C++","between 2 and 5 years","between 2 and 5 years","Numerical application and/or library","Parallelization of sequential program(s)","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Parallel Programming with MPI;Using MPI","MPICH;Open MPI;IBM MPI (BG/Q, PE, Spectrum)","I like to use it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Debugging","Point-to-point communications;Collective communications;MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","Point-to-point communications;Collective communications;MPI datatypes","MPI_THREAD_SINGLE","No appropriate lecture / book / info.;I do not like the API.","Sometimes","Yes, to minimize the changes of communication API.","OpenMP;CUDA","I do not have (know) tools to find performance bottlenecks.","A framework or library using MPI.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Resilience (fault tolerance);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.);Another API which is easier and/or simpler to use","Dynamic process creation","I prefer to have new API which is simpler and/or easier-to-use.","4"
"2019/04/09 7:27:25 AM AST","College/University","Germany","5","3","Fortran 90 or newer;Python;Julia","more than 10 years","between 2 and 5 years","Numerical application and/or library","Research and development of application(s);Research and development software tool(s)","","I read articles found on Internet.","","MPICH;Open MPI;Intel MPI;MS MPI","I have no special reason.","I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Algorithm design","Communicator operations (split, duplicate, and so on);One-sided communications;Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes","I have never called MPI_INIT_THREAD","I have no obstacles.","Sometimes","No, MPI calls are scattered in my programs.","","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","There are no unnecessary features","Yes, compatibility is very important for me.","3"
"2019/04/09 8:40:05 AM AST","Governmental institute","Switzerland","4","5","C/C++;Fortran 90 or newer;Python","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s);Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;going through the source code of MPI-enable applications","I have never read any MPI books","MPICH;Open MPI","I have no special reason.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Performance tuning","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI with OpenMP (or multithread)","MPI_THREAD_MULTIPLE","I have no obstacles.","Always","Yes, to minimize the changes of communication API.","OpenMP;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Multi-threading support","MPI is providing all the communication semantics required by my application","One-sided communication;Process topologies;Dynamic process creation","I prefer to have new API for better performance.","4"
"2019/04/09 10:23:33 AM AST","Governmental institute","Italy","5","1","Java;Python","more than 10 years","less than 2 years","System software development (OS, runtime library, communication library, etc.)","Research and development of application(s)","I have not read it, but I plan to.","I read articles found on Internet.","I have never read any MPI books","Open MPI","I was said to use it.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Domain decomposition","Collective communications;MPI datatypes;PMPI interface","MPI with OpenMP (or multithread)","I do not know or I do not care.","No appropriate lecture / book / info.","Sometimes","No, MPI calls are scattered in my programs.","No","I do not know if there is room for performance tuning.","I am not investigating any alternatives.","","Another API which is easier and/or simpler to use","Process topologies","I prefer to have new API which is simpler and/or easier-to-use.","1"
"2019/04/10 6:17:02 AM AST","Governmental institute","Germany","5","5","C/C++","more than 10 years","more than 10 years","System software development (OS, runtime library, communication library, etc.);Numerical application and/or library","Research and development of application(s);Research and development software tool(s)","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","Open MPI;MVAPICH;Intel MPI;IBM MPI (BG/Q, PE, Spectrum)","I am familiar with it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Performance tuning","","Point-to-point communications;Collective communications;MPI datatypes;One-sided communications;Persistent communications","I have never called MPI_INIT_THREAD","I have no obstacles.","Mostly","Yes, to minimize the changes of communication API.","OpenMP;Pthread","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","Low-level communication layer provided by vendor (Verbs, DCMF, ...).","Latency","MPI is providing all the communication semantics required by my application","One-sided communication;Communicator and group management","API should be clearly versioned.","5"
"2019/04/10 10:18:18 AM AST","College/University","Switzerland","5","1","C/C++;Python","between 5 and 10 years","between 2 and 5 years","Parallel language (incl. domain specific language);Numerical application and/or library","Research and development of application(s);Research and development software tool(s);Parallelization of sequential program(s)","No, and I will not read it.","I have not learned MPI.;Reverse engineering","I have never read any MPI books","Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I search the Internet (Google / Stack Overflow).","Algorithm design","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;Dynamic process creation;Persistent communication;MPI with OpenMP (or multithread)","Point-to-point communications","I have never called MPI_INIT_THREAD","No appropriate lecture / book / info.;Too complicated and hard to understand.","Never","Yes, to minimize the changes of communication API.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","no clue","no clue","no clue","I do not know or I do not care.","4"
"2019/04/10 11:52:30 PM AST","College/University","China","4","4","Fortran 90 or newer","between 5 and 10 years","between 5 and 10 years","Computational Fluid Dynamics","Research and development of application(s)","","I read articles found on Internet.","","MPICH;Open MPI;MVAPICH;Intel MPI;Cray MPI;IBM MPI (BG/Q, PE, Spectrum)","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).","Performance tuning","One-sided communications;Dynamic process creation;Persistent communication","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","","Too many routines.;No appropriate lecture / book / info.","I rely on the default ‘Errors abort’ error handling","No, MPI calls are scattered in my programs.","OpenMP;OpenACC","I have no chance to investigate.","I am not investigating any alternatives.","Bandwidth","Another API which is easier and/or simpler to use","One-sided communication","I prefer to have new API for better performance.","5"
"2019/04/11 10:31:38 AM AST","Governmental institute","Germany","5","2","Fortran 90 or newer","more than 10 years","less than 2 years","Numerical application and/or library;Big data","Research and development of application(s);Parallelization of sequential program(s)","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).","MPI: A Message Passing Interface Standard","Intel MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).","Debugging","Dynamic process creation;Persistent communication;PMPI interface","Collective communications;One-sided communications","I have never called MPI_INIT_THREAD","I have no obstacles.","Always","No, MPI calls are scattered in my programs.","No","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","MPI is providing all the communication semantics required by my application","There are no unnecessary features","API should be clearly versioned.","2"
"2019/04/11 8:07:53 PM AST","College/University","Spain","6","5","C/C++;Fortran 90 or newer;Python","more than 10 years","more than 10 years","Numerical application and/or library;Workflow and/or In-situ;Tool development (performance tuning, debugging, etc.)","Research and development of application(s);Research and development software tool(s)","I have not read it, but I plan to.","I had lecture(s) at school.;I read articles found on Internet.;I work with MPI quite a lot","","MPICH;Open MPI;Intel MPI","I like to use it.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","One-sided communications;Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes","I have never called MPI_INIT_THREAD","I mostly use the same things.  Presumably there are many other things, but I have not really needed those.","I rely on the default ‘Errors abort’ error handling","I/we use Python/C, and I/we mostly use Python bindings for MPI calls (not mpi4py though, for historical reasons)","","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.);Another API which is easier and/or simpler to use;Often it is not raw performance which is most important, but rather how to get a particular job done.  Last time I checked (a very long time ago) it was somehow difficult to write a process pool, something easily done with ordinary threading (I may be ignorant though)","","API should be clearly versioned.","3"
"2019/04/12 5:06:54 AM AST","Governmental institute","Switzerland","5","4","Julia","more than 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s);Research and development software tool(s);Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","I read only the chapters of interest for my work.","I read book(s).;I usually look up while working what I need in the html version(s) of the MPI standard documents.","Using MPI - 1st Edition (Book by Bill Gropp)","Open MPI;Cray MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI + CUDA C / CUDA-aware MPI","I have never called MPI_INIT_THREAD","Too many routines.","I rely on the default ‘Errors abort’ error handling","Yes, to keep the numerical algorithm implementation separated from MPI communication.","OpenMP;CUDA","No, my MPI programs are well-tuned.","A framework or library using MPI.;A Domain Specific Language (DSL).","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","Dynamic process creation;Error handlers","Yes, compatibility is very important for me.","3"
"2019/04/12 5:16:06 AM AST","Governmental institute","Germany","5","5","C/C++;Python","more than 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s);Performance tuning of MPI program(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","MPICH;Open MPI;MVAPICH;Intel MPI","I like to use it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","PMPI interface","Point-to-point communications;Collective communications;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED;MPI_THREAD_SERIALIZED;MPI_THREAD_MULTIPLE","I have nobody to ask.","Sometimes","Yes, to minimize the changes of communication API.","OpenMP;GASPI","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Multi-threading support","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","","I prefer to have new API for better performance.","4"
"2019/04/12 5:24:19 AM AST","Governmental institute","Germany","3","2","C/C++","between 5 and 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s)","No, and I will not read it.","I have not learned MPI.","","Open MPI;Intel MPI","I could not have any choice (the one provided by a vendor).","I search the Internet (Google / Stack Overflow).","Implementation issue workaround","Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications","I do not know or I do not care.","Too complicated and hard to understand.","Never","Yes, to minimize the changes of communication API.","No","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","There are no unnecessary features","Yes, compatibility is very important for me.","4"
"2019/04/12 8:01:43 AM AST","Governmental institute","India","4","5","C/C++","more than 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","I have never read any MPI books","MPICH;Open MPI;Intel MPI;Cray MPI;IBM MPI (BG/Q, PE, Spectrum)","I have no special reason.","I read online documents (such as man pages).;I ask colleagues.;I know almost all MPI routines.","Algorithm design","PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;Dynamic process creation;Persistent communications;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","Too many routines.","Sometimes","No, MPI calls are scattered in my programs.","OpenMP;Pthread;CUDA","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","I am not investigating any alternatives.","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","There are no unnecessary features","I prefer to have new API for better performance.","5"
"2019/04/12 9:08:48 AM AST","College/University","Switzerland","4","3","C/C++;Python","more than 10 years","between 2 and 5 years","Numerical application and/or library;Visualization","Research and development of application(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I had lecture(s) at school.","I have never read any MPI books","MPICH;Open MPI;Cray MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","One-sided communications;Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes","MPI_THREAD_MULTIPLE","Too many routines.","Never","Yes, to minimize the changes of communication API.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","Process topologies;Dynamic process creation;Error handlers","Yes, compatibility is very important for me.","3"
"2019/04/12 11:26:05 AM AST","Governmental institute","Switzerland","5","4","C/C++;Fortran 90 or newer;Python","more than 10 years","more than 10 years","Numerical application and/or library;Lattice Field Theory","Research and development of application(s)","I read only the chapters of interest for my work.","I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","Using MPI;MPI: The Complete Reference","Open MPI;MVAPICH;Intel MPI;Cray MPI;IBM MPI (BG/Q, PE, Spectrum)","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Implementation issue workaround","PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;One-sided communications","I have never called MPI_INIT_THREAD","I do not like the API.","I rely on the default ‘Errors abort’ error handling","No, MPI calls are scattered in my programs.","","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Bandwidth","Latency hiding (including asynchronous completion);Resilience (fault tolerance);Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","","I prefer to have new API which is simpler and/or easier-to-use.","3"
"2019/04/13 6:42:31 AM AST","Governmental institute","Germany","6","6","C/C++;Fortran 90 or newer;Python","more than 10 years","between 5 and 10 years","Numerical application and/or library;Big data;Workflow and/or In-situ;Visualization","Research and development of application(s);Research and development software tool(s);Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","I read only the chapters of interest for my work.","I read book(s).","Parallel Programming with MPI","MPICH;Open MPI;Intel MPI;Cray MPI;IBM MPI (BG/Q, PE, Spectrum)","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).","Domain decomposition","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE","Too many routines.","Always","Yes, to minimize the changes of communication API.","OpenMP;Pthread;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.;Low-level communication layer provided by vendor (Verbs, DCMF, ...).","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","There are no unnecessary features","Yes, compatibility is very important for me.","3"
"2019/04/14 4:31:15 AM AST","College/University","Switzerland","5","5","C/C++;Python","between 5 and 10 years","between 5 and 10 years","Numerical application and/or library","Research and development of application(s);Research and development software tool(s);Parallelization of sequential program(s)","No, and I will not read it.","I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","I have never read any MPI books","MPICH;Open MPI;MVAPICH;Cray MPI;MS MPI","I like to use it.","I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Finding appropriate MPI routines","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications","I have never called MPI_INIT_THREAD","Too many routines.;No appropriate lecture / book / info.","Never","No, MPI calls are scattered in my programs.","CUDA","I think there is room but I do not know how to tune it.","A framework or library using MPI.","Multi-threading support","Endpoints (multi-thread, sessions)","There are no unnecessary features","I prefer to have new API which is simpler and/or easier-to-use.","3"
"2019/04/14 7:55:34 AM AST","College/University","Czech Republic","5","5","C/C++","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s);Performance tuning of MPI program(s)","I read most of it.","I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).","Parallel Programming with MPI;Parallel Programming in C with MPI and OpenMP","Open MPI;Intel MPI","I like to use it.","I read online documents (such as man pages).;I know almost all MPI routines.","Domain decomposition","","Point-to-point communications;Collective communications;MPI datatypes;Persistent communications;MPI with OpenMP (or multithread)","MPI_THREAD_FUNNELED","Removed C++ interface, exceptions!!!, int32 for most of counts, displ, etc.","Always","Yes, to minimize the changes of communication API.","OpenMP;CUDA","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A framework or library using MPI.","Latency","Resilience (fault tolerance);Another API which is easier and/or simpler to use","One-sided communication;Dynamic process creation","I prefer to have new API which is simpler and/or easier-to-use.","4"
"2019/04/14 12:08:16 PM AST","Governmental institute","Switzerland","5","5","C/C++;Fortran 90 or newer;Python","more than 10 years","more than 10 years","Numerical application and/or library;scientific software","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s)","I read most of it.","I read the MPI standard document.;I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Beginning MPI (An Introduction in C);Parallel Programming with MPI;Using MPI;Parallel Programming in C with MPI and OpenMP;MPI: The Complete Reference","MPICH;Open MPI;MVAPICH;Cray MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I know almost all MPI routines.","Domain decomposition","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;Dynamic process creation;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE;I have never called MPI_INIT_THREAD","Too many routines.","Sometimes","Yes, to minimize the changes of communication API.","OpenMP;Pthread;OpenACC;OpenCL;CUDA","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A framework or library using MPI.;A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Message injection rate","Resilience (fault tolerance)","Dynamic process creation","I prefer to have new API for better performance.","4"
"2019/04/15 4:29:46 AM AST","Other","Italy","4","5","C/C++;Fortran 90 or newer;Python","more than 10 years","more than 10 years","Numerical application and/or library;Image processing","Research and development software tool(s);Parallelization of sequential program(s)","I read only the chapters of interest for my work.","I read book(s).;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Using MPI;MPI: The Complete Reference","MPICH;Open MPI;Intel MPI","I was said to use it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Performance tuning","Dynamic process creation;Persistent communication","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD;I do not know or I do not care.","I have no obstacles.","Mostly","Yes, but I have no special reason for doing that.","OpenMP;Pthread","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","Dynamic process creation","Yes, compatibility is very important for me.","3"
"2019/04/15 4:51:16 AM AST","Governmental institute","Italy","4","4","C/C++;Fortran 90 or newer;Python","between 2 and 5 years","less than 2 years","System software development (OS, runtime library, communication library, etc.);Numerical application and/or library","Research and development of application(s)","I have not read it, but I plan to.","I had lecture(s) at school.","","MPICH;Open MPI;Intel MPI","","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","Point-to-point communications;Communicator operations (split, duplicate, and so on);Dynamic process creation;Persistent communication","Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","","Sometimes","","","","","","","","",""
"2019/04/15 5:06:26 AM AST","Governmental institute","Czech Republic","4","3","C/C++;Python","between 5 and 10 years","between 2 and 5 years","Numerical application and/or library;Workflow and/or In-situ","Research and development of application(s)","I read only the chapters of interest for my work.","I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","Open MPI;Intel MPI","I am familiar with it.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Algorithm design","Communicator operations (split, duplicate, and so on);PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","I do not know or I do not care.","","Sometimes","No, MPI calls are scattered in my programs.","OpenMP;OpenACC","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Latency","Resilience (fault tolerance)","There are no unnecessary features","I prefer to have new API for better performance.","4"
"2019/04/15 7:40:23 AM AST","College/University","Germany","6","6","C/C++;Python","more than 10 years","more than 10 years","Parallel language (incl. domain specific language);Numerical application and/or library;Image processing","Research and development software tool(s);Parallelization of sequential program(s);Performance tuning of MPI program(s)","I read most of it.","I read the MPI standard document.;I read book(s).;Other lectures or tutorials (workplace, conference).","Parallel Programming with MPI;Using MPI;Parallel Programming in C with MPI and OpenMP","MPICH;Open MPI;IBM MPI (BG/Q, PE, Spectrum)","I am familiar with it.","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).;I read online documents (such as man pages).","Algorithm design","","Point-to-point communications;Collective communications;MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","Too many routines.","Mostly","Yes, to minimize the changes of communication API.","OpenMP;OpenACC;OpenCL;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.;A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).;A Domain Specific Language (DSL).","Multi-threading support","Resilience (fault tolerance)","Dynamic process creation","I prefer to have new API for better performance.","5"
"2019/04/15 8:11:38 AM AST","Other","Italy","5","4","C/C++;Python","between 5 and 10 years","less than 2 years","Numerical application and/or library;Image processing","Research and development of application(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","","MPICH;Open MPI;Cray MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read online documents (such as man pages).","Debugging","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes","Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes","I have never called MPI_INIT_THREAD;I do not know or I do not care.","I have no obstacles.","Never","Yes, to minimize the changes of communication API.","","I do not know if there is room for performance tuning.","I am not investigating any alternatives.","","","","I do not know or I do not care.",""
"2019/04/15 9:34:21 AM AST","Governmental institute","Switzerland","5","4","C/C++","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","I had lecture(s) at school.","Parallel Programming with MPI;MPI: The Complete Reference","MPICH;Open MPI;MVAPICH;Cray MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).","Algorithm design","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;Dynamic process creation;MPI with OpenMP (or multithread)","Point-to-point communications;Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_SERIALIZED","I have no obstacles.","Always","Yes, to minimize the changes of communication API.","OpenMP;Pthread;OpenACC;CUDA;TBB, C++11 threads.","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Multi-threading support","MPI is providing all the communication semantics required by my application","There are no unnecessary features","The gist of this survey is that you want to know if the API should be changed. The existing API is a good fit for existing functionality: it is a bit clunky, but the standard is clear, and it is easy to wrap in clean C++. The main problem with the API is that only a small part of the API is effiniently/correctly implemented on many implementations.","4"
"2019/04/15 12:11:45 PM AST","College/University","Czech Republic","4","1","C/C++;Python","between 5 and 10 years","less than 2 years","Parallel language (incl. domain specific language);Image processing","Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","","I had lecture(s) at school.","I have never read any MPI books","Open MPI;Intel MPI","I was said to use it.","I read the school lectures","Domain decomposition","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE","I am at the beginning of learning, so I cannot say yet.","Sometimes","No, my program is too small to do that.","OpenMP","I do not know if there is room for performance tuning.","","","","","I do not know or I do not care.",""
"2019/04/15 3:09:25 PM AST","Governmental institute","Germany","4","4","C/C++","more than 10 years","more than 10 years","System software development (OS, runtime library, communication library, etc.);Tool development (performance tuning, debugging, etc.)","Research and development software tool(s)","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Using MPI;MPI: The Complete Reference","MPICH;Open MPI;MVAPICH;Intel MPI","I have no special reason.","I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Debugging","Persistent communication","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_MULTIPLE","Too many routines.","Sometimes","Yes, to minimize the changes of communication API.","OpenMP","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","I am not investigating any alternatives.","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","MPI is providing all the communication semantics required by my application","There are no unnecessary features","API should be clearly versioned.","3"
"2019/04/17 4:24:18 AM AST","College/University","Austria","2","1","Python","between 2 and 5 years","less than 2 years","Bioinformatics","Research and development software tool(s)","I have not read it, but I plan to.","I have not learned MPI.","I have never read any MPI books","Open MPI","I could not have any choice (the one provided by a vendor).","I don't write MPI programs yet","Other","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;Dynamic process creation;Persistent communication;PMPI interface","no programs","I have never called MPI_INIT_THREAD","No appropriate lecture / book / info.","Never","","No","I do not know if there is room for performance tuning.","I am not investigating any alternatives.","Multi-threading support","","","",""
"2019/04/23 5:09:17 AM AST","Other","Germany","6","5","C/C++;Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library;Tool development (performance tuning, debugging, etc.)","Research and development of application(s);Research and development software tool(s)","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).","Using MPI","MPICH","I am familiar with it.","I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Debugging","Point-to-point communications;Collective communications;MPI datatypes;MPI with OpenMP (or multithread)","Point-to-point communications;Collective communications;MPI datatypes","I have never called MPI_INIT_THREAD","Too many routines.;Too complicated and hard to understand.","Always","No, MPI calls are scattered in my programs.","No","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","I am not aware of unncessary features, but maybe my overview is not large enough.","Yes, compatibility is very important for me.","1"
"2019/04/26 11:52:53 AM AST","Other","Germany","5","4","Fortran 90 or newer","more than 10 years","between 5 and 10 years","Numerical application and/or library;Earth System Science","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s);Debugging MPI programs","I read only the chapters of interest for my work.","I read book(s).;I read articles found on Internet.","Using MPI","MPICH;Open MPI;MVAPICH;Intel MPI;IBM MPI (BG/Q, PE, Spectrum)","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Debugging","Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications","I have never called MPI_INIT_THREAD","Too many routines.;Too complicated and hard to understand.","Always","Yes, to minimize the changes of communication API.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.","Bandwidth","Another API which is easier and/or simpler to use","There are no unnecessary features","Yes, compatibility is very important for me.","3"
"2019/05/02 6:31:22 PM AST","College/University","United States","5","2","Julia","between 5 and 10 years","less than 2 years","Parallel language (incl. domain specific language);Numerical application and/or library","Research and development software tool(s)","I read only the chapters of interest for my work.","I read the MPI standard document.;I read articles found on Internet.","","MPICH;Open MPI","I have no special reason.","I read the MPI Standard document (web/book).;I search the Internet (Google / Stack Overflow).","Debugging","","Point-to-point communications;Collective communications","I have never called MPI_INIT_THREAD","Too complicated and hard to understand.;I do not like the API.;Difficulty of using outside C/Fortran","Never","Yes, but I have no special reason for doing that.","Julia GPU","I think there is room but I do not know how to tune it.","","","","","API should be clearly versioned.","2"
"2019/05/02 8:11:12 PM AST","College/University","United States","5","2","Python;Julia","between 5 and 10 years","less than 2 years","Numerical application and/or library;AI (Deep Learning)","Research and development software tool(s);Parallelization of sequential program(s)","No, and I will not read it.","I read articles found on Internet.","I have never read any MPI books","Open MPI;Intel MPI","I have no special reason.","I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications","I do not know or I do not care.","Too complicated and hard to understand.;I have nobody to ask.","Sometimes","No, MPI calls are scattered in my programs.","CUDA","I think there is room but I do not know how to tune it.","A Domain Specific Language (DSL).","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","","","I prefer to have new API which is simpler and/or easier-to-use.","3"
"2019/05/10 5:53:22 AM AST","College/University","China","5","3","C/C++","between 5 and 10 years","between 2 and 5 years","System software development (OS, runtime library, communication library, etc.)","Research and development on system software (OS and/or runtime library)","","I read articles found on Internet.","I have never read any MPI books","MPICH;Open MPI","I have no special reason.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Domain decomposition","PMPI interface","Point-to-point communications;Communicator operations (split, duplicate, and so on);MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE","Too complicated and hard to understand.","","Yes, to minimize the changes of communication API.","OpenMP","I think there is room but I do not know how to tune it.","I am not investigating any alternatives.","MPI provides all semantics I need","Building inter-communicator is too slow","Dynamic process creation","API should be clearly versioned.","3"
"2019/05/11 7:40:15 AM AST","College/University","China","3","1","C/C++;Java","between 2 and 5 years","less than 2 years","Computational fluid dynamics","Research and development of application(s);Parallelization of sequential program(s);Performance tuning of MPI program(s)","No, and I will not read it.","I read book(s).","An Introduction to Parallel Programming","MPICH;Open MPI;Intel MPI;Tianhe MPI;Sunway MPI","I was said to use it.","I read book(s) (except the MPI standard).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Debugging","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);One-sided communications;MPI with OpenMP (or multithread)","I do not know or I do not care.","Too many routines.;No appropriate lecture / book / info.;Too complicated and hard to understand.;I have nobody to ask.;I do not like the API.","Never","No, MPI calls are scattered in my programs.","OpenMP;Pthread;OpenACC;CUDA","I do not have (know) tools to find performance bottlenecks.","A framework or library using MPI.","Latency","Resilience (fault tolerance)","Error handlers","I do not know or I do not care.","3"
"2019/06/06 7:20:58 AM AST","College/University","United Kingdom","5","5","C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer;Java","more than 10 years","more than 10 years","System software development (OS, runtime library, communication library, etc.);Numerical application and/or library;Tool development (performance tuning, debugging, etc.)","Research and development on system software (OS and/or runtime library);Research and development software tool(s);Parallelization of sequential program(s);Performance tuning of MPI program(s)","I read all.","I read the MPI standard document.;I read book(s).;I read articles found on Internet.","Parallel Programming with MPI;Using MPI;MPI: The Complete Reference","MPICH;Open MPI;MVAPICH","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).;I know almost all MPI routines.","Performance tuning","Persistent communication","Point-to-point communications;Collective communications;MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED;MPI_THREAD_SERIALIZED;MPI_THREAD_MULTIPLE","I have no obstacles.;Too many routines.","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","OpenMP;Pthread","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.;A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Multi-threading support","Latency hiding (including asynchronous completion);Endpoints (multi-thread, sessions);Resilience (fault tolerance);Another API which is easier and/or simpler to use","There are no unnecessary features","I prefer to have new API which is simpler and/or easier-to-use.","5"
"2019/06/13 9:54:56 PM AST","Software vendor","Japan","4","6","C/C++;Python","more than 10 years","between 5 and 10 years","System software development (OS, runtime library, communication library, etc.)","Research and development on system software (OS and/or runtime library)","I read most of it.","I read the MPI standard document.;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","I have never read any MPI books","Open MPI;Fujistu MPI","I was said to use it.","I read the MPI Standard document (web/book).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Debugging","","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;Persistent communications","MPI_THREAD_SERIALIZED","I do not like the API.","I rely on the default ‘Errors abort’ error handling","No, MPI calls are scattered in my programs.","No","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.;Low-level communication layer provided by vendor (Verbs, DCMF, ...).","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","Dynamic process creation;Error handlers","API should be clearly versioned.","3"
"2019/06/13 10:00:36 PM AST","Software vendor","Japan","6","4","C/C++;Fortran (older one than Fortran 90)","more than 10 years","more than 10 years","Numerical application and/or library","Research and development on system software (OS and/or runtime library)","No, and I will not read it.","I read book(s).","Using MPI","Fujistu MPI","I could not have any choice (the one provided by a vendor).","I search the Internet (Google / Stack Overflow).","Performance tuning","Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","I do not know or I do not care.","I have no obstacles.","Sometimes","Yes, to minimize the changes of communication API.","OpenMP","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","Dynamic process creation","Yes, compatibility is very important for me.","3"
"2019/06/14 2:47:02 AM AST","Hardware vendor","Japan","5","3","C/C++;Fortran 90 or newer;Python","more than 10 years","more than 10 years","System software development (OS, runtime library, communication library, etc.);Parallel language (incl. domain specific language)","Debugging MPI programs","I read only the chapters of interest for my work.","I read articles found on Internet.;I read existing codes.","","MPICH;Open MPI;HPE MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).","Domain decomposition","One-sided communications;Persistent communication","Point-to-point communications;MPI with OpenMP (or multithread)","I do not know or I do not care.","Too many routines.","Sometimes","No, MPI calls are scattered in my programs.","OpenMP;CUDA","I have no chance to investigate.","I am not investigating any alternatives.","Bandwidth","MPI is providing all the communication semantics required by my application","There are no unnecessary features","Yes, compatibility is very important for me.","3"
"2019/06/14 3:33:39 AM AST","Hardware vendor","Japan","6","6","C/C++;Fortran (older one than Fortran 90);Fortran 90 or newer;Python","more than 10 years","more than 10 years","System software development (OS, runtime library, communication library, etc.);Parallel language (incl. domain specific language);Numerical application and/or library;AI (Deep Learning);Big data;Workflow and/or In-situ;Tool development (performance tuning, debugging, etc.)","Research and development on system software (OS and/or runtime library);Research and development software tool(s)","I read all.","I read the MPI standard document.;I read book(s).;I had lecture(s) at school.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Using MPI","MPICH;Open MPI;Intel MPI;Fujistu MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).","Performance tuning","Persistent communication","Point-to-point communications;Collective communications","MPI_THREAD_SERIALIZED","I do not like the API.","Always","Yes, to minimize the changes of communication API.","OpenMP","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Bandwidth","Another API which is easier and/or simpler to use","One-sided communication","Yes, compatibility is very important for me.","2"
"2019/06/14 5:12:59 AM AST","Hardware vendor","Japan","5","5","Fortran (older one than Fortran 90);Fortran 90 or newer","more than 10 years","more than 10 years","Numerical application and/or library","Parallelization of sequential program(s);Performance tuning of MPI program(s)","","I read the MPI standard document.;Other lectures or tutorials (workplace, conference).;I read articles found on Internet.","Parallel Programming with MPI;Using MPI","Open MPI;Intel MPI;HPE MPI","I could not have any choice (the one provided by a vendor).","I read the MPI Standard document (web/book).;I read book(s) (except the MPI standard).;I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Performance tuning","","Point-to-point communications;Collective communications;One-sided communications;MPI with OpenMP (or multithread);PMPI interface","MPI_THREAD_SINGLE;MPI_THREAD_FUNNELED;MPI_THREAD_SERIALIZED","Too many routines.","Mostly","Yes, to minimize the changes of communication API.","No","Yes, I know there is room for tuning but I do not have enough resources to do that.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Bandwidth","Another API which is easier and/or simpler to use","Communicator and group management","I prefer to have new API for better performance.","4"
"2019/06/14 5:52:07 AM AST","Hardware vendor","Japan","2","2","C/C++;Fortran 90 or newer;Python","between 2 and 5 years","between 2 and 5 years","Numerical application and/or library","Research and development of application(s)","I have not read it, but I plan to.","I have not learned MPI.","I have never read any MPI books","Open MPI;Intel MPI;HPE MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).","Debugging","Dynamic process creation","Point-to-point communications;Collective communications;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","Too many routines.;No appropriate lecture / book / info.","I rely on the default ‘Errors abort’ error handling","No, my program is too small to do that.","OpenMP","I think there is room but I do not know how to tune it.","I am not investigating any alternatives.","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Another API which is easier and/or simpler to use","There are no unnecessary features","Yes, compatibility is very important for me.","3"
"2019/06/16 3:26:27 AM AST","Hardware vendor","Japan","5","4","C/C++","between 5 and 10 years","between 2 and 5 years","Super computer system operation","System operation and help desk","","I have not learned MPI.","I have never read any MPI books","MPICH;Open MPI;Intel MPI;HPE MPI","I am familiar with it.","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Performance tuning","MPI datatypes;Dynamic process creation;PMPI interface","Collective communications;Dynamic process creation;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","Too complicated and hard to understand.","","No, my program is too small to do that.","CUDA","I have no chance to investigate.","I am not investigating any alternatives.","Optimization opportunities except communication (architecture awareness, dynamic processing, accelerator support, etc.)","Another API which is easier and/or simpler to use","Error handlers","Yes, compatibility is very important for me.","4"
"2019/06/23 8:57:57 PM AST","Hardware vendor","Japan","6","5","C/C++","more than 10 years","more than 10 years","System software development (OS, runtime library, communication library, etc.)","Research and development on system software (OS and/or runtime library)","I read most of it.","I read the MPI standard document.","MPI: The Complete Reference","MPICH;Open MPI;Fujistu MPI","I like to use it.","I read the MPI Standard document (web/book).;I search the Internet (Google / Stack Overflow).","Performance tuning","","Point-to-point communications;Collective communications;One-sided communications;Persistent communications","MPI_THREAD_SERIALIZED","Too many routines.;Too complicated and hard to understand.","Mostly","Yes, to minimize the changes of communication API.","OpenMP","I think there is room but I do not know how to tune it.","A framework or library using MPI.;Low-level communication layer provided by vendor (Verbs, DCMF, ...).","Additional optimization opportunities in terms of communication (network topology awareness, etc.)","Additional optimization opportunities in terms of communication (topology awareness, locality, etc.)","Datatypes","I prefer to have new API for better performance.","4"
"2019/07/25 11:11:55 PM AST","College/University","Japan","5","5","Fortran (older one than Fortran 90)","more than 10 years","more than 10 years","Numerical application and/or library","Research and development of application(s)","I read only the chapters of interest for my work.","Other lectures or tutorials (workplace, conference).","Parallel Programming with MPI","Intel MPI;Fujistu MPI","I am familiar with it.","I read online documents (such as man pages).","Performance tuning","Persistent communication;PMPI interface","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;MPI with OpenMP (or multithread)","MPI_THREAD_MULTIPLE","I have no obstacles.","I rely on the default ‘Errors abort’ error handling","Yes, to minimize the changes of communication API.","OpenMP;CUDA","Yes, I know there is room for tuning but I should re-write large part of my program to do that.","A framework or library using MPI.","Bandwidth","Latency hiding (including asynchronous completion)","There are no unnecessary features","Yes, compatibility is very important for me.","4"
"2019/07/26 12:35:58 AM AST","College/University","Taiwan","4","3","C/C++;Python","between 5 and 10 years","between 2 and 5 years","Parallel language (incl. domain specific language);Numerical application and/or library;AI (Deep Learning)","Research and development of application(s);Research and development software tool(s);Parallelization of sequential program(s)","No, and I will not read it.","I had lecture(s) at school.;I read articles found on Internet.","I have never read any MPI books","Open MPI;Intel MPI","I am familiar with it.","I read online documents (such as man pages).;I ask colleagues.;I search the Internet (Google / Stack Overflow).","Implementation issue workaround","MPI datatypes;Dynamic process creation;Persistent communication;PMPI interface","Point-to-point communications;Collective communications;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","I have no obstacles.","Mostly","Yes, to minimize the changes of communication API.","OpenMP;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","I am not investigating any alternatives.","Bandwidth","MPI is providing all the communication semantics required by my application","Communicator and group management","I prefer to have new API for better performance.","4"
"2019/07/26 12:45:39 AM AST","Governmental institute","Japan","5","3","C/C++","more than 10 years","between 2 and 5 years","Numerical application and/or library","Research and development software tool(s)","I have not read it, but I plan to.","I read book(s).;I read articles found on Internet.","Using MPI","Open MPI;Intel MPI;Fujistu MPI","I could not have any choice (the one provided by a vendor).","I read online documents (such as man pages).;I search the Internet (Google / Stack Overflow).","Domain decomposition","Dynamic process creation;Persistent communication;PMPI interface","Collective communications;MPI with OpenMP (or multithread)","I have never called MPI_INIT_THREAD","I have no obstacles.","Sometimes","No, my program is too small to do that.","OpenMP","I have no chance to investigate.","I am not investigating any alternatives.","MPI provides all semantics I need","MPI is providing all the communication semantics required by my application","Communicator and group management","API should be clearly versioned.","2"
"2019/07/26 1:32:42 AM AST","College/University","Japan","3","3","C/C++","between 2 and 5 years","between 2 and 5 years","Parallel language (incl. domain specific language)","Research and development on system software (OS and/or runtime library)","I have not read it, but I plan to.","I had lecture(s) at school.","Using MPI","MVAPICH","I was said to use it.","I read online documents (such as man pages).","Other","PMPI interface","MPI with OpenMP (or multithread)","MPI_THREAD_MULTIPLE","No appropriate lecture / book / info.","Sometimes","No, MPI calls are scattered in my programs.","OpenMP;OpenACC","I think there is room but I do not know how to tune it.","A PGAS language (UPC, Coarray Fortran, OpenSHMEM, XcalableMP, ...).","Multi-threading support","Endpoints (multi-thread, sessions)","There are no unnecessary features","Yes, compatibility is very important for me.","3"
"2019/07/31 5:45:46 AM AST","Hardware vendor","Japan","4","4","C/C++","more than 10 years","between 5 and 10 years","Numerical application and/or library","Performance tuning of MPI program(s)","No, and I will not read it.","I read articles found on Internet.","","Open MPI;Intel MPI","I am familiar with it.","I search the Internet (Google / Stack Overflow).","Debugging","Dynamic process creation;Persistent communication","Point-to-point communications;Collective communications;Communicator operations (split, duplicate, and so on);MPI datatypes;One-sided communications;MPI with OpenMP (or multithread)","MPI_THREAD_MULTIPLE","I have no obstacles.","Mostly","Yes, but I have no special reason for doing that.","OpenMP;Pthread;CUDA","Yes, I know there is room for tuning but I do not have enough resources to do that.","A framework or library using MPI.;Low-level communication layer provided by vendor (Verbs, DCMF, ...).","Multi-threading support","MPI is providing all the communication semantics required by my application","There are no unnecessary features","I prefer to have new API which is simpler and/or easier-to-use.","3"